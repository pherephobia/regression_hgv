[["index.html", "Reading Notes for Regression and Other Stories by Andrew Gelman, Jeniffer Hill and Aki Vehtari Chapter 1 Overview 1.1 The three challenges of statistics 1.2 Why learn regression? 1.3 Some examples of regression 1.4 Challenges in building, understanding, and interpreting regressions 1.5 Classical and Bayesian inference 1.6 Computing least squares and Bayesian regression", " Reading Notes for Regression and Other Stories by Andrew Gelman, Jeniffer Hill and Aki Vehtari Sanghoon Park 2021-06-21 Chapter 1 Overview 이 책(이하 Gelman, Hill, and Vehtari (2020))은 예측모형을 만들고, 이해하고, 사용하는 데 있어서 마주할 수 있는 문제들을 다루고 있다. 우선 데이터, 측정, 그리고 통계치(statistics)에 관한 기본적인 개념들을 앞의 다섯개 챕터에서 검토하고, 하나의 예측변수와 여러개의 예측변수를 가지는 선형 회귀모델을 다룬다. 뒷 부분에서는 로지스틱 회귀모델을 포함한 일반화 선형모델들을 살펴보게 될 것이다. 저자들이 말하는 것처럼 이 책의 장점 중 하나는 단순히 기법적인 것들을 설명하는 것이 아닌, 이러한 모델들을 이용해서 어떻게 가지고 있는 데이터로부터 인과추론에 이르기까지 일반화를 할 수 있는지에 대한 회귀모델 “적용”의 문제를 다루고 있다는 것이다. GHV를 읽고 정리한 이 리딩노트는 모든 내용을 요약하지 않고 필수적이라고 생각되는 예제들을 선택적으로 포함하여 본문의 Figure 나 Table과 캡션이나 레이블이 일치하지 않을 수 있다. 이를 참고하기 바란다. 1.1 The three challenges of statistics 통계적 추론(statistical inference)에 있어서 마주할 수 있는 세 가지 문제는 다음과 같다: 표본을 가지고 모집단 수준으로 일반화를 해야하는 문제. 이 문제는 설문 표집(survey sampling)과 관련되어 있지만, 사실 모든 통계 추론을 적용할 때 제기될 수 있는 문제이다. 왜냐하면 우리가 가진 데이터는 그것이 설문 데이터이건 아니건 간에 모두 하나의 표본(sample)이기 때문이다. 처치집단의 결과를 가지고 통제집단까지 일반화를 해야하는 문제. 거의 대부분의 회귀모델을 해석하는데 있어서 야기되는 인과추론과 관련된 문제이다. 결국 회귀모델도, 통계모델도 일종의 준실험적(quasi-experimental)이라고 불리는 만큼, 어떻게 관계에 영향을 미치는 잡음(noise)과 체계적 요인(systematic factors)을 구분해 우리가 관심을 가지고 있는 관계를 드러낼 것인가에 대한 “통제”의 문제와 밀접하게 관련을 가진다. 관측된 측정지표를 가지고 우리가 관심을 가지고 있는, 그 측정지표 너머의(기저의) 구성개념으로 일반화를 해야하는 문제. 대부분의 경우, 우리가 가지고 있는 데이터가 완벽하게 혹은 정확하게 우리가 이상적으로 연구하고자 하는 대상을 기록하고 있다고 보기는 어렵다. 예를 들어, 민주주의를 측정한다고 할 때, 우리가 개념적으로 기대하는 민주주의를 실제 측정지표로 완벽하게 포착하기는 어렵다. 따라서 우리는 일종의 조작화(operationalization)라는 과정을 거치게 되는데, 이때 우리의 개념화(conceptualization)와 조작화(operationalization) 간에는 필연적으로 간극이 생길 수 밖에 없게 된다. 이 간극을 어떻게 좁힐 것인가에 대한 문제라고도 이해할 수 있다. 위의 세 문제들은 “예측의 문제”(problems of prediction)라는 한 울타리 안에 담을 수 있다. 예를 들어, 새로운 사람들을 대상으로 했을 때, 변화한 표본이 이전의 표본과 마찬가지로 모집단 수준에서 일반화를 하기에 적절한지, 처치(treatment)가 달라졌을 때 이전과 이후의 결과가 어떻게 달라질지, 그리고 앞으로도 우리가 조작화한 측정지표가 우리가 기대한 개념을 정확하게 측정할지 등에 대한 문제가 산적해있는 것이다. 이런 점들을 고려하여 GHV는 이 책을 통해 다음과 같은 핵심 역량을 기르기를 주문한다. 회귀모델을 이해하는 것. 회귀모델이란 결국 일련의 예측변수들을 이용해서 결과과 어떠할 것이라고 예측하는 수리적 모델이다. 이 책은 그 예측을 일종의 선형(linear) 관계로 바라보는 것으로부터 다양한 비선형(non-linear) 관계로 일반화할 수 있는 단계로까지 이해할 수 있는 내용을 다룬다. 회귀모델을 구성하는 것. 회귀모델에 어떤 변수를 선택해서 포함시키고, 혹은 변수를 어떻게 변형시킬지 등은 연구자에게 주어진 선택지이다. 동일한 결과를 회귀모델로 분석하고자 하더라도 연구자마다 다른 변수들을 사용하여 분석할 수 있다. 데이터에 회귀모델을 적합시키는 것. R과 Stan이라는 소프트웨어를 이용하여 데이터로부터 회귀모델을 적합, 그 분석 결과를 도출할 수 있는 스킬을 배우게 된다. 회귀보델의 결과를 보여주고 해석하는 것. 단순히 통계 분석을 수행하는 것이 아니라 그 결과가 가지는 의미를 다른 사람들이 이해할 수 있는 방식으로 보여주고 해석하는 것이 중요하다. 이를 위해서 통계 분석 이상의 프로그래밍 스킬과 수학적 이해를 요구한다. 마지막으로 이 책의 핵심 주제는 바로 추론 (inference)이다. 우리가 손에 넣은 특정한 데이터로부터 수리적 모델을 이용해 (모집단에서 통용되는) 일반화된 주장을 할 수 있는 능력을 의미한다. 1.2 Why learn regression? Figure 1.1: Predicting elections from the economy: (a) the data, (b) the linear fit, y = 46.3 + 3.0x. 회귀모델은 일련의 예측변수들로 정의된 개별 개체들에 따라서 결과의 평균적인 값, 혹은 예측이 어떻게 될 것이라는 걸 보여주는 방법이다. 예를 들어, Figure 1.1a는 미국 대선에서의 집권당의 득표율과 각 선거가 있었던 해에 경제성장률의 측정지표를 그래프로 보여주고 있다. Figure 1.1b는 그 데이터에 적합하는 선형 회귀모델의 결과를 보여준다. 회귀모델은 비록 어느정도의 불확실성은 존재하지만 변화하는 경제성장률에 따라 득표율이 어떻게 될 것이라는 예측이 가능하게 해주며, 그러한 가정 하에서 미래의 선거도 과거와 비슷하다면 어떻게 전개될 것이라고 기대할 수 있게 해준다. GHV는 Stan을 이용해 베이지안 통계 패키지를 이용해 회귀모델을 분석하고 있지만, 여기서는 일반적인 패키지를 이용해 분석한다. 회귀분석에 대한 자세한 내용은 이후의 챕터들에서 다루게 될 것이다. 회귀모델이 주요하게 사용되는 것은 다음과 같다: 예측: 가지고 있는 데이터를 모델링하거나 새로운 데이터를 예측하는 것을 의미힌다. 관계의 탐색: 얼마나 변수들이 결과를 잘 예측하는지를 보여주는 것이 필요하다. 외삽(extrapolation): 여기서는 외삽이라는 개념을 사용했는데, 그보다는 일반화(generalization)라는 표현이 좀 더 이해하기 쉬울 듯 하다. 표본과 모집단의 차이를 알아야 한다는 것에서 시작한다. 현실세계의 표본은 결코 모집단을 완벽하게 대표할 수 없기 때문에, 우리는 표본을 통해서 얻은 결과를 모집단의 수준에서 일반화하는 과정에서 일종의 조정 과정을 거치게 되는데, 이를 외삽이라고 표현한 것이다. 회귀분석은 Figure 1.1b에서 보았듯 일종의 예측을 제시하지만 어디까지나 주어진 표본 하에서 그 선은 그어진 것이고, 앞으로도 계속 그 추세가 이어질지는 알지 못한다. 그럼에도 불구하고 우리는 주어진 데이터에서 모델을 이용한 예측을 일반화화된 진술로 표현하게 된다. 인과추론: 회귀모델에서 가장 중요한 부분으로, 처치효과(treatment effects)를 추정하는 것에 관련된 것이다. 즉, 우리가 기대하는 어떠한 변수가 진짜로 결과의 차이를 가져오는 데 기여하였는가, 그렇다면 얼마나 기여하였는가를 추정하는 것이다. 인과추론은 평균적으로 얼마나 처치 이전에 처치군과 통제군이 유사하였는지, 그리고 처치 이후에 두 집단의 차이가 존재하였는지를 확실히 보여주는가에 그 성패가 달려있다고 할 수 있다. 1.3 Some examples of regression 1.3.1 A randomized experiment on the effect of an educational television program Figure 1.2: Post-treatment classroom-average test scores from an experiment measuring the effect of an educational television program, The Electric Company, on children’s reading abilities. The dark vertical line in each histogram shows the average for the corresponding group of classrooms. 1970년대 새로운 TV 교육 프로그램(The Electric Company)이 어린이들의 독해력에 미치는 효과를 측정하기 위해 수행된 연구를 살펴보자. 실험대상은 미국의 두 작은 도시에 1-4학년 사이의 아이들이었다. 각 도시와 학년에 따라서 10개부터 20개 사이의 학교가 선택되었고, 각 학교는 독해력 시험 점수가 가장 낮은 해당 학년의 두개 학급씩을 선정하였다. 각 2개 학급별로 한 학급은 무작위로 정규 독해 강의를 듣게 했고, 다른 학급은 TV 프로그램을 시청하게 하였다. 즉, 성적이 최하위인 A와 B라는 같은 학년의 두 학급을 선정 후, A에서 무작위로 뽑은 학생들은 정규 독해 강의를 듣고, B에서 무작위로 뽑은 학생들은 TV 프로그램을 보게 한 것이다. 따라서 A는 강의를 들은 학생들과 듣지 않은 학생, B는 TV 프로그램을 본 학생과 보지 않은 학생으로 구분할 수 있다. 각 학생들은 학년이 시작하기 전에 사전 테스트를 쳤고, 학년 말에 사후 테스트를 쳤다. Figure 1.2는 각 학년별 통제 학급과 처치 학급의 사후 테스트 결과를 보여준다. 각 행을 비교하면 통제 학급에 비해 처치 학급이 저학년(Grade 1, Grade 2)의 경우 TV 프로그램을 시청하였을 때 더 높은 독해력을 보여주는 것을 확인할 수 있고, 그 차이는 고학년(Grade 3, Grade 4)으로 가면 줄어드는 것을 확인할 수 있다. 물론, 더 자세한 처치 효과를 추정하기 위해서는 통계적 분석이 필요하다(제19장에서 다시 살펴본다). 1.3.2 Comparing the peacekeeping and gun-control studies GHV는 UN의 평화유지군 파병이 내전이 발생했던 국가가 다시 내전에 재돌입하는 것에 미치는 효과를 본 연구와 일련의 총기 관련 정책이 가지는 효과를 두루 살펴본 연구를 비교하면서 다음과 같은 함의를 이끌어내고 있다. 보고자 하는 것이 무엇인지(연구문제)를 명확히 하고, 그에 맞는 연구설계를 할 필요가 있다. 그 경우에 보다 믿을 수 있고 설득력 있는 결과를 제시할 수 있다. 한 번에 하나의 모델에서 너무 많은 인과관계를 보여줄 필요는 없다. 변수를 많이 추가할수록 조건이 추가되는 것이다. 즉, A가 일정할 때, B가 결과에 미치는 효과는 어떠할 것이다라는 진술과 A부터 G까지의 변수들이 일정할 때, H가 변수에 미치는 효과는 어떠할 것이다라는 진술은 현실 세계에서 우리가 그 결과를 직관적으로 이해할 수 있는가에 영향을 미칠 수 있다. 마찬가지로 비교하고자 하는 대상–분석 단위에 대한 고민도 필요하다. 분석 단위들 간에 존재할 수 있는 체계적 차이를 어떻게 고려하느냐도 우리의 결과가 가지는 신빙성에 영향을 미칠 수 있기 때문이다. 1.4 Challenges in building, understanding, and interpreting regressions 인과추론을 위한 회귀모델에 있어서 두 가지를 구분할 수 있다: 관계를 추정하는 것과 비교하고자 하는 대상들의 기저에 놓인 변수들을 조정(adjusting)하는 것이다. 1.4.1 Regression to estimate a relationship of interest 어떤 처치군과 통제군을 비교한다고 가정해보자. 일단 첫 번째 생각해야할 조건은 처치군과 통제군에 들어갈 사람들이 무작위로 배정되었는지(randomly assigned)에 대한, “무작위화”(randomization)이다. 혹은 배정이 두 집단 간의 균형을 고려한 보다 복잡한 설계를 바탕으로 이루어졌을 수도 있다. 처치군과 통제군을 대략적으로(완벽하게 동일한 개체가 될 수는 없으니까) 비교가능한 집단으로 만드는 것과 이 두 집단 간에 알려진, 혹은 모델에 포함된 차이를 조정하는 방법은 다양하게 존재한다. Figure 1.3: Regression to estimate a causal effect with (a) simple comparison of treatment and control, or (b) a range of treatment levels. Figure 1.4: (a) Hypothetical data in which the causal effect is a nonlinear function of the treatment level; (b) same data with a linear effect estimated. It is always possible to estimate a linear model, even if it does not fit the data. 만약 처치, \\(x\\)가 결과, \\(y\\)에 미치는 효과에 관심이 있고 가지고 있는 데이터가 무작위화 혹은 다른 처치군과 통제군 간의 균형을 고려한 실험설계 방법을 통해 얻어졌다면 우리는 회귀모델을 데이터에 적합하여 불확실성을 포함해 \\(x\\)로부터 \\(y\\)를 예측할 수 있다.1 만약 \\(x\\)가 이항변수(통제일 경우 \\(x=0\\), 처치가 이루어졌을 경우 \\(x=1\\))라면 회귀모델 분석의 결과는 Figure 1.3a와 같이 나타날 것이고, 만약 \\(x\\)가 연속적인 값을 같는 변수라면 Figure 1.3b와 같은 결과를 확인할 수 있을 것이다. 실험방법을 통해 두 집단 간의 비교가능성이 확보된 상황이라면 주어진 처치에 대해 결과를 예측한 회귀분석 결과는 인과효과(causal effect)를 직접적으로 추정한 것이라고 할 수 있다. 하지만 데이터를 더 잘 설명하기 위해, 혹은 더 정확하게 예측하기 위해 더 정교한 모델링을 할 수도 있다. 예를 들어, 연속형 변수의 처치효과가 결과에 비선형적인 관계를 가지는 경우를 생각해볼 수 있다. Figure 1.4a가 바로 그런 경우이다. Figure 1.4a와 Figure 1.4b 모두 같은 데이터를 예측하지만 처치 효과의 관계가 선형적이냐, 비선형적이냐에 따라 다른 기대를 가지고 있는 모델이다. 혹은 모델 내 서로 다른 예측변수들 간의 함수적 관계에 따라 처치효과가 다르게 나타나는 상호작용(interactions)을 모델에 포함할 것을 고려해볼 수 있다. Figure 1.5: Lifetime added risk of lung cancer for men, as a function of average radon exposure in picocuries per liter (pCi/L). The relation between cancer rate and radon is different for smokers and nonsmokers. Figure 1.5은 라돈 가스가 남성의 폐암 발병률에 미치는 효과를 추정한 것을 보여준다. 라돈은 폐암을 발병시키고, 그 효과는 비흡연자에 비해 흡연자들에게서 더 크게 나타난다. 이 모델은 라돈의 효과가 선형적이라고 가정하며 동시에 흡연과 상호작용할 것이라는 가정을 하고 있다. 1.4.2 Regression to adjust for differences between treatment and control groups 현실의 인과추론의 문제에서 처치와 통제가 이루어지는 피험체(experimental units) 간에는 체계적 차이(systematic difference)가 존재한다.2 Figure 1.6은 가상으로 만든 데이터와 그에 적합하는 선형회귀모델을 시각화한 것이다. Figure 1.6은 다음과 같이 요약할 수 있다. 처치를 받은 단위의 평균은 \\(\\bar{y}=31.7\\)로 통제된 단위의 평균인 \\(\\bar{y}=25.5\\)에 비해 4.8 포인트 높았다. 그러나 두 집단은 처치가 이루어지기 이전의 예측변수에 있어서 차이를 보였다: 예측변수, \\(x\\)의 평균인 \\(\\bar{x}\\)는 처치군에서는 0.4였고, 통제군에서는 1.2였다. 이러한 차이를 조정한 이후에는 처치효과가 10.0이라고 추정할 수 있었다. 따라서 주요 예측변수에 있어서 처치/통제 단위 간 불균형(imbalance)이 존재한다고 할 때에는 그 불균형을 어느 정도 조정(adjustment) 해주는 것이 필요하다. Figure 1.6: Hypothetical data with a binary treatment and a continuous pre-treatment variable. Treated units are displayed with circles on the scatterplot, and controls are shown with dots. Overlaid is a fitted regression predicting the outcome given treatment and background variable, with the estimated treatment effect being the difference between the two lines. 1.4.3 Interpreting coefficients in a predictive model 회귀모델은 일종의 예측모델이지만 만약 모델 내에 포함된 오차(errors)가 클 경우에는 무언가를 예측하는 것에는 거의 무용하다(useless). 다만 회귀모델은 추정된 기울기(estimated slope)를 통해 관측된 데이터의 변수들 간의 관계 양상을 탐색하는 것에 유용하다. 오차를 포함하더라도 그 관계가 정(positive)인지 부(negative)인지에 대한 패턴을 보여주기 때문이다. 또한 회귀모델은 표집(sampling)을 통한 추론이기 때문에, 우리는 회귀모델을 적합한 표본(sample)이 우리가 알고자 하는 모집단(population)에 대해 대표성을 가질 것이라고 기대하고 그 결과를 모집단 수준에서 직접적으로 해석할 수 있다. 혹은 표본과 모집단 간의 간극을 좁히기 위해 모델에 추가적인 예측변수들을 포함할 수도 있다. 여기서 알 수 잇는 것은 첫째, 표본이 대표성을 가지지 못한다면 표본을 통해 얻은 결과를 모집단 수준에서 해석하는 것에서 왜곡이 일어날 수 있다는 것, 둘째는 예측변수들을 추가함으로써 우리는 표본과 모집단 간의 간극을 좁힐수도 있지만 동시에 잘못된 예측변수를 추가하게 되면 그 간극이 오히려 넓어질수도 있다는 것이다. 회귀모델을 인과추론으로 해석하는 것이 일견 자연스러워 보이지만 모델 안에 포함되어야 하지만 우리가 관측하지 못해 포함하지 못한 변수들(lurking variables or confounders)이 존재할 수 있기 때문에 회귀모델은 완벽한 통제(control)가 이루어진다고 볼 수 없다. 따라서 회귀모델을 통해 인과추론을 하는 것에는 주의가 필요하다. 1.4.4 Building, interpreting, and checking regression models 통계분석은 다음과 같은 네 단계를 거쳐서 수행된다: \\(y = \\alpha + \\beta x + \\mathrm{error}\\)의 형태로 단순선형모델로 시작해 추가적인 예측변수들(\\(x_2\\cdots x_n\\)), 상호작용, 그리고 변형된 변수(transformations)들을 추가하는 것으로 확장되는 모델 구축(model building) 단계. 데이터 조작(data manipulation), 프로그래밍, 그리고 회귀계수와 불확실성을 추정하고 확률적 예측을 하기 위한 알고리즘의 사용을 포함한 모델 적합(model fitting) 단계. 그래픽과 프로그래밍, 그리고 측정지표와 모수, 그리고 연구 기저에 놓인 목적 간의 (불완전한) 관계를 적극적으로 조사하는 모델 등의 적합도(model fit)을 이해하는 단계. 모델을 발전시키기 위한 방향을 고민하고 비판하는 단계. 어떠한 연구도 완벽하지 않다(No study is perfect). 1.5 Classical and Bayesian inference GHV는 기본적으로 베이지안 추론을 사용하지만, 이 리딩노트는 기본적으로 빈도주의적 접근을 취하고자 한다. 하지만 이 장에서의 베이지안 추론의 소개는 알아둘만한 것이기에 간단히 정리한다. 통계를 하는 사람으로서 우리는 데이터에 모델을 적합하고 그 모델을 이용해 예측하는 데 많은 공을 들인다. 그리고 이러한 단계들은 방법론적, 철학적 이론틀에 바탕을 두고 있다. 전통적인(빈도주의적인) 분석틀과 베이지안 분석틀 모두가 취하고 있는 공통적인 접근법으로는: (1) 추정(estimation) 과정에 어떠한 정보(information)가 사용되는가, (2) 어떤 가정(assumptions) 하에서 이루어지는가, (3) 추정치와 예측값을 어떻게 해석(interpretation)하는가 등이 있다. 1.5.1 Information 어떤 회귀모델이던간에 결과변수(종속변수), \\(y\\)와 하나 이상의 예측변수, \\(x\\)에서 시작한다. 데이터 그 자체에 더해 우리는 데이터가 어떻게 수집되는지에 대한 정보도 필요하며, 데이터의 가용성 여부에 대한 정보도 필요하다. 마지막으로 우리는 지금 당장 가지고 있는 데이터뿐 아니라 이전의 경험, 유사한 연구 등을 바탕으로 일종의 사전적 지식(prior knowledge)을 가지게 된다. 그리고 연구에 있어서 이러한 정보들을 어떻게 반영하는가, 모델에 포함시키는가는 주위해야한다. 예를 들어, 기게재된 연구논문들은 “통계적 유의성”을 보이는 결과, 혹은 큰 효과를 보이는 결과를 선별적으로 보여주어야 출판될 수 있다는 압박에 효과를 과다추정하는 경향을 보일 수 있다. 이 경우, 데이터가 충실하지 않고, 사전적 지식이 없다면 말이 되지 않는 결론을 도출할 수 있다. 1.5.2 Assumptions 예측변수 \\(x\\)와 결과변수 \\(y\\)에 대한 회귀모델에는 약 세 가지 핵심적인 가정이 필요하다. \\(x\\)와 \\(y\\)의 관계에 대한 함수적 형태에 관한 가정이 필요하다. 데이터가 어디서 오는가에 대한 가정이 필요하다. 다른 책이나 연구논문에서는 데이터 생성과정(Data Generating Process; DGP)이라고도 한다. 기본적으로는 표본으로 우리가 확보하게 될 데이터의 (결코 관측될 수 없는) 모집단이 어떻게 생겨먹었나에 대한 가정이라고 할 수 있다. 측정된 데이터가 과연 실제 현실세계에 대한 적절성(relevance)을 가지는가에 대한 가정이 필요하다. 1.5.3 Classical inference 빈도주의적 접근(frequentist approach)이라고도 한다. 사전적 정보가 아닌, 우리가 관측하여 확보한 데이터의 정보를 요약하고 가급적 편향되지 않고 분산 정도가 적은 추정치와 예측치를 얻고자 하는 데 그 목적이 있다. 그리고 당연히 표본을 통해 추론하는 것이니 만큼, 표본을 얻는 데 필연적으로 포함되는 불확실성이 존재한다. 1.5.4 Bayesian inference 베이지안 추론은 단순히 존재하는 데이터를 요약하는 것을 넘어 사전적 정보를 포함하여 추론하는 접근법이다. 예컨데, 만약 선행연구가 어떠한 경험적 연구를 축적해 와서 핵심 예측변수가 결과변수에 미치는 평균적 효과에 대한 “사전적 정보”가 존재한다고 할 때, 그 사전적 정보를 이용하여 사후에 얻은 데이터에 반영, 사후 분포(post distribution)를 추정하는 방법인 것이다. 장점: 보다 합당한 결과를 확인할 수 있으며, 미래의 결과/미래 실험의 결과에 대해 직접적인 예측이 가능하다. 단점: 사전 분포(prior distribution)라고 하는 추가적인 정보가 필요하다. 전통적 추론은 예측값으로 한정되는 데이터의 요약을 보여줄 수 있다면, 베이지안 추론은 관측된 데이터가 빈약하더라도 추가적인 가정에 의존하여 이론으로부터 타당한 예측을 도출할 수 있다.–절대적으로 옳은 한 가지 방법이 있는 것은 아니다. 1.6 Computing least squares and Bayesian regression 베이지안 접근법과 시뮬레이션 접근법은 정규화(regularized) 선형회귀모델이나 멀티레벨 모델을 적합할 때 보다 중요하다.3 References "],["data-and-measurement.html", "Chapter 2 Data and Measurement 2.1 Examining where data come from 2.2 Validity and reliability 2.3 All graphs are comparisons 2.4 Data and adjustment: trends in mortality rates", " Chapter 2 Data and Measurement 모델을 적합하기에 앞서, 모델에 사용할 데이터와 측정지표를 탐색하고 이해할 필요가 있다. 2.1 Examining where data come from ## Error in select(., state, hdi, hdi_rank = rank, canada_dist = canada.dist): unused arguments (state, hdi, hdi_rank = rank, canada_dist = canada.dist) ## Error in select(., state = st_state, state_abbr = st_stateabb, income_2000 = st_income): unused arguments (state = st_state, state_abbr = st_stateabb, income_2000 = st_income) ## Error in loadNamespace(x): &#39;ussf&#39;이라고 불리는 패키지가 없습니다 ## Error in left_join(., hdi %&gt;% mutate(state = str_replace(state, &quot;Washington, D.C.&quot;, : object &#39;us&#39; not found ## Error in ggplot(.): object &#39;us_hdi&#39; not found Figure 2.1: Graphing the Human Development Index versus average income by state: (a) scatterplot of the data, (b) scatterplot of ranks. Figure 2.1은 Human Development Index (HDI)를 워싱턴 DC와 50개 주를 비교한 지도이다. 이 지도가 우리가 생각하는 주들 간 공중보건 수준을 현실적으로 반영하고 있을까? HDI는 세 가지 차원으로 측정된다: 기대수명(life expectancy) 성인 문해율(adult literacy rate)과 초중고등 교육 등록률(primary, secondary, and tertiary gross enrollment ratio) 구매력을 기준으로 한 일인당 국내총생산(GDP)에 자연로그를 취한 값: 생활 수준(standard of living) 즉, HDI는 위의 세 지표를 결합한 것이기 때문에 역으로 특정 지표의 값이 높지만 나머지 지표의 값이 낮은 주와 평균적으로 세 지표 모두를 중간 수준의 값으로 가지는 주 간의 차이를 구분하지 못할 수 있다는 것이다. Figure 2.2는 HDI와 주들 간 평균 소득 수준을 비교한 플롯이다. Figure 2.2a는 두 변수 간 관계가 강하지만 비선형적이라는 것을 보여주며, Figure 2.2b는 평균 소득 순위와 HDI 순위 간 관계가 매우 선명한 선형 관계를 가지고 있다는 것을 보여주고 있다. 이 예시는 다른 방법으로 그래프를 그림으로써 데이터를 더 잘 이해할 수 있다는 것을 보여준다. 2.1.1 Details of measurement can be important 미국정치는 거대 양당에 의해 주도되고 있지만 이념적 스펙트럼에 있어서는 그 강도에 따라 세분화할 수 있다. 그러나 당파성과 이념적 척도는 동일하지 않다. Figure 2.3a는 자기이념에 있어서 진보-중도-보수의 비율이 모든 소득 수준에서 비슷한 것으로 나타난다. Figure 2.3b는 당파성에 있어서 소득 수준이 적어도 2008년 기준으로는 공화당 당파성과 강한 관계가 있음을 보여준다. 회귀모델은 데이터를 요약하고, 데이터로부터 추론을 도출하는 방법이다. 따라서 회귀모델은 분석하고자 하는 데이터의 질(quality of data)과 연구문제에 대한 데이터의 적실성에 좌우된다. 측정지표와 현실 간 간극은 과학적 연구에 있어서 일반적인 문제이다. Figure 2.2: Distribution of (a) political ideology and (b) party identification, by income, from a survey conducted during the 2008 U.S. election campaign. 2.2 Validity and reliability 측정은 두 가지 이유에서 중요하다. 우리는 실제로 데이터가 무엇을 의미하는지 이해해야 한다. 이를 위해 데이터를 시각화하고, 데이터로부터 필요한 정보를 추출하는 노력이 필요하다. 정확성, 신뢰성, 그리고 타당도는 분산(variance), 상관관계(correlation), 그리고 오차 등을 이해하는 데 중요한 기초이다. 2.2.1 Validity 타당도란 “측정하고자 하는 것을 보여주는 정도”를 의미하며, 가능한 범주에서 평균적으로 정확한 답을 찾아낼 수 있도록 측정하는 과정이라고 할 수 있다. 즉, 어떤 측정지표가 측정하고자 하는 것을 제대로 측정하느냐의 문제라고 할 수 있다. 2.2.2 Reliability 신뢰도란 정확하고 안정적인 측정지표의 특성을 말한다. 우리가 무언가를 측정할 때, 그것을 여러번 측정하더라도 비슷하게 측정될 때, 신뢰도를 확보했다고 할 수 있다. 2.2.3 Sample selection 데이터 선정(selection)은 관측할 수 없는 모집단의 표본이 모집단을 잘 대표하지 못할 수도 있다는 문제를 의미한다. 물론 연구목적에 따라서 특정한 표본을 선정해야하는 경우도 있기 때문에 항상 특정한 기준으로 선택된 표본이 문제라고는 할 수 없다. 2.3 All graphs are comparisons 2.3.1 Simple scatterplots Figure 2.4는 보건지출과 기대수명 간의 관계를 보여주는데, 미국이 다른 국가에 비하여 그다지 기대수명에 눈에 보이는 진전이 나타나지 않는데도 불구하고 높은 수준의 일인당 보건지출을 하고 있다는 것을 확인할 수 있다. Figure 2.3: Health care spending and life expectancy in several countries. This scatterplot shows two things: the generally positive correlation between spending and lifespan, and the extreme position of the United States. 2.3.2 Displaying more information on a graph 이 산포도는 \\(x\\), \\(y\\), 그리고 그 두 축 위에 놓인 고나측치를 통해 측정 전 후의 처치와 통제 간의 결과를 비교하는 플롯이다. 연달아 있었던 선거의 두 해를 대상으로 지역구가 특정한 한 정당에 편향적으로 우호적인지를 보여주는 당파성 편향(partisan bias)을 추정한 결과를 보여준다. 분석단위: 미국의 주 의회 선거(state legislative election) 처치(treatment): 서로 다른 선거구 재획정 계획(redistricting plan) 통제: 선거구 제획정이 일어나지 않았던 두 선거의 관측치들(지역구들) Figure 2.5에서 상호작용은 데이터를 해석하는데 매우 중요하다. 선거구 재획정이 없으면, 당파성 편향은 체계적으로 변화하지 않는다. 선거구 재획정의 가장 큰 효과는 당파성 편향을 0에 보다 가깝게 만든다는 것이다. 이처럼 시각화한 결과는 우리가 가진 데이터의 정보를 직관적으로 이해하도록 돕는다. Figure 2.4: Effect of redistricting on partisan bias in U.S. state legislative elections. Each symbol represents a state and election year, with solid circles, open circles, and crosses representing Democratic, bipartisan, and Republican redistricting, respectively. The small dots are the control cases&lt;U+2014&gt;state-years that did not immediately follow a redistricting. Lines show fit from a regression model. Redistricting tends to make elections less biased, but small partisan biases remain based on the party controlling the redistricting. 2.3.3 Multiple plots 데이터를 기대하지 않은 방식으로 바라보는 것도 때로는 새로운 것을 발견하는 단초가 될 수 있다. 자세한 내용은 GHV의 27-28 페이지의 예제를 참고. 간단히 말하면, 데이터를 가지고 여러 플롯으로 쪼개서 다각적으로 살펴보면 새로운 것을 발견할 수도 있다는 조언이다. Figure 2.5: Distribution of last letters of boys’ names from a database of American babies born in 1906, 1956m and 2006. Redrawn from a graph by Laura Wattenberg. Figure 2.6: Trends in percentage of boys’ names ending in each letter. This graph has 26 lines, with the lines for N, D, and Y in bold to show the different trends in different-sounding names. Compare to Figures 2.6 and 2.7, which show snapshots of the last-letter distribution in 1906, 1956, and 2006. Figure 2.7: Trends in concentration of boys’ and girls’ names. In the late 1800s, and then again at different periods since 1950, there have been steep declines in the percentage of babies given the most popular names, so that now the top 10 names of each sex represent only about 10% of baby names. Thus, even as the sounds of boys’ names have become more uniform (as indicated by the pattern of last letters shown in Figure 2.6), the particular names chosen have become more varied. 2.3.4 Grids of plots 산포도는 두 개의 연속형 변수, \\(y\\)와 \\(x_1\\) 간의 관계를 보여준다. 만약 \\(x_2\\)라는 추가적인 변수가 있고, 이것이 이산형(discrete)라고 하면 산포도에서 점의 색 등을 \\(x_2\\)의 카테고리별로 다르게 출력하는 등으로 보여줄 수 있다. \\(x_2\\)가 연속형일 경우도 색의 진하기로 표현할 수 있지만, 시각적으로 뚜렷하게 구분하기가 어려워 추천하지는 않는다. 또는 \\(x_2\\), \\(x_3\\) 등을 추가적인 기준점으로 산포도 자체를 세분화해 쪼개는 방법(grid)이 있다(small multiples). Figure 2.9에서도 확인할 수 있듯, 산포도를 통해 우리는 연속형 종속변수인 \\(y\\)를 연속형 예측변수인 \\(x_1\\)과 대응되도록 그래프를 그린 후, 이산형 예측변수인 \\(x_2\\), \\(x_3\\), \\(x_4\\)를 레이어를 덧씌우듯 (마커에 색을 추가하는 등) 시각화할 수 있다. 또한, 각각의 플롯에 \\(x_2, \\cdot x_4\\)의 예측변수들의 서로 다른 고정된 값에서 \\(x_1\\)와 \\(y\\) 간의 함수적 관계에 따른 \\(y\\)의 기대값을 보여주는 예측선을 그리는 것 등도 가능하다. ## Error in select(., state_code, district_code, d_prop_prev = d_prop): unused arguments (state_code, district_code, d_prop_prev = d_prop) ## Error: Problem with `filter()` input `..3`. ## i Input `..3` is `abs(d_prop - 0.5) &lt; 0.3 &amp; abs(d_prop_prev - 0.5) &lt; 0.3`. ## x object &#39;d_prop_prev&#39; not found ## Error: At least one layer must contain all faceting variables: `period`. ## * Plot is missing `period` ## * Layer 1 is missing `period` ## * Layer 2 is missing `period` ## * Layer 3 is missing `period` Figure 2.8: Swings in U.S. congressional elections in three different periods. This grid of plots demonstrates how we can display an outcome (in this case, the swing toward the Democrats or Republicans between two elections in a congressional district) as a function of four predictors: previous Democratic vote share, incumbency status (gray for incumbents running for reelection, black for open seats), region of the country, and time period. Uncontested and landslide elections have been excluded. 2.3.5 Applying graphical principles to numerical displays and communication more generally 데이터를 분석할 때는 그 결과를 읽는 독자의 입장 또한 생각해야한다. 독자의 입장에서 괜히 부담되는 불필요한 정보를 과다하게 전달할 필요는 없다. 예컨대, 숫자의 소수점도 일정 부분에서 반올림하여 읽는 사람이 직관적으로 이해할 수 있도록 도울 필요가 있다. 불확실성을 보여주는 구간 [3.276, 6.410]은 [3.3, 6.4]라고 적더라도 그 실질적 의미는 훼손되지 않으며 보는 사람 입장에서는 더 간결하다. 그리고 통계적 결과들을 그래프로 보여주는 것은 가독성을 높여준다. 단, 설명할 수 없는 그래프를 굳이 보여줄 필요는 없다. 모든 그래프에는 제목(caption)을 달아야 한다. 2.3.6 Graphics for understanding statistical models 통계분석에서 그래프는 크게 세 부분에서 유용하다. 원 데이터(raw data)를 보여주는, 이른바 “탐색적 분석”에 용이하다. 예측 모델과 추론에 있어서 그래프는 모델의 적합도를 파악하는데 도움을 준다. 예측 모델을 통해서 재생산된 데이터를 시뮬레이션해서 원 데이터와 비교하는 그래프를 그려서 보여줄 수도 있다. 최종 결과물을 그래프로 보여줄 수 있다. 그래프를 그리는 목적은 연구자 본인과 연구를 읽는 대상 간의 소통을 용이하게 하기 위해서이다. 2.3.7 Graphs as comparisons 모든 시각화된 그래프는 일종의 비교를 위한 수단이라고 볼 수 있다. 2.3.8 Graphs of fitted models 적합된 모델과 데이터를 동일한 플롯에 함께 그리는 것이 유용할 수 있다. 예를 들어, 실제 데이터와 우리가 시뮬레이션을 이용해서 예측한 값들의 관계를 함께 보여주면 우리가 가설적으로 수립한 관계가 관측된 데이터들에서도 그 양상이 나타나는지를 파악하기가 용이하다. 2.4 Data and adjustment: trends in mortality rates GHV는 사망률(mortality rates)의 예제를 통해 특정 연령집단에서의 집합적인 사망률의 증가가 45세부터 54세 연령 집단의 구성이 1990년부터 2013년 사이에 크게 변화하였기 때문인지를 분석한다. 만약 45세부터 54세 연령집단의 구성이 시간에 따라 변화하여 사망률의 차이가 나타났다면, 그 집단의 시간에 따른 사망률의 변화는 연령에 특정한 사망률의 변화는 반영하고 있지 않는다고 볼 수 있다. 즉, 연도-시간의 변화가 주요 요인이라면 45세부터 54세라는 이 중장년층이라는 연령 자체의 특정한 효과는 사망률의 변화에 큰 영향을 미치지 않앗을 것이라고 볼 수 있다는 것이다. 이를 확인하기 위해서 GHV는 이 연령 집단의 순수한 사망률의 변화도 보고, 평균 연령의 변화, 나아가 그 두 패턴을 비교해본다. Figure 2.10이 바로 그것이다. Figure 2.10은 해당 연령 집단의 사망률 변화를 이해하기 위해서는 연령에 대한 조정이 필요하다는 것을 보여준다(연령 그 자체가 사망률에 영향을 미칠 수 있음). 왜냐면 시간적 추이에 따라서 사망률이 계속 증가하는 것은 맞지만 동시에 평균 연령도 증가하고 있기 때문에 평균연령의 증가가 사망률의 증가로 이어졋을 가능성을 배제할 수 없기 때문이다. ## Error in select(., !c(year, deaths, population)): unused argument (!c(year, deaths, population)) Figure 2.9: (a) Observed increase in raw mortality rate among 45-to-54-year-old non-Hispanic whites, unadjusted for age; (b) increase in average age of this group as the baby boom generation moves through; (c) raw death rate, along with trend in death rate attributable by change in age distribution alone, had age-specific mortality rates been at the 2013 level throughout. Figure 2.11a은 연령에 대해 조정한 경향성이 그다지 사망률의 증가에 민감한 영향을 미치지 않는다는 것을 보여준다. 반면에 성별로 연령대별 조정한 사망률을 분리해서 살펴보면 Figure 2.11b와 같은 결과를 얻을 수 있는데, 1999년부터 2013년까지 여성의 사망률이 증가한 반면, 남성의 사망률은 1999년부터 2005년까지 증가하지만 2005년부터 2013년까지는 반전하는 것을 확인할 수 있는 것이다. 이처럼 데이터가 가지고 있는 정보는 그것을 어떻게 집약(aggregation)하고, 또는 해체(disaggregation)하느냐에 따라서 다른 결과를 보여줄 수 있다. ## Error in select(., !c(year, deaths), weight = population): unused arguments (!c(year, deaths), weight = population) ## Error in select(., !c(year, deaths), weight = population): unused arguments (!c(year, deaths), weight = population) Figure 2.10: (a) Age-adjusted death rates among 45-to-54-year-old non-Hispanic whites, showing an increase from 1999 to 2005 and a steady pattern since 2005; (b) comparison of two different age adjustments; (c) trends in age-adjusted death rates broken down by sex. The three graphs are on different scales. 마지막으로 Figre 2.12는 셩별에 따른 미국의 지역별 연령 조정된 사망률의 추이를 보여주는데, 특기할 것은 남부 지역의 여성의 사망률이 눈에 띄는 증가세를 보인다는 점이다. 반면에 두 성별 모두 북동부에서는 사망률이 감소하는 모습을 보였고, 가장 낮은 추이를 보였다. 이같은 일련의 그래프들은 데이터 탐색(data exploration)이 얼마나 중요한지를 보여준다. Figure 2.11: Age-adjusted death rates among 45-to-54-year-old non-Hispanic white men and women, broken down by region of the country. The most notable pattern has been an increase in death rates among women in the South. In contrast, death rates for both sexes have been declining in the Northeast. The graphs are on different scales; as can be seen from the y-axes, death rates are lower for women than for men. "],["some-basic-methods-in-mathematics-and-probability.html", "Chapter 3 Some Basic Methods in Mathematics and Probability 3.1 Weighted averages 3.2 Vectors and matrices 3.3 Graphing a line 3.4 Exponential and power-law growth and decline; logarithmic and log-log relationships 3.5 Probability distributions 3.6 Probability modeling", " Chapter 3 Some Basic Methods in Mathematics and Probability 회귀모델에 있어서 기초적인 수리통계학적 기법들을 숙지하는 것은 약 세 가지 측면에 있어서 중요하다. 선형대수(linear algebra)와 간단한 확률분포는 정교한 모델의 토대가 된다. 모델들을 들여다보기에 앞서 추론에 대한 기본적인 개념들을 이해하는 것은 유용하다. 때로는 정교한 모델을 적합하기 이전에 연구문제의 일부에 대해 빠르게 비교 및 추정해보는 것은 모델 결과를 이해하는 데 유용하다. 3.1 Weighted averages 통계학에서 연구하고자 하는 모집단(target population)에 맞추기 위하여 데이터 또는 추론에 어떠한 가중치를 부여하는 것은 흔한 일이다. 간단한 예로, 2010년에 북미에 거주하는 4,560만명 중 3억 1000만명은 미국에, 1억 1200만명은 멕시코에, 3,400만명은 캐나다에 거주하는 사람이었다고 하자. 해당 연도에 각 국가에 거주하는 사람들의 평균 연령은 Table 3.1에서 확인할 수 있다. 그리고 모든 북미 거주자의 평균연령은 가중평균(weighted average)이다. \\[ \\begin{align*} \\text{average age} &amp; = \\frac{310{,}000{,}000 \\cdot 36.8 + 112{,}000{,}000 \\cdot 26.7 + 34{,}000{,}000 \\cdot 40.7}{310{,}000{,}000 + 112{,}000{,}000 + 34{,}000{,}000} \\\\ &amp; = 34.6. \\end{align*} \\] 단순평균이 아니라 가중평균이라고 하는 이유는 각 국가의 인구에 가중치(weights), 36.8, 26.7, 40.7, 를 비례하여 곱해주었기 때문이다. 북미의 전체 인구는 \\(310 + 112 + 34 = 456\\), 즉 4억 5,600만명이고, 우리는 위의 식을 다음과 같이 바꾸어 쓸 수 있다. \\[ \\begin{align*} \\text{average age} &amp; = \\frac{310{,}000{,}000}{456{,}000{,}000} \\cdot 36.8 + \\frac{112{,}000{,}000}{456{,}000{,}000} \\cdot 26.7 + \\frac{34{,}000{,}000}{456{,}000{,}000} \\cdot 40.7 \\\\ &amp; = 0.6798 \\cdot 36.8 + 0.2456 \\cdot 26.7 + 0.0746 \\cdot 40.7 \\\\ &amp; = 34.6. \\end{align*} \\] 위의 식에서 나타난 비율, 0.6798, 0.2456, 그리고 0.0746의 총합은 1이며, 이들 각각은 가중평균에서 각 국가들에 대한 가중치를 의미한다. 위와 같은 가중평균을 구하는 식은 다음과 같이 축약할 수 있다. \\[\\text{weighted average} = \\frac{\\sum_j N_j \\bar y_j}{\\sum_j N_j},\\] 이때, \\(j\\)는 국가를 나타내며 가중평균을 구하기 위해서 우리는 각 층위(strata), 여기서는 각 국가 단위에서의 연령의 합을 구해주어야 한다. Table 3.1: Populations and average ages of countries in North America. (Data from CIA World Factbook 2010.) The average age of all North Americans is a weighted average of the average ages within each country. Stratum Label Population Average age 1 United States 310 million 36.8 2 Mexico 112 million 26.7 3 Canada 34 million 40.7 3.2 Vectors and matrices 일련의 숫자들의 모임(a list of numbers)을 벡터(vector)라고 한다. 동시에 숫자를 이차원으로 배열한 것(a rectangular array of numbers)은 행렬(matrix)라고 한다. Section 1.2에서 선거 직전 해의 경제적 조건에 따른 미국 대선의 집권당 투표율 예측 예시를 떠올려보자. \\[ \\begin{align*} \\text{predicted vote percentage} &amp; = 46.3 + 3.0 \\cdot (\\text{growth rate of average personal income}) \\\\ \\hat y &amp; = 46.3 + 3.0 x \\\\ \\hat y &amp; = \\hat a + \\hat b x, \\end{align*} \\] 이때 \\(\\hat a\\)와 \\(\\hat b\\)는 데이터로부터 적합하여 추정해낸 추정값(estimates)을 의미하며, \\(\\hat y\\)는 예측값(predicted value)을 보여준다. 위의 예제에서 \\(y\\)는 실제 선거 결과를 의미한다. \\(\\hat y\\)는 모델의 예측 결과를 나타낸다. 이제 이 모델을 몇 가지 특수한 사례들에 적용해보자. \\(x = -1\\). 경제성장률이 -1%일 때, 모델에 따르면 집권당의 득표율은 \\(46.3 + 3.0 * (-1) = 43.3%\\)가 된다. \\(x = 0\\). 경제성장률이 0%, 즉 전혀 성장하지 않았을 때에는 \\(46.3 + 3.0 * 0 = 43.3%\\)가 된다. \\(x = 3\\), 약 3%의 경제성장률은 집권당 후보가 이길 수 있는 \\(46.3 + 3.0 * 3 = 55.3%\\)의 득표율로 이어질 것이다. Table 3.2: Special cases for the model a_hat b_hat x formula y_hat 46.3 3 -1 46.3 + 3 * -1 43.3 46.3 3 0 46.3 + 3 * 0 46.3 46.3 3 3 46.3 + 3 * 3 55.3 위의 적용은 벡터로도 나타낼 수 있다. \\[\\hat y = \\begin{bmatrix} 43.4 \\\\ 46.3 \\\\ 55.3 \\end{bmatrix} = \\begin{bmatrix} 46.3 + 3.0 \\cdot (-1)\\\\ 46.3 + 3.0 \\cdot 0 \\\\ 46.3 + 3.0 \\cdot 3\\end{bmatrix},\\] 마찬가지로 행렬로도 나타낼 수 있다. \\[\\hat y = \\begin{bmatrix} 43.4 \\\\ 46.3 \\\\ 55.3 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; -1 \\\\ 1 &amp; 0 \\\\ 1 &amp; 3 \\end{bmatrix} \\begin{bmatrix} 46.3 \\\\ 3.0 \\end{bmatrix},\\] 혹은 더 축약하여 다음과 같이 나타낼 수 있다. \\[\\hat y = X \\hat \\beta,\\] 이때 \\(y\\)와 \\(x\\)는 길이가 3인 벡터가 된다.4 이때, \\(X\\)는 \\(3\\times 2\\)의 행렬이 되며, 1 세개는 각각의 \\(x\\) 사례에서 모델에 포함될 절편을, 그리고 다른 하나의 열은 세 \\(x\\) 값을 가지게 된다. \\(\\hat \\beta = (46.3, 3.0)\\)은 추정된 계수값의 벡터이다. 즉, \\(\\hat y = X \\hat \\beta,\\)은 일종의 회귀모델의 개념으로 \\(\\text{예측값} = \\text{주어진 관측값}\\times\\text{모델로 추정한 계수값}\\)으로 구성된다고 이해할 수 있다. 3.3 Graphing a line 선형회귀모델을 효과적으로 사용하기 위해서는 회귀모델로 인해 그리는 직선에 대한 대수학(algebra)와 기하학(geometry)적 논리를 이해하는 것이 필요하다. Figure 3.2는 \\(y = a + bx\\)에 대한 선을 보여준다. 절편(intercept), \\(a\\)는 \\(x\\)가 0일 때의 \\(y\\)의 값이다. 계수값(coefficient), \\(b\\)는 직선의 기울기(slope)를 의미한다. \\(b&gt;0\\)이면 기울기가 우상향하고 우리는 이 관계를 정의 관계(positive)라고 서술한다. \\(b&lt;0\\)이면 기울기가 우하향하고 우리는 이 관계를 부의 관계(negative)라고 서술한다. \\(b=0\\)이면 기울기는 수평해지며, 이때 우리는 \\(x\\)와 \\(y\\)의 관계가 독립적이라고 볼 수 있다. 왜냐하면 \\(x\\)가 어떤 값을 취하던 \\(y\\)는 항상 일정하기 때문(변하지 않기 때문)에 \\(x\\)가 \\(y\\)에 어떠한 영향을 미친다고 볼 수 없기 때문이다. 기울기 값의 절대값이 클수록 그 관계 양상은 심화되며, 기울기는 가팔라진다. Figure 3.1: Lines y = a + bx with positive and negative slopes. Figure 3.3a는 \\(y = 1007-0.39x\\)라는 수리적 예제에 대한 시각화 결과이다. 이 식은 \\(x\\)가 0일 때 \\(y\\)는 1007이며, \\(y\\)는 \\(x\\)의 한 단위가 증가할 때마다 0.39씩 감소한다는 것을 의미한다. 이 선은 1900년부터 2000년까지 세계 1마일 달리기 애회의 기록과 개략적으로 일치한다(Figure 3.3b). Figure 3.2: (a) The line y = 1007 &lt;U+2212&gt; 0.393x. (b) For x between 1900 and 2000, the line y = 1007 &lt;U+2212&gt; 0.393x approximates the trend of world record times in the mile run. Compare to Figure A.1. 물론 이 결과는 실제 값과는 다르다. 왜냐하면 \\(x\\)는 현실 세계에서 0일 수 없기 때문이다. 3.4 Exponential and power-law growth and decline; logarithmic and log-log relationships \\(y = a + bx\\)의 선은 로그변환(logarithmic transformations)을 통하여 보다 일반적인 관계 양상을 표현하는 데 사용될 수 있다. \\(\\log y = a+bx\\)는 기하급수적인(exponential) 성장(\\(b&gt;0\\)일 때)이나 침체(\\(b&lt;0\\))를 나타내며, \\(A = e^a\\)라고 할 때, \\(y = Ae^{bx}\\)로 나타낼 수 있다. \\(A\\)는 \\(x= 0\\)일때의 \\(y\\)의 값이다. \\(b\\)는 경제성장률 혹은 침체율의 그 비율(rate)을 결정하는 모수(parameter)이다. \\(x\\)의 한 단위 변화는 \\(\\log y\\)에 있어서의 \\(b\\)만큼의 추가적인 변화로 이어지며, 이는 곧 \\(y\\)가 \\(e^b\\)만큼 변화하는, 일종의 곱셈적 관계로 나타난다. 기하급수적(exponential)이라는 표현을 사용하는 이유는 그 관계가 선형, 직선의 형태로 서술되지 않기 때문이다. 로그 변환이 회귀모델 분석의 해석과 어떠한 관계가 있는지를 나타내기 위해 하나의 예제를 살펴보자. \\(y, x\\) 모두에 로그변환이 이루어진 상태로 다음과 같은 모델이 존재한다고 하자: \\[ \\log y = 1.4 + 0.74\\log x. \\] 우리는 양변의 로그를 모두 풀어줄 수도 있다. 이때, 위의 식을 변환하지 않은 척도의 \\(x\\)와 \\(y\\)로 나타내면 다음과 같다. \\[ \\begin{align*} e^{\\log y}&amp;=e^{1.4 + 0.74\\log x}\\\\ y&amp;=4.1x^{0.74}. \\end{align*} \\] 그리고 \\(x\\)와 \\(y\\)를 로그변환했을 때는 직선의 형태로 나타났던 관계가, 로그변환을 풀어주면 곡선의 관계로 바뀌게 된다. 당연히 해석하는 방식도 달라질텐데, 여기서 하나의 함의는 원래 비선형 관계인 \\(x\\)와 \\(y\\)를 로그변환 등을 통해 직선의 관계로 나타낼 수는 있지만 실질적 해석을 할 때에는 그 둘의 관계가 원래는 비선형이었다는 것을 염두에 두어야 한다는 것이다. 예를 들어, \\(\\log x\\)의 한 단위 증가가 \\(\\log y\\)의 \\(\\beta\\) 만큼의 증가로 이어진다라고 해석하면 누구도 쉽게 이해하지 못할 것이다. Figure 3.3: Fitted curve of metabolic rate vs. body mass of animals, on the log-log and untransformed scales. The difference from the elephant’s metabolic rate from its predictive value is relatively small on the logarithmic scale but large on the absolute scale. Figure 3.4: Fitted curve of metabolic rate vs. body mass of animals, on the log-log and untransformed scales. The difference from the elephant’s metabolic rate from its predictive value is relatively small on the logarithmic scale but large on the absolute scale. 3.5 Probability distributions 앞에서 기울기와 절편 등은 선형회귀모델의 예측에 있어서의 “결정주의적”(deterministic) 부분을 보여주는 것이었다면5, 여기서는 우리의 모델이 정확하게 데이터와 적합하지 않기에 필요한 확률분포와 확률변수라는 개념을 살펴본다. 확률분포는 현실 속 모델에 포함되지 않는 측면을 식에서 오차항(error term, \\(\\epsilon\\))으로 나타내며, 위에서 살펴본 모델은 \\(y = a + bx + \\epsilon\\)의 형태로 업데이트 될 수 있다. 그리고 이러한 불확실성은 우리가 데이터를 통해 어떠한 인과성 등을 추론하게 하는 원동력이 된다. 우리의 처치6는 일종의 개념적 정의와 수리적 공식이 결합된 것이기 때문에 확률분포에 대해 이해는 유용하다. 확률분포에 대한 적용은 다음과 같은 것들을 의미한다. \\(y_i, i = 1, \\dots, n\\)으로 나타낼 수 있는 데이터의 분포 \\(\\epsilon_i, i = 1, \\dots, n\\)으로 나타낼 수 있는 오차항의 분포 회귀모델에서 핵심적인 부분은 주어진 예측변수들의 조건 하에서 결과변수들의 값이 어떻게 분포되어 있는지를 살펴보는 것이다. 주어진 예측변수들의 조건 하에서 결과변수의 평균값을 예측한다. 예측값의 변동성(variation)을 요약(summarize)한다. 회귀모델에서 확률분포는 평균을 예측한 이후에 존재하는 분산을 특정하는데 사용된다. 즉, 확률분포란 우리의 예측이 어느 정도의 불확실성을 내포하는지를 추정하고자 하는 모수를 기준으로 보여주는 데 사용된다.7 3.5.1 Mean and standard deviation of a probability distribution 확률변수, \\(z\\)의 확률분포는 일정한 값의 범위를 가진다. 분포의 평균(mean)은 그 모든 범위 값의 평균(average)이다. 평균은 기대값(expected value)라고도 불리며, \\(E(z)\\) 또는 \\(\\mu_z\\)라고 쓸 수 있다.8 한편 확률변수 \\(z\\)의 분포에 대한 분산(variance)은 \\(E((z-\\mu_z)^2)\\)로 표현할 수 있으며, 각 관측치와 평균 간의 차이를 제곱한 것의 평균값이다. 분포의 변동성 정도에 따라서 \\(z\\)에 대한 표본추출된 값은 다를 수 있다. 변동성 정도에 따라서 \\(\\mu_z\\)를 기대하였지만 표본의 평균은 그보다 작거나 클수도 있고, 그 차이는 더 커질수도, 작아질수도 있다. 만약 변동성이 존재하지 않는다면, \\(z\\)의 분산은 0이라고 할 수 있다. Figure 3.5: (a) Heights of women, which approximately follow a normal distribution, as predicted from the Central Limit Theorem. The distribution has mean 63.7 and standard deviation 2.7, so about 68% of women have heights in the range 63.7 ± 2.7. (b) Heights of men, approximately following a normal distribution with mean 69.1 and standard deviation 2.9. (c) Heights of all adults in the United States, which have the form of a mixture of two normal distributions, one for each sex. 표준편차(standard deviation)는 분산에 제곱근을 취한 것이다. Figure 3.5a에서 여성 키의 표준편차는 2.7인치로, 이는 우리가 모집단에서 무작위로 여성들을 뽑아 표본으로 만들 경우, 그 관측된 값(확률분포), \\(z\\)에서 평균 키를 빼고 제곱을 취한 뒤 평균을 낸 것에 제곱근을 취한 결과라는 것이다. 즉, \\((z-63.7)^2\\)을 구한 뒤 평균을 내면 분산이 되고, 그 값이 7.3이라고 할 때, \\(\\sqrt{7.3} = 2.7\\)이 표준편차라고 할 수 있다. 정리하자면 표준편차는 관측치들이 평균적으로 평균으로부터 떨어져 있는 정도를 보여준다고 할 수 있다. 3.5.2 Normal distribution; mean and standard deviation Figure 3.6: Approximately 50% of the mass of the normal distribution falls within 0.67 standard deviations from the mean, 68% of the mass falls within 1 standard deviation from the mean, 95% within 2 standard deviations of the mean, and 99.7% within 3 standard deviations 확률의 중심극한정리(The Central Limit Theorem)는 소규모의 독립적인 확률 변수들의 총합이 정규분포(normal distribution)라 불리는 확률변수로 근사한다는 정리이다. 독립적인 각 요소들의 총합: \\(z = \\sum^n_{i=1}z_i\\) \\(z\\)의 평균: \\(\\mu_z =\\sum^n_{i=1}\\mu_{z_i}\\) \\(z\\)의 분산: \\(\\sigma_z = \\sqrt{\\sum^n_{i=1}\\sigma^2_{z_i}}\\) 수리적으로 정규분포는 \\(z\\sim \\mathrm{N}(\\mu_z, \\sigma^2_z)\\)라고 쓸 수 있다. 확률변수 \\(z\\)는 평균–\\(\\mu_z\\)와 분산–\\(\\sigma^2_z\\)를 가지는 분포라는 의미이다. 앞으로 평균 \\(\\mu\\)와 표준편차 \\(\\sigma\\)를 가지는 정규분포를 \\(\\mathrm{N}(\\mu, sigma^2)\\)라고 쓴다. 대략적으로 이 분포에 속한 값들의 50%는 \\(\\mu \\pm 0.67\\sigma\\)에 속하는 값의 범위에 떨어지게 된다. 약 68%에 해당하는 값들은 \\(\\mu \\pm \\sigma\\)의 범위 내에 속하게 되며, 95%의 값들은 \\(\\mu \\pm 2\\sigma\\)에, 99.7%의 값들은 \\(\\mu \\pm 3\\sigma\\)의 범위 내에 위치하게 된다(Figure 3.6 참고). 정규분포는 총합, 차이, 그리고 추정된 회귀계수 등을 평균 또는 가중평균 등의 수리적 표현으로 나타낼 수 있다는 점에서 유용하다. 3.5.3 Linear transformations 정규분포는 선형변환(linear tranformation)해도 여전히 정규성을 지닌다. 만약 \\(y\\)가 남성의 키를 인치로 나타낸 변수로 그 평균이 69.1이라고 하고 표준편차가 2.9라고 하자. 그러면 2.54 \\(y\\)는 센티미터로의 키를 의미하며, 평균은 \\(2.54*69 = 175\\)가 되며 표준편차는 \\(2.54*2.9 = 7.4\\)가 된다. 3.5.4 Mean and standard deviation of the sum of correlated random variables 평균이 \\(\\mu_u,\\mu_v\\)이고 표준편차가 \\(\\sigma_a, \\sigma_b\\)인 두 확률변수 \\(u\\)와 \\(v\\)가 있다고 하자. 이때, 이 두 변수의 상관관계(correlation)은 \\(\\rho_{uv} = \\mathrm{E}((u-\\mu_u)(v-\\mu_v))/(\\sigma_a\\sigma_b)\\)로 나타낼 수 있다. 그리고 상관관계는 \\([-1, 1]\\)의 범위 내에 존재하게 된다. 상관관계는 \\(u\\)와 \\(v\\)의 선형결합에 관한 정보를 제시한다. 두 변수의 합(\\(u+v\\))의 평균은 \\(\\mu_u + \\mu_v\\)로, 표준편차는 \\(\\sqrt{\\sigma^2_{u} + \\sigma^2_{v} + 2\\rho\\sigma_u\\sigma_v}\\)로 나타낼 수 있다. 일반적으로 가중치가 부여된 합(\\(au + bv\\))는 \\(a\\mu_u + b\\mu_v\\)를 평균으로, \\(\\sqrt{a^2\\sigma^2_{u} + b^2\\sigma^2_{v} + 2ab\\rho\\sigma_u\\sigma_v}\\)를 표준편차로 가진다. 마찬가지로 두 변수의 차이인 \\(u-v\\)의 평균은 \\(\\mu_u-\\mu_v\\)로, 표준편차는 \\(\\sqrt{\\sigma^2_{u} + \\sigma^2_{v} - 2\\rho\\sigma_u\\sigma_v}\\)이다. 3.5.5 Lognormal distribution 로그변환은 0이나 음수값을 취하는 것을 허용하지 않기 때문에 로그 척도로 확률변수를 변환할 경우 모두 양수값을 가지게 된다. Figure 3.7은 미국 내 남성들의 로그를 취한 몸무게와 몸무게의 원변수의 분포를 각기 보여준다. Figure 3.7: Weights of men (which approximately follow a lognormal distribution, as predicted from the Central Limit Theorem from combining many small multiplicative factors), plotted on the logarithmic and original scales. 3.5.6 Binomial distribution 농구에서 20발의 슛을 쐈다고 하고, 성공률이 0.3이며 각각의 슈팅은 서로 독립적이라고 가정하자. 그러면 우리는 \\(n=20\\)에 \\(p=0.3\\)인 이항분포(binomial distribution)이며, \\(y\\sim \\mathrm{binomial(n, p)}\\)로 나타낼 수 있다. \\(n\\), \\(p\\)의 모수를 갖는 이항분포는 \\(np\\)를 평균으로, \\(\\sqrt{np(1-p)}\\)를 표준편차로 갖는다. 3.5.7 Poisson distribution 포아송 분포는 암발병 환자의 수나 웹사이트 방문자 수와 같은 횟수와 관련된 카운트 데이터에 사용되는 분포이다. 정치학 분야에서는 전쟁 횟수 등과 같은 종속변수를 분석하기 위해 사용될 수 있다. 3.5.8 Unclassified probability distribution 실제 데이터가 항상 특정한 확률 분포와 대응되는 것은 아니다. 하지만 확률분포의 종류는 실제 데이터를 이해 및 분석하는 데 있어서 일종의 가이드라인을 제시한다. 3.5.9 Probability distributions for error 회귀모델은 실제 데이터의 변동성으로 수립할 수 있는 \"결정적 모델(deterministic model)\"과 오차(error), 또는 설명되지 않는 변동성을 포착하기 위해 포함되는 확률분포로 이루어진다. 3.5.10 Comparing distributions 평균과 같은 요약치들을 이용해 분포들을 비교하기도 하지만 분위(quantiles)의 변화 등도 살펴볼 필요가 있다. 평균은 집단의 중심경향성(central tendancy)을 보여주는 값이기는 하지만, 분포가 치우쳐 있을 경우(skewed), 평균이 대표값으로 유용하지 않을 수도 있고, 평균 그 자체는 불확실성 정도를 보여주지 못하기 때문이다. Figure 3.8: Distributions of potential outcomes for patients given placebo or heart stents, using a normal approximation and assuming a treatment effect in which stents improve exercise time by 20 seconds, a shift which corresponds to taking a patient from the 50th to the 54th percentile of the distribution under the placebo. 3.6 Probability modeling 두 명의 후보와 \\(n\\)명의 유권자가 참여하는 선거가 있다고 가정하자. 만약 모든 유권자가 정확히 반반으로 갈라지거나 (\\(n\\)이 짝수일 때), 후보가 득표한 수가 서로 동수일 때 (\\(n\\)이 홀수 일 때), 한 표 한 표가 더해질 때마다, 그 표들은 잠재적으로 결과를 “결정지을 수 있는” 표가 된다(승부를 결정하는 표). 이 경우, 확률을 추정하기 위해 두 가지 방법을 생각해볼 수 있다: 첫째는 경험적으로 예측하는(forecasting) 접근법이고, 둘째는 이항확률모델을 사용하는 것인데, 이 경우는 심각한 문제를 가지고 있다. 3.6.1 Using an empirical forecast \\(y\\)가 후보 중 한 명이 받을 표의 비율이라고 하고, \\(y\\)의 불확실성은 평균 0.49, 표준편차 0.04의 정규분포로 나타낼 수 있다고 하자. 즉, 후보자가 질 거라고 예측되지만(평균이 \\(0.49 &lt; 0.5\\)), 불확실성을 감안하면 실제 결과는 이길수도, 질수도 있다는 것이 된다(\\(0.49-0.04 &lt; 0.05 &lt; 0.53\\)). \\(n\\)명의 표가 \\(n\\)이 짝수일 때 정확하게 갈라질 확률 또는 \\(n\\)이 홀수일 때 딱 한 표 차이로 나뉘게 될 확률은 \\(1/n\\)에 0.5의 예측 득표율 밀도의 곱으로 나타낼 수 있다. 예를 들어, 200,000명의 유권자가 있는 선거에서 이 확률은 아래와 같이 계산할 수 있다. dnorm(0.5, 0.49, 0.04)/2e5 ## [1] 4.833351e-05 결과는 약 4.8e-5로 약 \\(1/21000\\)에 근사하는 값이다. 이 값은 개별 유권자에게 있어서는 매우 낮은 확률이지만 캠페인에 있어서는 그다지 낮다고 보기는 힘들다. 유권자 수가 늘어날수록 이 확률은 점차 증가할 것이기 때문이다. 3.6.2 Using an reasonable-seeming but inappropriate probability model \\(n\\)명의 유권자가 있고, 특정 후보에게 투표할 확률이 \\(p\\)라고 하자. 둘이 정확하게 동점이 되거나 혹은 동점에서 딱 한 표가 모자랄 확률은 이항분포를 통해서 계산할 수 있다. 예를 들어, \\(n=200,000\\)이고 \\(p=0.5\\)라고 할 때, 선거 동수의 확률은 다음과 같이 계산할 수 있다. dbinom(1e5, 2e5, 0.5) ## [1] 0.001784122 그런데 이항분포 모델을 사용했을 때의 문제가 무엇일까? 가장 직접적으로 이항분포 모델을 사용할 수 없는 이유는 그 분포가 \\(n\\)번의 독립시행에서의 \\(p\\)의 확률에 따른 성공의 횟수를 나타낸다는 것에 있다. 하지만 유권자들은 독립적으로 의사결정을 내리지 않는다. 그들의 결정은 홍보, 후보자들의 연설, 뉴스 등과 같은 여러 공통적 요인들에 의해 영향을 받는다. 게다가 유권자들은 확률 \\(p\\)를 공유하지도 않는다. 유권자들의 당파성은 서로 독립적이지도, 동일하지도 않다. 어기서의 선거 예제에서 핵심적인 문제점은 이항 모델이 불확실성을 잡아내는 데 썩 훌륭하지 않다는 것이다. \\(n\\)명의 유권자가 독립적인 의사결정을 한다고 하고, 비현실적이지만 각각이 특정 후보에게 투표할 확률 \\(p\\)를 동일하게 갖는다고 가정하자. 만약 \\(p\\)가 유권자 전체의 평균 확률로 해석될 수 있다면, 이 \\(p\\) 자체는 어디서 오는 걸까? 실제 선거에서 우리는 이 확률을 결코 알 수 없다. 즉, 어디까지나 가정해야하기 때문에 불확실성을 포착할 수 없는 것이다. 3.6.3 General lessons for probability modeling 결과적으로 우리는 확률모델을 경험적 함의(emplical implications)로 확인할 필요가 있다. 만약 확률모델이 상식적으로 말이 안되는 예측을 내놓는다면, 모델에 무언가 문제가 있는지를 확인할 기회를 가지게 되고, 어떠한 가정이 위배되는지를 검토할 수 있게 된다. 확률모델에 문제가 있을 경우에, 우리는 그 (예측)실패를 우리의 이해를 제고하기 위한 방법으로 사용할 수 있기 때문에, 예측모델은 강력한 분석도구라고 할 수 있다. 위에서 \\(x\\)에 해당하는 경제성장률도 세 개의 값을 줬기 때문에 그에 따라서 예측되는 \\(\\hat y\\)도 세개가 되므로, 각각은 길이가 3인 벡터가 된다.↩︎ 여기서 결정주의적이라는 의미는, 확실한 혹은 무작위가 아니(비체계적이지 않은)라는 의미로 이해할 수 있다.↩︎ GHV는 처치라는 표현을 많이 쓰는데, 풀어서 이해하자면 우리가 종속변수, 혹은 결과변수인 \\(y\\)에 주요한 영향을 미칠 것으로 기대하는 예측변수, 설명변수라고 이해할 수 있다. 예컨대, 통계에서 \\(x_1\\)이 우리가 기대하는 주요 예측변수고 \\(x_2\\cdots x_n\\)이 선행연구 등을 통해 종속변수에 영향을 미칠 수 있는 여타의 변수로서 모델에 포함된 통제변수라고 할 때, 우리는 \\(x_1\\)의 값이 변화할 때(처치가 가해질 때)의 $ y$의 변화를 통해서 \\(x_1\\)과 \\(y\\)의 관계를 추론하고자 하는 것이다.↩︎ \\(\\alpha\\)라고 하는 모집단의 모수(parameter)를 추정하기 위해 표본을 통해 \\(a\\)라는 통계치(statistics)를 얻었다고 하자. 우리는 모집단과 표본 간에 존재하는 필연적 불확실성–표본이 아무리 모집단을 대표한다고 해도 표집방법 등과 같은 이유로 나타날 수 밖에 없는 오차로 인해여 통계치가 완벽하게 모수와 동일하다고 확신할 수 없다. 즉, 통계치는 일정한 불확실성을 수반하게 되는데, 확률분포는 이 불확실성을 보여주기 위해 사용된다.↩︎ 하지만 이 부분은 조금 더 부연설명이 필요한데, 모집단을 대표하는 값을 기대값이라고 할 때, 현실적으로 우리가 가진 데이터(표본)을 대표할 수 있는 값 중 하나가 평균이다. 그래서 평균을 표본 수준에서 일종의 기대값에 대응하는 개념으로 사용하는 것이지 엄밀하게 말하면 평균 = 기대값이라고 보기에는 무리가 있다.↩︎ "],["statistical-inference.html", "Chapter 4 Statistical Inference 4.1 Sampling distributions and generative models 4.2 Estimates, standard errors, and confidence intervals 4.3 Bias and unmodeled uncertainty 4.4 Statistical significance, hypothesis testing, and statistical errors 4.5 Problems with the concept of statistical significance 4.6 Moving beyond hypothesis testing", " Chapter 4 Statistical Inference 통계적 추론은 데이터에 기초하여 모집단의 모수에 관한 예측을 추정과 불확실성을 포함한 진술의 형태로 구성하는 것이다. 즉, 데이터가 현실 속에서 우리가 연구하고자 하는 모집단에 대한 하나의 표본이라고 할 때, 그 표본을 통해 모집단에서 존재하는 관계양상 등(모수)에 관해 예측하고, 그 예측에는 표본-모집단의 관계로 인한 불확실성이 존재하기에 그것 또한 반영하여 진술(statement)의 형태로 가공해내는 것이다. 이 챕터에서는 확률모델, 추정(estimation), 편향(bias), 분산, 그리고 통계적 추론의 해석과 통계적 오차에 관한 기본적인 내용들을 다룬다. 나아가 통계적 추론에서 불확실성의 개념이 어떻게 연계되는지를 살펴보고 잡음이 있는 데이터(불확실성을 포함한 데이터)로부터 확실성을 이끌어내기 위해 가설 검정과 통계적 유의성을 사용하는 것의 문제 또한 짚어본다. 4.1 Sampling distributions and generative models 4.1.1 Sampling, measurement error, and model error 우리는 불완전하거나 혹은 미비한 데이터를 바탕으로 통계적 추론을 이끌어낸다. 추론의 역할은 다음과 같다. 표집모델(sampling model): 우리가 알고 싶은 것은 모집단에 대한 특성이지만 모집단을 직접 관측하거나 확보할 수 없기때문에 우리는 모집단으로부터 추출한 표본으로부터 모집단의 특성을 추정해야만 한다. 측정오차모델(measurement error model): 우리는 기저의 어떠한 패턴이나 법칙(law)에 대해 알고싶지만 현실에서 측정된 데이터는 항상 오차를 수반한다. 측정오차가 항상 예측변수들과 독립적인 것(혹은 가산형, additive)은 아니다9: 때로는 승산형(multiplicative) 모델이 더 말이 될 수 있고, 이산형 데이터를 모델링할 때는 이산형 분포가 필요할 수도 있다. 모델오차(model error): 실제 데이터에 적용하는데 있어서 모델이 가지는 본연적 불완전성을 의미한다. 위의 세 통계적 추론에 대한 패러다임은 서로 다른 특징을 가진다. 예를 들어, 표집모델은 측정에 관해서는 구체적으로 설명하지 않고, 완벽한 데이터가 관측되더라도 측정오차모델에 대한 접근법을 취할 수 있다. 그리고 모델 오차는 완벽하게 정확한 관측치들을 대상으로도 제기될 수 있는 문제이다. 통계모델을 수립하고, 통계모델을 가지고 작업하는 과정에서 위의 세 문제 모두 고려해야 한다. Gelman, Hill, and Vehtari (2020) 은 측정오차모델(\\(y_i = a + bx_i + \\epsilon_i\\))의 분석틀에서 회귀모델을 수립하는 접근법을 취하고 있다. 이때, \\(\\epsilon_i\\)은 모델 오차로 해석할 수 있으며, 동시에 표본과 모집단의 관계에서는 가설적인 초모집단(superpopulation)이라고 할 수 있는 분포로부터 무작위로 표본을 추출하며 나타난 일련의 표집오차들(sampling errors), \\(\\epsilon_1,\\dots,\\epsilon_n\\)로 볼 수도 있다. 4.1.2 The sampling distribution 표집분포는 데이터 수집 과정이 반복될 때, 관측될 수 있는 일련의 “가능한(possible)” 데이터셋을 의미한다. 우리가 관심을 가지고 연구하고자 하는 모집단이 존재한다고 할 때, 확률적으로 표본을 추출할 경우, 우리는 여러 표본들을 얻을 수 있을 것이다. 그리고 그 표본들의 분포를 표집분포라고 한다. 하지만 우리는 실제로 표집분포를 알 수는 없고 단지 추정할수만 있을 뿐이다. 왜냐하면 모집단을 모르기 때문에 모집단에서 표본들이 어떻게 추출되었는지 알 수 없다는 것이다. 마찬가지로 측정오차모델에서 표집분포는 데이터로부터 추정된 알려지지 않은 모수 \\(a\\), \\(b\\), 그리고 \\(\\sigma\\)에 좌우된다. 데이터가 무작위(확률적) 과정을 통해 수집되지 않았다면, 통계적 추론을 위해서는 데이터에 관한 어떤 확률모델을 가정하는 것이 유용하다. 표집분포는 생성모델(generative model)이라고도 불린다.10 4.2 Estimates, standard errors, and confidence intervals 4.2.1 Parameters, estimands, and estimates 모수(parameters)는 통계모델을 결정하는 “알려지지 않은 수,” 모집단의 특성을 의미한다. 예를 들어, 아래와 같은 모델이 있다고 하자. \\[ y_i = a + bx_i + \\epsilon_i, \\: \\epsilon \\sim \\mathrm{N}(0, \\sigma). \\] 계수(coefficients): \\(a\\)와 \\(b\\) 분산(variance): \\(\\sigma\\) 한편 추정치(estimand) 또는 우리가 관심을 갖는 통계치(quantity of interests)는 추정하고자 하는 데이터 또는 모수에 대한 요약을 제공한다. 위의 모델에서는 \\(a\\), \\(b\\), 즉 절편과 계수가 우리가 관심을 가진 추정치라고 할 수 있으며, 또는 모델을 통해 산출안 예측값(predicted values)이 우리가 관심을 갖는 추정치일 수도 있다. 4.2.2 Standard errors, inferential uncertainty, and confidence intervals 표준오차(standard error)는 추정된 값에 대한 “추정된(estimated)” 표준편차를 의미하며, 우리가 관심을 갖는 추정량의 불확실성 정도를 보여주는 지표이다. 표준오차는 추정치의 변동성을 보여주는 측정지표이면서 표본의 규모가 더 커질수록 표준오차는 감소하고 종래에는 거의 0에 수렴하게 된다. 신뢰구간(confidence interval)은 주어진 표집분포의 가정 하에서 데이터와 대략 일치하는 모수 또는 추정하고자 하는 통계치의 값의 범위를 나타낸다. 간단히 얘기하자면, 모집단의 평균이라는 모수를 추정하고자 할 때, 우리는 표본을 통해 어떠한 값의 범위 안에 그 모수가 존재할 것이라고 기대하는 신뢰구간을 표본을 통해 산출할 수 있다. 대개 대규모 표본을 대상으로 표집분포가 정규분포를 따른다는 가정 하에 추정치로부터 \\(\\pm2\\) 표준오차의 범위의 95% 신뢰구간을 추정한다. 4.2.3 Standard errors and confidence intervals for average and proportions 표본규모가 \\(n\\)인 단순무작위 추출된 표본으로 무한대의 값을 가지는 모집단의 평균을 추정할 때, 그 표준오차는 \\(\\sigma\\sqrt{n}\\)이며, 이때 \\(\\sigma\\)는 모집단의 측정지표에 대한 표준편차가 된다. 한편, 데이터가 연속형이 아니라 이산형, 특히 0과 1을 값으로 가질 경우에는 평균(average)은 데이터에서 1이 갖는 비율(proportion)과 같다. 예를 들어, \\(n\\)명의 응답자를 상대로 설문을 하고 예(Yes)라고 말한 사람의 수를 \\(y\\), 무응답자의 수가 \\(n-y\\)라고 하자. 이 경우에 설문을 통해 모집단에서 예라고 응답한 사람의 비율(\\(\\hat p\\))을 추정하면, \\(\\hat p = y/n\\)이 된다. 그리고 이때 표준편차는 \\(\\sqrt{\\hat p (1-\\hat p)/n}\\)이 된다. 만약 모집단에서의 응답비율, \\(p\\)가 거의 \\(0.5\\)라고 한다면, 표본에서의 비율은 표본크기에 따라서 달라질 수 있으며, 대략 \\(0.5/\\sqrt n\\)로 근사한다고 할 수 있다. 만약 표본에서의 응답비율이 \\(0.5\\)라면 \\(\\sqrt{0.5*0.5} = 0.5\\), \\(0.4\\)라면 모수에 대한 추정치는 \\(\\sqrt{0.4*0.6}=0.49\\), \\(0.3\\)이라면 \\(\\sqrt{0.3*0.7}=0.46\\)가 된다. 비율에 대한 신뢰구간을 표준오차 공식에 따라서 계산해보자. 1000명의 무작위 표본 중 700명이 사형제 지지, 300명이 사형제 반대한다고 할 때, 모집단에서의 지지자 비율에 대한 95% 구간은 \\([0.7\\pm2\\sqrt{0.7*0.3/1000}] = [0.67, 0.73]\\)로 도출된다. 이 구간은 모수, \\(0.7 (700/1000)\\)을 포함한다. R로도 계산해볼 수 있다. 4.2.4 Standard error and confidence interval for a proportion when \\(y = 0\\) or \\(y = n\\) \\(y=0\\)이거나 \\(n-y = 0\\)인 극단적인 경우, 표준오차의 추정값은 0이되며, 신뢰구간의 너비도 0이 된다. n &lt;- 1000 y &lt;- 0 estimate &lt;- y/n se &lt;- sqrt(estimate*(1-estimate)/n) int_95 &lt;- estimate + qnorm(c(0.025, 0.975)) * se int_95 ## [1] 0 0 4.2.5 Standard error for a comparison 두 독립적인 값의 차이에 대한 표준오차는 다음과 같이 계산할 수 있다. \\[ \\text{standard error of the difference} = \\sqrt{se^2_1 + se^2_2}. \\] 예를 들어, 1000명을 대상으로 한 설문에서 400명은 남성, 600명은 여성이었다고 해보자. 이들에게 다음 선거 때 누구에게 투표할 생각이 있느냐고 물었을 때, 남성 중 57%, 여성 중 45%가 공화당 후보에게 투표할 것이라고 응답했다고 하자. 이때 남성의 공화당 후보에 투표할 비율에 대한 표준오차는 \\(\\text{se}_\\text{men} = \\sqrt{0.57*0.43/400}\\), 여성의 경우는 \\(\\text{se}_\\text{women} = \\sqrt{0.45*0.55/600}\\)으로 계산할 수 있다. 따라서 추정된 공화당 지지에 대한 성별의 차이는 \\(0.57-0.45 = 0.12\\)이며, 그 표준오차는 \\(\\sqrt{\\text{se}_\\text{men}^2 + \\text{se}_\\text{women}^2} = 0.032\\)라고 할 수 있다. 4.2.6 Sampling distribution of the sample mean and standard deviation; normal and \\(\\chi^2\\) distributions 평균이 \\(\\mu\\)이고 표준편차가 \\(\\sigma\\)인 정규분포로부터 \\(n\\)개의 관측치(\\(y_1,\\dots y_n\\))를 추출했을 때, 표본의 평균은 \\(\\bar{y} = \\frac{1}{n}\\sum^{n}_{i=1}y_i\\)가 되고, 표준편차는 \\(s_y = \\sqrt{\\frac{1}{n-1}\\sum^n_{i=1}(y_i-\\bar{y})^2}\\)라고 할 수 있다. 이때, 표본평균과 표본표준편차는 정규분포에서 독립적인 표본들을 무작위추출했다는 가정 하에서 일종의 표집분포를 이룰 수 있다. 예를 들어, 모집단으로부터 무수히 많은 표본들을 뽑아 그들 각각의 평균을 구한다면, 그 평균이 또 하나의 분포를 이룰 수 있다는 것이다. 그리고 표본 추출 횟수가 증가할수록(\\(n\\uparrow\\)), 그 표본평균은 정규성을 띄게 될 것이다. 따라서 우리는 표본평균 \\(\\bar{y}\\)가 모집단 평균 \\(\\mu\\)를 중심으로 추출횟수, 표본규모에 따른 표준편차 \\(\\sigma/\\sqrt{n}\\)를 가지는 정규분포를 가지게 될 것이라고 기대할 수 있다. 마찬가지로 표본의 표준편차는 \\(s^2_y*(n-1)/\\sigma^2\\)로, \\(n-1\\)의 자유도(degree of freedom)를 가지는 \\(\\chi^2\\)(카이스퀘어) 분포를 띄게 된다. 4.2.7 Degrees of freedom 그렇다면 대체 자유도란 무엇일까? Gelman, Hill, and Vehtari (2020) 은 “적합된 모델로부터 예측값들의 오차를 추정할 때, 과적합(overfitting)의 문제를 교정할 필요가 있다”라는 말로 자유도의 개념을 설명하는데, 조금 알아듣기 어렵다. 간단히 정리하면, 자유도란 주어진 조건 하에서 통계적 제한을 받지 않고 자유롭게 변화를 줄 수 있는 관측치의 수를 의미한다. 예를 들어, \\(x + y + z = 12\\)라는 수식이 있다고 할 때, 자유도는 몇 개일까? 일견 미지수가 3개이므로 자유도가 3이라고 생각할 것 같지만 여기서의 자유도는 2이다. 왜냐하면 \\(x\\)와 \\(y\\)의 값이 결정되는 순간, \\(z\\)의 값은 자유롭지 못하고 고정되기 때문이다. 자유도가 작을수록 과적합을 조정해주어야할 필요성은 증가한다. 왜냐하면 변수가 자유롭지 않다는 얘기는 딱 그 표본에 한하여 모델이 유효할 가능성이 높다는, 즉 일반화하기 어렵다는 문제를 해결해야 한다는 의미이기 때문이다. 자유도의 문제는 모델에서의 잔차의 추정에 있어서의 불확실성과 연관되는데, 자세한 내용은 11장에서 살펴보도록 한다. 4.2.8 Confidence intervals from the \\(t\\) distribution \\(t\\) 분포는 정규분포와 비슷하지만 양 끝 꼬리가 조금 더 두터운 분포를 말한다. 관측치의 개수가 많아지면 (자유도가 커질수록) \\(t\\) 분포는 정규분포에 수렴하게 된다. 만약 표준오차가 \\(n\\)개의 데이터로 추정된다면, 우리는 \\(n-1\\)의 자유도를 가진 \\(t\\) 분포를 이용해 그 불확실성을 설명할 수 있다. 정규분포와 \\(t\\) 분포의 차이는 자유도의 크기 차이라고 봐도 무방하다. y &lt;- c(35, 34, 38, 35, 37) n &lt;- length(y) estimate &lt;- mean(y) se &lt;- sd(y)/sqrt(n) int_50 &lt;- estimate + qt(c(0.25, 0.75), n-1)*se int_95 &lt;- estimate + qt(c(0.025, 0.975), n-1)*se int_50;int_95 ## [1] 35.2557 36.3443 ## [1] 33.75974 37.84026 4.2.9 Inference for discrete data 이항변수가 아닌 이산형 데이터에 대해서도 연속형 변수의 표준오차를 계산하는 공식을 적용할 수 있다. 1000명의 무작위 표집된 성인을 대상으로 그들이 개를 몇 마리 소유하였는지를 설문하였다고 하자. 600명은 개가 없다고 응답했고, 300명은 1마리를, 50명은 2마리를, 30명이 3마리를, 20명이 4마리의 개가 있다고 응답했다. 이때, 모집단에서 소유한 개의 평균 수에 대한 95% 신뢰구간은 어떻게 추정할 수 있을까? N Mean Standard Deviation Standard Error C.I. (Low) C.I. (High) 1000 0.57 0.875 0.028 0.516 0.624 4.2.10 Linear transformations 선형변환된 모수에 대한 신뢰구간을 구하기 위해서는 그 구간도 선형변환의 형태를 취한다. 예를 들어, 일인당 소유한 개의 평균의 신뢰구간이 \\([0.52, 0.62]\\)라고 할 때, 백만명을 대상으로 하면 그 구간은 \\([520,000, 620,000]\\)이 되는 셈이다. 4.2.11 Comparisons, visual and numerical Figure 4.2는 표본 별 불확실성을 시각적으로 비교할 수 있도록 만든 플롯이다. Figure 4.1: Simulation of coverage of confidence intervals: the horizontal line shows the true parameter value, and dots and vertical lines show estimates and confidence intervals obtained from 100 random simulations from the sampling distribution. If the model is correct, 50% of the 50% intervals and 95% of the 95% intervals should contain the true parameter value, in the long run. 4.2.12 Weighted averages 서로 다른 집단의 평균과 분산을 결합하여 가중평균을 구하듯, 가중평균에 대한 신뢰구간도 구할 수 있다 (Gelman, Hill, and Vehtari 2020: 54). 4.3 Bias and unmodeled uncertainty 모델이 참일 경우, 측정이 편향되지 않았을 경우, 무작위로 추출된 표본일 경우, 무작위화가 전제된 실험일 경우, 앞서 논의한 추론은 모두 일관된 결과를 내놓게 된다. 그러나 실제의 데이터 수집은 모두 불완전하므로 우리는 추론과 예측에 있어서 모델 오차의 가능성을 포함하게 된다 (Gelman, Hill, and Vehtari 2020: 55). 4.3.1 Bias in estimation 즉, 평균적으로 추정치가 맞다면, 우리는 추정치가 불편향(unbiased)하다고 한다. 예를 들어, 미국의 성인을 대상으로 하는 단순무작위표본이 있다고 하고, 각 응답자들은 하루에 TV를 몇 시간 보는지에 대해 응답하였다고 하자. 응답자들이 모두 정확하게 응답하였다고 할 때, 표본의 평균응답은 모집단의 평균 시청시간에 대한 불편추정량이 된다. 여성이 남성보다 더 응답을 많이 했다고 할때, 표본은 평균적으로 여성을 과대대표하게 되며, 여성이 평균적으로 남성보다 TV를 덜 시청한다는 결론은 모집단의 비율에 대해 “편향된”(biased) 추정량이 되는 것이다. 4.3.2 Adjusting inferences to account for bias and unmodeled uncertainty 통계모델에 포함하지 않은/포함할 수 없는 오차를 어떻게 설명할 수 있을까? 일반적으로 세 가지 방법으로 우리는 이 문제를 다룰 수 있다: (1) 데이터 수집의 질을 향상시키는 것, (2) (불확실성을 포함하는) 모델을 확장시키는 것, (3) 모델에 포함되지 않은 오차, 불확실성을 보다 명확하게 설명하는 것이 바로 그것이다(Gelman, Hill, and Vehtari 2020: 56). 4.4 Statistical significance, hypothesis testing, and statistical errors 데이터를 분석할 때 한 가지 주의해야할 것은 재현되지 않는 결론을 내리는 실수를 하거나, 또는 모집단에서의 실제 패턴을 반영하지 못하는 실수를 하는 것이다. 가설검정과 오차분석에 대한 통계이론은 추론과 의사결정이라는 맥락에서 이러한 가능성들을 계량화하고자 발전된 것이다(Gelman, Hill, and Vehtari 2020: 57). 4.4.1 Statistical significance 통계적 유의성은 통상적으로 가설검정의 맥락에서 영가설(null hypothesis), 또는 효과가 없을 것이라는 것을 보여주는 특정한 값(prespecified value)에 비해 \\(p\\)-값이 0.05보다 작은지로 정의된다. 적합된 회귀모델로 얘기하자면, 이러한 논리는 회귀계수의 추정치가 효과가 없을 것이라는 의미의 0과 비교하여 최소 2 표준오차만큼 차이가 나는지 여부를 가지고 통계적 유의성이 존재하는지를 판단하는 것이다(Gelman, Hill, and Vehtari 2020: 57). Gelman, Hill, and Vehtari (2020) 은 동전을 20번 던졌을 때, 8번 앞면이 나오는 사건을 예시로 제시한다. 기존의 영가설은 앞면과 뒷면이 나올 확률이 각각 \\(p = 0.5\\)라고 할 때, 20번 중에서 8번, 즉 관측한 \\(\\hat p = 0.4\\)가 통계적으로 \\(p = 0.5\\)와 유의미한 차이인지를 표준오차를 통해 \\(\\sqrt{\\hat p (1 - \\hat p) / n}\\)로 계산하는 방식이다. n &lt;- 20 y &lt;- 8 # the estimated probability (p &lt;- y / n) ## [1] 0.4 # the standard error (se &lt;- sqrt(p * (1 - p) / n)) ## [1] 0.1095445 # the 95% CIs p + c(-2 * se, 2 * se) ## [1] 0.180911 0.619089 이렇게 계산했을 때, 신뢰구간은 \\(p = 0.5\\)를 보함하고, 우리는 관측한 결과가 영가설과 통계적으로 유의미하게 다르지 않다고 결론을 내리게 된다. 4.4.2 Hypothesis testing for simple comparisons. 기존의 가설검정의 핵심적인 개념들을 간단한 예시를 통해 살펴보자. 콜레스테롤 수치를 낮추기 위한 두 약의 효과성을 비교하기 위한 무작위 실험을 수행했다고 하자. 처치 이후의 콜레스테롤 수치의 평균과 표준편차는 처치집단(\\(n_T\\))은 \\(\\bar y_T\\), \\(s_T\\)이며, 통제집단(\\(n_C\\))은 \\(\\bar y_C\\)와 \\(s_C\\)라고 하자(Gelman, Hill, and Vehtari 2020: 57). 4.4.2.1 Estimate, standard error, and degrees of freedom. 우리가 알고싶은 모집단의 특성, 모수는 \\(\\theta = \\theta_T - \\theta_C\\)로, 두 집단의 실험 이후 콜레스테롤 수치의 차이에 대한 기대(expectation)라고 할 수 있다. 실험이 올바르게 수행되었다고 가정할 때, 추정치는 \\(\\hat \\theta = \\bar y_T - \\bar y_C\\)가 되며, 표준오차는 \\(\\text{se} (\\hat \\theta) = \\sqrt{s_C^2 / n_C + s_T^2 / n_T}\\)로 계산할 수 있다. 이때 약 95%의 신뢰구간은 \\([\\hat \\theta \\pm t_{n_C + n_T - 2}^{0.975} * \\text{se} (\\hat \\theta)]\\)이며, \\(t_{df}^{0.975}\\)는 \\(df\\)라는 자유도가 주어졌을 때, \\(t\\) 분포에서의 97.5 분위 즉, 1000개의 관측치가 있다면 975번째의 값을 의미한다(Gelman, Hill, and Vehtari 2020: 57). 4.4.2.2 Null and alternative hypotheses. 가설검정을 위해서는 영가설(null hypothesis)과 대안가설(alternative hypothesis)을 정의해야 한다. 여기에서 영기설은 \\(\\theta = 0\\), 즉 처치집단과 통제집단의 처치 이후 콜레스테롤 수치가 같다는 것(\\(\\theta_T = \\theta_C\\))으로 두 약의 효과 차이가 없다는 것을 의미한다. 한편, 연구가설은 \\(\\theta \\neq 0\\)으로 처치집단과 통제집단의 처치 이후 콜레스테롤 수치가 같지 않다(\\(\\theta_T \\neq \\theta_C\\))는 것을 의미한다. 가설검정은 영가설로 설정된 값으로부터 데이터로 얻은 값이 얼마나 떨어져 있는지를 요약해서 보여주는 검정통계치(test statistic)를 가지고 수행한다. 통상적인 검정 통계치는 \\(t\\)-값의 절대값으로, \\(t = |\\hat \\theta| / \\text{se}(\\hat \\theta)\\), “양측 검정(two-sided test)”이라 불리는 가설검정을 사용한다. 이는 데이터로부터 얻은 값이 양수(positive)이던 음수(negative)이던 간에 상관없이 0으로부터 유의미한 차이를 가지고 있는지 여부만 본다는 것을 의미한다. 4.4.2.3 \\(p\\)-value. 가설검정에서 데이터가 영가설로부터 얼마나 떨어져 있는지는 \\(p\\)-값을 통해서도 볼 수 있다. \\(p\\)-값은 우리가 얼마나 극단적인 관측값을 확인할 수 있는지를 확률적으로 보여주는 수치이다. \\(p\\)-값은 \\(\\nu\\)의 자유도를 가진 \\(t\\)-분포에서 영가설로부터 극단적으로 떨어진 값을 관측할 확률을 의미한다. R에서 theta_hat = \\(\\hat \\theta\\), se_theta = \\(\\text{se}(\\hat \\theta)\\) n_C = \\(n_C\\), 그리고 n_T = \\(n_T\\)라고 할 때, \\(p\\)-값은 다음과 같이 구할 수 있다. 2 * (1 - pt(abs(theta_hat) / se_theta, df = n_C + n_T, ncp = 2)) 4.4.3 Hypothesis testing: general formulation. 가설검정의 가장 간단한 형태는 영가설(\\(H_0\\))은 잠정적인 재현 데이터(\\(y^\\text{rep}\\))에 대한 특정한 확률모델(\\(p(y)\\))로 나타난다. 가설검정을 수행하기 위해서 우리는 검정통계량, 데이터로부터 어떠한 함수적 관계를 통해 계산되는 \\(T\\)를 정의해야한다. 주어진 데이터 \\(y\\)에 대해 \\(p\\)-값은 \\(\\operatorname{Pr}(T(y^\\text{rep}) \\geq T(y))\\)로 나타낼 수 있고, 이는 모델로 데이터의 관측된 값만콤 혹은 더 극단적인 값을 관측할 확률을 의미한다. 아까 위의 콜레스테롤 약을 예시로 들자면, 영가설은 효과가 없을 것이라고 할 때 \\(p\\)-값은 데이터로부터 영가설에 비해 얼마나 더 극단적인 값을 관측할 것인지의 확률을 보여주는 것으로, 극단적을 관측할 확률이 높을수록 우리는 데이터가 영가설(효과없음)과는 차이가 있는 값을 내놓을 것이라고 기대할 수 있게 되는 것이다. 회귀모델에서는 가설검정이 조금 더 복잡하다. 우리가 적합하고자 하는 모델을 \\(p(y|x, \\theta)\\)라고 할 때, \\(\\theta\\)는 계수와 잔차의 표준편차, 그리고 이외의 다른 모수들을 포함하는 것이라고 하자. 이때 영가설은 계수값이 0일 경우를 의미한다(Gelman, Hill, and Vehtari 2020: 58). 간단히 말하면 예측변수 \\(x_1\\)이 \\(y\\)와 맺는 관계가 0, 무관한 것과 같다는 것을 영가설로 설정하고 그 계수값이 표준오차를 고려했을 때 0으로부터 유의미하게 떨어져 있다면, 우리는 그 영가설을 기각하여 \\(x_1\\)과 \\(y\\)가 유의미한 관계를 맺고 있을 것이라고 결론을 내리게 되는 것이다. 4.4.4 Comparisons of parameters to fixed values and each other: interpreting confidence intervals as hypothesis tests. 모수가 0일 것(혹은 어떠한 고정된 값)이라는 가설은 그 모수를 포함한 모델을 적합하고 95% 신뢰구간을 분석함으로써 직접적으로 검정할 수 있다. 만약 우리가 추정한 신뢰구간이 0 (혹은 설정한 고정값을)을 포함하지 않는다면, 가설은 5%의 신뢰수준에서 기각된다고 말할 수 있다. 두 개의 모수가 서로 같은지 여부를 검정하는 것은 둘의 차이가 0인지를 검정하는 것과 같다. 따라서 모델 안에 두 모수 모두를 포함하고 그 두 모수의 차이에 대한 95% 신뢰구간을 분석하면 두 모수가 서로 같은지 여부를 검정할 수 있다. 하나의 모수에 대해 추론할 때와 마찬가지로 종종 가설검정 그 자체보다는 신뢰구간을 살펴보는 것이 더 흥미로울 수 있다. 예를 들어, 사형제에 대한 지지도가 약 \\(6\\pm2\\) 퍼센트 감소했다고 할 때, 이렇게 추정된 차이의 크기는 그 변화의 신뢰구간이 0을 포함하지 않느냐 만큼이나 중요할 수 있다. 4.4.5 Type 1 and type 2 errors and why we don’t like talking about them. 통계적 검정은 1종오류(type 1 error)와 2종오류(type 2 error)로 이해할 수 있다. 1종오류: 영가설이 맞는데 그것을 거짓으로 기각할 확률. 즉, 콜레스테롤 약이 효과가 없는게 맞는데 효과가 없다는 영가설을 기각해버렸을 오류를 의미한다. 2종오류: 영가설이 기각되어야 하는데, 기각에 실패할 확률. 즉, 콜레스테롤 약의 효과에 차이가 있는데, 기각하지 못하여 두 약의 효과에 차이가 없다고 결론을 내릴 오류를 의미한다. 이론적으로는 이 두 오류에 대해 이해하고 있어야하지만, 이 두 오류가 사회과학 또는 과학적 연구 일반에 있어서 정확하게 들어맞기는 어렵다.11 그보다 1종오류와 2종오류 저변에 놓여있는 문제를 인지할 필요가 있는데, 4.4.6 4.4.6 Type M (magnitude) and type S (sign) errors. S형 오류(type S error)는 추정된 효과의 부호(sign)가 모집단의 효과(진짜 효과; 추정하고자 한 효과; true effect)와 정반대로 나타나는 오류를 의미한다. M형 오류(type M error)는 추정된 효과의 크기가 진짜 효과의 크기와 크게 다를 때를 일컫는 오류이다. 통계적 기법으로 이 두 오류의 확률을 계산할수는 있지만, 앞의 1종오류, 2종오류와 마찬가지로 모집단의 효과를 우리가 관측하지 못하는 한, 완벽한 오류의 확인은 불가능하다. 4.4.7 Hypothesis testing and statistical practice. 일반적으로 영가설의 유의성 검정을 사용하지는 않는다. 실제 연구를 수행할 때, 영가설이 사실(\\(H_0 = 0\\), 또는 특정한 고정값과 “같다”)일 것이라고 기대하지는 않기 때문이다. 대개는 모든 처치가 어느 정도의 효과는 있으리라 생각한다. 그리고 어떠한 비교 혹은 관심을 갖고 있는 회귀계수가 정확히 0일 것이라고 기대하지도 않는다. 영가설 검정은 일종의 데이터 수집과 관련된 문제라고 할 수 있다: 충분한 규모의 표본이 있다면 어느 가설도 기각될 수 있다. 그리고 이론적으로 그러할 것이라고 믿지 않는 가설을 기각하기 위해 대규모의 데이터를 수집하는 것에는 의미가 없다(Gelman, Hill, and Vehtari 2020: 59). 즉, 영가설을 기각한다는 것—검정통계치가 특정 기준을 충족시킨다는 것이 모든 통계적 분석에 답이 되는 것은 아니다. 4.5 Problems with the concept of statistical significance 흔한 통계적 오류는 바로 통계적 유의성으로 비교해야할 내용을 정리해 유의하고 유의하지 않은 결과 간의 뚜렷한 차이를 도출해내는 것이다. 통계적 유의성으로만 결과를 살펴보는 데에는 다섯 가지 위험성이 존재한다. 그 중 두 가지는 명확하고, 나머지 셋은 잘 이해되지는 않는 위험이다(Gelman, Hill, and Vehtari 2020: 60). 4.5.1 Statistical significance is not the same as practical importance. 첫 번째 위험성은 통계적으로 유의한 것이 실제로 의미있는 것은 아닐 수 있다는 점이다. 우리가 효과의 크기를 확인하는 이유이기도 하다. 예를 들어, 탄 음식을 먹으면 암에 걸릴 확률이 증가한다는 가설에 대해 통계적으로 유의한 결과를 얻었다고 하자. 그런데 그 확률이 0.0000001%, 즉 한 번에 몇 십톤을 먹어야 발암 확률이 한 자리수로 증가한다는 결과라고 할 때, 과연 그 결과가 실질적으로 유의미하다고 할 수 있을까? 4.5.2 Non-significance is not the same as zero. 둘째, 통계적으로 유의미하지 않다는 것이 결코 효과가 없다는 것과 같은 의미는 아니다. 우리가 분석한 데이터가 영가설을 기각하지 못했을 뿐, 오히려 영가설을 “지지하는” 데이터일 수 있다. 4.5.3 The difference between “significant” and “not significant” is not itself statistically significant. 통계적으로 유의한 것과 유의하다는 것의 차이 그 자체는 통계적으로 유의하지 않다. 효과에 대한 추정치와 표준오차가 각각 \\(25 \\pm 10\\)와 \\(10 \\pm 10\\)인 두 독립적인 연구가 있다고 하자. 첫 번째 연구는 1% 신뢰수준에서 통계적으로 유의미하고 두 번째는 0으로부터 1 표준오차 떨어져 있는지를 기준으로 보았을 때에도 전혀 유의미하지 않았다. 이 두 연구의 결과를 비교해볼 때, 우리는 두 연구 간에 매우 큰 차이가 존재한다고 결론내리고 싶을 것이다. 하지만 사실 이 두 연구 결과의 차이는 통계적으로 유의하지조차 않다: 추정된 차이는 15이지만 표준편차가 \\(\\sqrt{10^2 + 10^2} = 14\\)이기 때문이다(Gelman, Hill, and Vehtari 2020: 61). 4.5.4 Researcher degrees of freedom, \\(p\\)-hacking, and forking paths. 통계적 유의성의 또 다른 문제는 바로 여러 집단을 비교할 때 존재한다. 여러 가지 방식으로 데이터를 선택하고, 제외하고, 분석할 수 있다고 할 때, 실제로는 어떠한 기저의 패턴이 존재하지 않더라도 낮은 \\(p\\)-값을 얻는 것은 어렵지 않은 일이다. 여기서의 문제는 단순히 유의하지 않은 발견들이 출판되지 않는 “서류함 효과(file-drawer effect)”12만을 일컫는 것이 아니라 어떠한 연구도 데이터를 고딩하고 분석에 어떤 변수를 포함시킬지 결정하고, 어떻게 통계적 모델링을 할지 결정할 때, 연구자에게 주어지는 재량권(Gelman, Hill, and Vehtari (2020) 은 이를 연구자의 “자유도(degree of freedom)”이라고 적시하고 있다)과도 관련되어 있다(Gelman, Hill, and Vehtari 2020: 61). 예컨대, 연구자가 분석 과정에서 \\(p\\)-값이 낮은 결과/모델들만 선택적으로 보고할 때 생기는 문제 등을 생각해볼 수 있다. 4.5.5 The statistical significance filter. 마지막으로 통계적으로 유의미한 추정치가 과대추정되는 문제를 생각해볼 수 있다. M형 오류라고도 생각해볼 수 있는데, 바로 앞에서 언급한 서류함 효과를 생각해볼 수 있다. 일반적으로 출판된 연구의 경향성은 통계적으로 유의미한 결과들이 체계적으로 효과 크기를 과대추정하거나 결과를 왜곡하는 것으로 이어질 수 있다(Gelman, Hill, and Vehtari 2020: 62). 4.6 Moving beyond hypothesis testing 영가설 유의성 검정은 여러 문제를 가지고 있지만 특히나 정량연구에 있어서 실제적인 우려를 다루고 있다: 우리는 잡음이 많은 데이터(noisy data; 오차가 많은 데이터)로 인해 잘못된 결론을 내리지 않을 수 있기를 바라며, 가설검정은 오차에 대한 과대해석을 방지해줄 것을 기대한다. 어떻게 하면 통계적 유의성에 바탕을 둔 기존의 논리와 관련된 과잉확신과 과장의 문제를 피하되 통계적 논리로 얻을 수 있는 장점을 취할 수 있을까? Gelman, Hill, and Vehtari (2020, 66) 은 세 가지를 조언하고 있다. 가지고 있는 모든 데이터를 분석하라. 즉, 데이터의 특정한 부분만을 취사선택하여 분석하지 말고 연구 대상이 되는 데이터 전체를 분석하라는 것이다. 모든 비교 결과를 제시하라. 원하는 결과만을 취사선택하여 보여주지 말고, 유의하였건 유의하지 않았건 비교 결과를 모두 제시하여 연구의 투명성을 제고하고 일종의 효과의 과대추정 편향 보고를 지양하라는 것이다. 마지막으로 데이터를 공개할 수 있으면 가급적 공개하라는 것이다. 이는 다른 이들이 그 데이터를 통해 동일한 절차 혹은 다른 절차로 결과를 재현할 수 있느냐, 즉 과학적 연구의 재현가능성을 제고하는 데 기여할 수 있다. References "],["simulation.html", "Chapter 5 Simulation 5.1 Simulation of discrete probability models 5.2 Simulation of continuous and mixed discrete/continuous models 5.3 Summarizing a set of simulations using median and median absolute deviation 5.4 Bootstrapping to simulate a sampling distribution 5.5 Fake-data simulation as a way of life", " Chapter 5 Simulation 확률변수의 시뮬레이션은 다음과 같은 이유에서 응용통계에서 중요하다. 첫째, 우리는 현실세계에서 나타나는 여러 가지 변이 양상들(variation)을 모방하는 확률모델을 사용하며, 시뮬레이션 도구들은 어떻게 이러한 변이 양상들이 작동하는지에 대해 더 잘 이해할 수 있도록 돕는다. 둘째, 시뮬레이션을 이용해서 데이터의 표집분포(sampling distribution)에 근사한 결과를 확인할 수 있고, 그 결과는 통계적 추정량과 절차의 표집분포를 살펴보는 데 활용할 수 있다. 셋째, 회귀모델은 확률적이다(not deterministic; 결과가 정해져 있는 것이 아니다). 즉, 회귀모델의 결과는 확률적 예측을 생산한다. [따라서] 시뮬레이션은 예측에 잇어서의 불확실성을 보옂루 수 있는 가장 편리하고 일반적인 방법이다. 5.1 Simulation of discrete probability models 5.1.1 How many girls in 400 births? 여자아이일 확률이 약 48.8%, 남자아이일 확률이 약 51.2%고 전세계적으로 이 확률은 고정되어 있다고 하자. 이때, 한 병원에서 특정 연도에 태어난 400명의 아이들이 있다고 할 때, 그 아이들 중에서 여자아이들은 몇 명일까? Gelman, Hill, and Vehtari (2020, 69) 는 이항분포를 이용해서 400명의 출생아이들에 대한 시뮬레이션을 수행한다. n_girls &lt;- rbinom(1, 400, 0.488) # 이항분포에서 무작위로 추출 print(n_girls) ## [1] 205 위의 결과는 400명의 출생아에 대해서 발생할 수 있는 가능성을 보여준다. 실제로 “일어날 수 있는 분포”를 얻기 위해서, 우리는 이 과정을 1,000번 반복하는 시뮬레이션을 수행한다. n_sims &lt;- 1000 # 시뮬레이션 횟수 지정 n_girls &lt;- rep(NA, n_sims) # 시뮬레이션 결과를 담을 깡통 for (s in 1:n_sims){ # 1부터 시뮬레이션 횟수까지 반복 n_girls[s] &lt;- rbinom(1, 400, 0.488) # 깡통, n_girls의 각 요소에 } # 1000번의 결과를 각각 저장 n_girls %&gt;% as_tibble() %&gt;% ggplot(aes(x = value)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;) + labs(x = &quot;n_girls&quot;, y = &quot;Frequency&quot;) + theme_bw() Figure 5.1: Histogram of 1000 simulated values for the number of girls born in a hospital from 400 births, as simulated from the model that includes the possibility of twins. Figure 5.1의 1000회 시뮬레이션은 모집단으로부터 표본을 추출하면서 존재할 수 있는 불확실성을 포착한다. 위에서는 loop 함수를 이용했지만 replicate 함수를 이용해서 시뮬레이션을 할 수도 있다. 5.1.2 Accounting for twins 모델은 다양한 방식으로 확장할 수 있다. 예를 들어, 이란성 쌍둥이를 낳을 확률이 1/125이고 이때, 쌍둥이 중 하나가 여자아이일 확률이 약 49.5%라고 하자. 일란성 쌍둥이를 낳을 확률은 1/300이고, 이 쌍둥이가 여아 쌍둥이일 확률은 약 49.5%라고 할 때, 400명의 출생을 대상으로 시뮬레이션을 할 경우 아래와 같다. birth_type &lt;- sample(c(&quot;fraternal twin&quot;,&quot;identical twin&quot;,&quot;single birth&quot;), size=400, replace=TRUE, # Pr(이란성), Pr(일란성), Pr(단일출생) prob=c(1/125, 1/300, 1 - 1/125 - 1/300)) girls &lt;- rep(NA, 400) for (i in 1:400){ if (birth_type[i]==&quot;single birth&quot;) { girls[i] &lt;- rbinom(1, 1, 0.488) } else if (birth_type[i]==&quot;identical twin&quot;) { girls[i] &lt;- 2*rbinom(1, 1, 0.495) # 일란성이므로 성별은 동일 } else if (birth_type[i]==&quot;fraternal twin&quot;) { girls[i] &lt;- rbinom(1, 2, 0.495) # 이란성은 성별이 다를 수 있음. } } n_girls &lt;- sum(girls) n_girls # 400건의 모든 유형의 출산 중 여자아이의 수 ## [1] 205 여기서 girls는 0, 1, 2로 이루어진 길이가 400인 벡터로 각 출생 건에 있어서 여자아이의 수를 보여준다. loop를 쓰지 않고도 동일한 결과를 얻을 수 있다. girls &lt;- ifelse(birth_type==&quot;single birth&quot;, rbinom(400, 1, 0.488), ifelse(birth_type==&quot;identical twin&quot;, 2*rbinom(400, 1, 0.495), rbinom(400, 2, 0.495))) 400건의 출산 중 여자아이들의 수에 대한 분포(distribution)를 근사하기 위해서, 1000회의 시뮬레이션을 반복한다. n_sims &lt;- 1000 n_girls &lt;- rep(NA, n_sims) for (s in 1:n_sims){ birth_type &lt;- sample(c(&quot;fraternal twin&quot;, &quot;identical twin&quot;, &quot;single birth&quot;), size=400, replace=TRUE, prob=c(1/125, 1/300, 1 - 1/125 - 1/300)) girls &lt;- rep(NA, 400) for (i in 1:400) { if (birth_type[i]==&quot;single birth&quot;) { girls[i] &lt;- rbinom(1, 1, 0.488) } else if (birth_type[i]==&quot;identical twin&quot;) { girls[i] &lt;- 2*rbinom(1, 1, 0.495) } else if (birth_type[i]==&quot;fraternal twin&quot;) { girls[i] &lt;- rbinom(1, 2, 0.495) } } n_girls[s] &lt;- sum(girls) } 중첩된 루프(nested loop)는 복잡한 데이터 구조에 대한 시뮬레이션의 특성을 보여준다. Figure 5.1은 모델을 통해 얻은 출생한 여자아이의 수의 확률분포를 보여준다. 5.2 Simulation of continuous and mixed discrete/continuous models 시뮬레이션은 모든 유형의 분포-정규(normal), 로그정규(lognormal)13, 이항(binomial), 포아송(Poisson) 확률분포 등에 대해서 수행할 수 있다. n_sims &lt;- 1000 y1 &lt;- rnorm(n_sims, 3, 0.5) y2 &lt;- exp(y1) y3 &lt;- rbinom(n_sims, 20, 0.6) y4 &lt;- rpois(n_sims, 5) distributions &lt;- tibble( normal = y1, exp = y2, binom = y3, poisson = y4 ) panel1 &lt;- distributions %&gt;% ggplot(aes(y1)) + geom_histogram(color = &quot;black&quot;, fill = &quot;white&quot;) + scale_x_continuous(breaks = seq(floor(min(y1)), max(y1) + 0.2, 0.4)) + labs(x = &quot;&quot;, y = &quot;Frequency&quot;, subtitle = &quot;1000 draws from a normal dist. with mean 3, sd 0.5&quot;) + theme_bw() + theme(plot.subtitle = element_text(size = 6)) panel2 &lt;- distributions %&gt;% ggplot(aes(y2)) + geom_histogram(color = &quot;black&quot;, fill = &quot;white&quot;) + scale_x_continuous(breaks = seq(0, max(y2) + 5, 10)) + labs(x = &quot;&quot;, y = &quot;&quot;, subtitle = &quot;1000 draws from the corresponding lognormal dist.&quot;) + theme_bw() + theme(plot.subtitle = element_text(size = 6)) panel3 &lt;- distributions %&gt;% ggplot(aes(y3)) + geom_histogram(color = &quot;black&quot;, fill = &quot;white&quot;) + scale_x_continuous(breaks = seq(-0.5, 20.5, 2)) + labs(x = &quot;&quot;, y = &quot;Frequency&quot;, subtitle = &quot;1000 draws from the binomial dist. with 20 tries, probability 0.6&quot;) + theme_bw() + theme(plot.subtitle = element_text(size = 6)) panel4 &lt;- distributions %&gt;% ggplot(aes(y4)) + geom_histogram(color = &quot;black&quot;, fill = &quot;white&quot;) + scale_x_continuous(breaks = seq(-0.5, max(y4) + 1, 2)) + labs(x = &quot;&quot;, y = &quot;&quot;, subtitle = &quot;1000 draws from the Poisson dist. with mean 5&quot;) + theme_bw() + theme(plot.subtitle = element_text(size = 6)) panel1 + panel2 + panel3 + panel4 + plot_layout(ncol = 2) Figure 5.2: Histograms of 1000 simulated values from four distributions, demonstrating the ability to draw from continuous and discrete random variables in R. 또 하나의 예제로 연속형과 이산형이 결합된 형태의 모델을 살펴보자. 미국의 성인 중 52%가 여성이고 48%가 남성이라고 해보자. 남성의 키는 평균이 69.1인치이고 표준편차 2.9인치인 정규분포에 근사한다. 여성은 평균 63.7인치, 표준편차 2.7인치인 정규분포에 근사한다고 하자. 그렇다면 무작위로 선택된 성인 중 한명의 키는 다음과 같은 코드로 구할 수 있다. male &lt;- rbinom(1, 1, 0.48) height &lt;- if_else(male == 1, rnorm(1, 69.1, 2.9), rnorm(1, 63.7, 2.7)) 만약 10 명의 성인을 무작위로 선택한다고 할 때, 그들의 평균 키는 어떻게 될까? N &lt;- 10 male &lt;- rbinom(N, 1, 0.48) height &lt;- ifelse(male == 1, rnorm(N, 69.1, 2.9), rnorm(N, 63.7, 2.7)) avg_height &lt;- mean(height) print(avg_height) ## [1] 63.85087 평균 키를 보여주는 avg_height의 분포를 시뮬레이션하기 위해서 1000번 반복한다. n_sims &lt;- 1000 avg_height &lt;- rep(NA, n_sims) for (s in 1:n_sims){ N &lt;- 10 male &lt;- rbinom(N, 1, 0.48) height &lt;- if_else(male == 1, rnorm(N, 69.1, 2.9), rnorm(N, 63.7, 2.7)) avg_height[s] &lt;- mean(height) } avg_height %&gt;% as_tibble() %&gt;% ggplot(aes(x = value)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;) + labs(x = &quot;Dist of avg height of 10 adults&quot;, y = &quot;Frequency&quot;) + theme_bw() 무작위로 추출한 10명의 성인 중 가장 키가 큰 사람은 몇 인치일까? max_height &lt;- rep(NA, n_sims) for (s in 1:n_sims){ N &lt;- 10 male &lt;- rbinom(N, 1, 0.48) height &lt;- if_else(male == 1, rnorm(N, 69.1, 2.9), rnorm(N, 63.7, 2.7)) max_height[s] &lt;- max(height) } max_height %&gt;% as_tibble() %&gt;% ggplot(aes(x = value)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;) + labs(x = &quot;Dist of max height of 10 adults&quot;, y = &quot;Frequency&quot;) + geom_vline(xintercept = mean(max_height), color = &quot;red&quot;) + theme_bw() 5.2.1 Simulation in R using custom-made functions 위에서 사용한 loop 반복문을 커스텀된 함수를 이용해서 간단하게 재현할 수 있다. Gelman, Hill, and Vehtari (2020, 72) 는 replicate() 함수를 소개하고 있다. 먼저 우리가 특정 함수를 지정하고, 그 함수를 replicate()가 정해진 횟수만큼 반복하는 것이다. height_sim &lt;- function(N){ male &lt;- rbinom(N, 1, 0.48) height &lt;- ifelse(male==1, rnorm(N, 69.1, 2.9), rnorm(N, 63.7, 2.7)) mean(height) } avg_height &lt;- replicate(1000, height_sim(N=10)) avg_height %&gt;% as_tibble() %&gt;% ggplot(aes(x = value)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;) + labs(x = &quot;Dist of average height of 10 adults&quot;, y = &quot;Frequency&quot;) + geom_vline(xintercept = mean(avg_height), color = &quot;red&quot;) + theme_bw() 5.3 Summarizing a set of simulations using median and median absolute deviation 확률모델로부터 시뮬레이션을 보여줄 수 있는, 분포를 요약해서 보여주는 시뮬레이션 추출 방법에는 여러가지가 있다. 컴퓨터로 시뮬레이션을 돌려 분포를 얻었을 때, 그것을 요약해서 보여주는 방식은 단순히 공식에 바탕을 두고 계산하는 분석적 접근(analytical approach)에 비하여 다른 의미로 분포를 요약해서 보여주는데 편리할 수 있다. 주로 데이터 분포의 형태를 보여주는 데는 평균(mean)과 중앙값(median)을 사용하고, 그 변동성을 보여주는 데에는 표준편차(standard deviation)를 사용한다. ghv2020 은 표준편차 대신 중앙값 절대편차(median absolute deviation)을 사용할 것을 권한다. 간단하게 말하면 편차를 구할 때, 평균이 아니라 중앙값을 기준으로 구하는 방식이다. 하지만 표준편차로 분포의 변동성을 파악하는 것이 일반적이기 때문에 Gelman, Hill, and Vehtari (2020) 은 중앙값 절대편차를 구할 때에는 1.483을 곱해서 리스케일링을 해서 정규분포의 표준편차와 같은 척도로 조정해준다. 이러한 방식을 mad sd라고 하며, R에서의 mad() 함수를 이용해 구할 수 있다. 혹은 1.483*median(abs(y - median(z)))으로 구할 수 있다. Gelman, Hill, and Vehtari (2020) 은 기본적으로 중앙값에 기초를 둔 요약통계치를 볼 것을 추천하는데, 그 이유는 시뮬레이션을 통해 얻은 분포는 약간의 치우침이 있을 수 있고, 그 경우 그 분포의 중심경향성을 더 잘 보여줄 수 있는 값이 중앙값이기 때문이다. 평균 5, 표준편차 2의 정규분포를 10,000번 추출해보도록 하자. z &lt;- rnorm(1e4, 5, 2) cat(&quot;mean =&quot;, mean(z), &quot;, median =&quot;, median(z), &quot;, sd =&quot;, sd(z), &quot;, mad sd =&quot;, mad(z)) ## mean = 4.996545 , median = 5.007528 , sd = 1.991452 , mad sd = 2.003363 위의 결과는 대략적으로 우리가 상정한 평균 5와 표준편차 2에 근사하며, 약간의 차이는 표집에 따른 변동성이라고 이해할 수 있다. 왜냐하면 시뮬레이션은 한정된 수의 추출을 한 것이기 때문에 시뮬레이션 횟수가 증가할수록 상정한 평균과 표준편차의 결과에 근사한 결과를 얻을 수 있겠지만 완전히 동일한 값을 얻을 수는 없다. 이 리딩노트에서는 stan 코드를 사용하지는 않을 것이지만, 간단히 Gelman, Hill, and Vehtari (2020) 이 소개하는 내용을 살펴보도록 한다. stan_glm을 이용해서 회귀모델을 적합하게 된다면, 각각의 회귀계수에 대한 추론은 사후분포의 중앙값이나 중앙값을 리스케일링한 mad sd로 요약하게 되고, 이는 각각 전통적인 방식의 회귀계수 추정값과 표준오차에 해당하게 된다. 하지만 전통적인 방법에 비해서 stan_glm은 더 작은 표본 규모 혹은 로지스틱 회귀모델이나 일반화 선형모델에서 나타날 수 있는 치우친 분포(skewed distribution)에 대해서도 더 안정적인 결과를 얻을 수 있다. 마지막으로 어떤 분포에 대해서든 불확실성을 구간추정치로 요약해서 보여주게 된다. 예를 들어, qunatile(z, 0.025, 0.975)의 경우는 1000번 시뮬레이션해서 얻은 표집분포의 요약통계치 중 하위 25번째와 상위 25번째의 값을 보여주는 결과로 우리가 일반적으로 이해하는 95% 신뢰구간과 같은 함의를 지닌다고 볼 수 있다. 5.4 Bootstrapping to simulate a sampling distribution 앞에서는 사전에 특정된(prespecified) 확률모델로부터 시뮬레이션을 하는 경우에 대해서 논의했다면, 여기서는 부트스트래핑(bootstrapping)에 대해서 살펴본다. 부트스트래핑이란 데이터로부터 표본을 재추출함으로써 표집분포의 일부를 근사하는 데 사용할 수 있도록 하는 시뮬레이션된 데이터셋들을 생성하는 불확실성을 추정하는 또 다른 접근법이다. 부트스트래핑을 통해서 데이터 수집 과정이 “다시 한 번” 이루어졌을 때에 예상할 수 있는 모집단-표본 추출 관계에서의 불확실성-변동성을 우리는 재현해볼 수 있다. 부트스트래핑은 어떤 데이터로부터 표본을 재추출해서 만들어진 자료를 일컫는 말이며, “어떠한 분포에 관한 가정이 필요없이 표집 분포에 대한 추정량을 얻을 수 있게 하는 과정”에 따라 만들어진 데이터를 의미한다. 부트스트랩 표본재추출은 복원추출로 이루어진다. 즉, 동일한 관측치가 재추출된 표본 데이터셋에 여러 번 포함될 수 있다는 것을 의미한다. 이렇게 해야지만 원표본과 동일한 규모의 부트스트랩 표본을 만들 수 있다. 생각해보면 당연하다. 모집단(\\(X\\)) \\(\\rightarrow\\) 표본(\\(x_1\\))이라고 하자. 무작위 표집이 전제되었을 때, 우리는 \\(x_1\\)이 \\(X\\)에 대한 대표성을 가질 것이라고 기대한다. 하지만 \\(X \\neq x_1\\)이다. 왜냐하면 표본은 모집단으로부터 추출한 것이지만, 모집단에 대표적인 특성을 가지고 있을 뿐, 모집단 그 자체는 아니기 때문이다. 부트스트랩 표본도 동일하다. 다만 그 관계가 \\(x_1\\) \\(\\rightarrow\\) 부트스트랩 표본(\\(x^{(1)}_1\\cdots x^{n}_1\\))으로 대체할 수 있을 뿐이다. 무작위 표본이 전제되었을 때, 우리는 \\(x^{n}_1\\)이 원표본, \\(x_1\\)로부터 추출되었다면 \\(x_1\\)에 대한 대표성을 가질 것이라고 기대할 수 있다. 이때, 복원추출을 하게 되면 \\(x^{n}_1\\)의 표본크기는 \\(x_1\\)과 동일할 수 있지만 그 구성된 관측치는 \\(x^{n}_1 \\neq x_1\\)일 수 있으며, 그렇다고 해서 \\(x^{n}_1\\)의 \\(x_1\\)에 대한 대표성이 사라지는 것은 아니다. 1990년에 미국 전국에 대한 설문조사 데이터를 바탕으로 남성의 중위소득 대비 여성의 중위소득의 비율을 추정하는 것이 목표라고 해보자. earnings &lt;- read.csv(&quot;data/ros-master/Earnings/data/earnings.csv&quot;) earn &lt;- earnings$earn male &lt;- earnings$male medians &lt;- earnings %&gt;% group_by(male) %&gt;% summarize(Median = median(earn)) ratio &lt;- as.numeric(medians[1,2]/medians[2,2]) ratio ## [1] 0.6 이때, ratio = 0.6은 남성의 중위소득에 비해 여성의 중위소득이 약 60% 정도에 불과하다는 것을 의미한다. 그러나 어디까지나 이 결과는 하나의 표본을 대상으로 추정한 것에 불과하다. 실제 모집단에 대한 추론을 위해서는 모집단-표본 간 관계에 존재할 수 있는 불확실성이 포함되어야 한다. 이 불확실성을 어떻게 얻을 수 있을까? 부트스트랩 접근법으로 보자면 표본-earnings로부터 약 100개의 무작위 부트스트랩 표본들을 추출한 뒤 그 부트스트랩 표본들 각각으로부터 얻은 ratio의 분포를 통해 이 불확실성을 추정할 수 있다. n &lt;- nrow(earnings) boot &lt;- sample(n, replace=TRUE) # sample id earn_boot &lt;- earn[boot] # earn data point 중 boot에 따라 무작위로 추출 male_boot &lt;- male[boot] # male data point 중 boot에 따라 무작위로 추출 ratio_boot &lt;- median(earn_boot[male_boot==0])/ median(earn_boot[male_boot==1]) # 위의 정보로 하나의 부트스트랩을 루프로 돌려 얻을 수 있다. boot_ratio &lt;- function(data){ n &lt;- nrow(data) boot &lt;- sample(n, replace=TRUE) earn_boot &lt;- data$earn[boot] male_boot &lt;- data$male[boot] median(earn_boot[male_boot==0])/ median(earn_boot[male_boot==1]) } # 이러한 부트스트랩 과정을 10000회 반복한다. n_sims &lt;- 10000 output &lt;- replicate(n_sims, boot_ratio(data=earnings)) output %&gt;% as_tibble() %&gt;% ggplot(aes(x = value)) + geom_histogram( color = &quot;black&quot;, fill = &quot;white&quot;) + labs(subtitle = &quot;Dist of median earning ratio of 10000 Bootstrap sample&quot;, x = &quot;&quot;, y = &quot;Frequency&quot;) + geom_vline(xintercept = median(output), color = &quot;red&quot;) + geom_segment( x = median(output) - sd(output), xend = median(output), y = 3000, yend = 3000, color = &quot;blue&quot;)+ geom_text(aes(y = 3300, x = median(output) - sd(output)/2), label = paste(&quot;sd =&quot;, round(sd(output), 2)), color = &quot;blue&quot;, size = 3) + geom_text(aes(y = 4300, x = median(output)), label = paste(&quot;Median =&quot;, round(median(output), 2)), color = &quot;red&quot;, size = 3) + theme_bw() + theme(plot.subtitle = element_text(size = 7)) 부트스트랩 분포의 표준편차는 0.03이다. 따라서 우리는 추정된 중위값의 비율이 0.6, 표준오차는 0.03이라고 말할 수 있다. 5.4.1 Choices in defining the bootstrap distribution 단순회귀모델에서 우리는 데이터 \\((x, y)_i\\)에 대한 재표본을 추출할 수 있다. 모델 \\(y = X\\beta + \\mathrm{error}\\)를 적합하고 그 적합된 모델에서의 잔차, \\(r_i = y+i - X_i \\hat\\beta\\)를 계산해서 잔차 \\(r_i\\)에 대한 \\(n\\)개의 값들로부터 표본을 재추출, 부트스트랩된 데이터 \\(y^{boot}_i = X_i \\hat\\beta + r^{boot}_i\\)를 생성할 수 있다. 이 과정을 1000번 반복하면 우리는 1000개의 부트스트랩 결과를 얻게 되고, 시뮬레이션된 부트스트랩 표집분포를 얻게 된다. 5.4.1.1 Time series 시계열 데이터를 생각해보자. 관측치 \\(y_1,\\dots,y_n\\)이 있고 측정 시점에 대한 변수가 \\(t_i\\)일 때, \\((t, y)_i i=1, \\dots, n\\)라고 한다고 하자. \\((t, y)\\)에 대한 단순 재표집 결과는 어떤 시점에서는 원표본과 같은 관측치가 다수 포함되지만 다른 시점에서는 관측치가 없는 데이터셋을 만들어내게 된다. 즉, 재추출된 표본으로는 분석이 어려울 수 있다. 잔차를 부트스트랩할 수는 있지만 이 절차에는 문제가 생길 수 있다. 예를 들어, 시간에 따라 부트스트랩된 잔차를 순서대로 모델에 적합한다면, 각 부트스트랩된 시계열 자료는 실제에 가까운 데이터에서 시작하지만 훨씬 다른 결과를 산출하게 될 것이다. 명시적으로 표집모델을 생각하기 어려운 상황에서는 표집분포에 대한 개념도 명확하게 정의되지 않는다. 부트스트랩 절차에 시계열로 인해 나타날 수 있는 시계열 상관 등을 제대로 반영하지 못한다면 단순 부트스트랩은 우리가 기대한 것보다 비효율적인 결과로 이어질 수 있다. 5.4.1.2 Multilevel structure 교내 학생들에 대한 데이터를 가지고 있다고 해보자. 학생들을 대상으로 표본 재추출을 통해 부트스트랩 해야할까? 학교를 대상으로 표본 재추출을 통해 부트스트랩 해야할까? 아니면 학교를 대상으로 먼저 표본 재추출을 하고 나서 학교별로 학생들을 표본 재추출 해야할까? 위의 세 질문은 서로 다른 표집모델에 대한 것이고, 다른 모델들은 추정치에 대해 서로 다른 부트스트랩 표준오차를 산출하게 될 것이다. 데이터가 멀티레벨 구조를 가지고 있을 때는 이러한 고민들이 선행되어야 한다. 5.4.1.3 Discrete data 이항변수로 이루어진 데이터를 가지고 로지스틱 회귀모델을 할 때, 가장 단순한 부트스트랩은 데이터 \\((x, y)_i\\)를 표본 재추출 하는 것이다. 그러나 \\((x, n, y)\\)의 형태를 가진 이항로지스틱 회귀모델의 경우는 어떻게 해야할까 (e.g., 패널 이항모델)? 한 가지 선택지는 클러스터를 바탕으로 부트스트랩을 하는 것으로, \\(x, n, y)_i\\)를 표본 재추출 하는 것이다. 또 다른 선택지는 각각의 관측치를 \\(n\\)개의 서로 다른 분리된 데이터 포인트로 확장하는 것이다: \\((x_i, n_i, y_i)\\)는 \\(y_i\\)개의 \\((x_i, 1)\\)에 대한 관측치를 산출하게 되고, \\(n_i - y_i\\)개의 \\((x_i, 0)\\)에 대한 관측치를 따로 산출해 이 결과를 \\(\\sum_i n_i\\)의 데이터 포인트를 가진 로지스틱 회귀모델에 묶어서 투입하는 것이다. 그리고 이렇게 새롭게 만들어진 번들 데이터에 대해 부트스트랩을 할 수 있다. 말이 어렵게 되어 있는데, 종속변수가 이항변수긴 하지만 구별할 수 있는 집단이 하나가 아니라 여러 개인 데이터라면 재추출 방법은 크게 두 가지 라는 점이다. 첫째는 서로 다른 집단을 하나로 묶어서, 즉 “국가-연도-종속변수”를 하나의 셋으로 묶어서 표본 재추출하는 것이고, 두 번째 방법은 각 단위-, “미국,” “연도,” “종속변수”를 (국가, 종속변수 = 1)을 종속변수가 1인 개수 만큼 표본재추출하고, (국가, 종속변수 = 0)인 경우를 종속변수가 0인 개수만큼 표본 재추출한 다음에 하나로 합쳐서 분석한다는 얘기다. 결국, 묶어서 돌릴거냐 좀 쪼개서 단계를 나눠 돌릴거냐의 차이다. 5.4.2 Limitations of bootstrapping 부트스트랩에 대해 흔히 제기할 수 있는 문제는 바로 일반성(generality)이다. 어떤 추정치도 추정치와 표집분포만 알 수 있다면 부트스트랩할 수 있다. 문제는 부트스트랩이 종종 부적절하게 높은 수준의 “확실성”을 담보한다는 것이다. 간단히 얘기하면 부트스트랩의 유효성은 표집 절차나 프로토콜에만 달려있는 것이 아니라 우리가 분석하고자 하는 데이터에 좌우될 수 있다는 것이다. 모집단 \\(\\rightarrow\\) 원표본 \\(\\rightarrow\\) 부트스트랩 표본으로 이어지는 이 연결고리에서 모집단 \\(\\rightarrow\\) 원표본에 심각한 편향(bias)이 존재한다면, 모집단에 대한 대표성이 담보되지 않은 원표본에서 파생된 부트스트랩 표본이 타당한 결과를 산출할까? 혹은 부트스트랩 표본을 가지고 추정한 결과는 원표본에 대해 과적합(overfitting)된 결과를 가지고 올 수도 있다. 부트스트랩의 강점 중 하나는 데이터에 대한 정형적인 확률모델에 대한 가정 없이도 알고리즘을 통해 표집분포를 구현할 수 있다는 것에 있다. 그러나 모순적이게도 이와 같은 부트스트랩 표본을 통해 얻은 추정치들은 사전에 정규화되고 혹은 한번 조정된(smoothed) 추정치에 대해 적용될 경우에 더 효과적일 수 있다. 즉, 부트스트랩 방법은 그것을 추출하기 이전의 표본 혹은 표본통계치에 좌우될 수 있다는 것이다.14 5.5 Fake-data simulation as a way of life 표집분포는 통계방법을 사용하고 이해하는 데 있어서 가장 기본이 된다. 이 장에서는 확률변수에 대한 시뮬레이션과 확률 표집, 그리고 통계모델을 직접적으로 시뮬레이션할 수 있는 내용들을 학습하였다. 가상의 데이터를 만들어 시뮬레이션을 돌린다고 할 때, 시뮬레이션 그 자체로는 데이터 혹은 실제 세계의 문제에 대한 통찰을 제공하지는 않지만, 우리가 사용하는 통계 방법과 가정하고 있는 주어진 모델들을 평가하는 데에는 유의미한 함의를 제공할 수 있다. References "],["background-on-regression-modeling.html", "Chapter 6 Background on regression modeling 6.1 Regression models 6.2 Fitting a simple regression to fake data 6.3 Interpret coefficients as comparisons, not effects 6.4 Historical origins of regression 6.5 The paradox of regression to the mean", " Chapter 6 Background on regression modeling 순수하게 수학적인 측면에서 회귀모델은 두 가지 목적을 갖는다: 예측(prediction)과 비교(comparison)이다. 주어진 일련의 투입(설명변수/예측변수)을 가지고 결과(종속변수/결과변수)의 분포를 예측하는 것. 투입(설명변수/예측변수)의 서로 다른 값들에 대해 이 예측들이 어떻게 달라지는지를 집단 간 단순비교 혹은 인과효과의 추정 등을 통해 비교하는 것. 6.1 Regression models 가장 단순한 회귀모델은 하나의 예측변수를 가진 선형모델이다. \\[ \\text{Basic regression model}: y = a + bx + \\mathrm{error}. \\] \\(a\\)와 \\(b\\)는 계수(coefficients), 혹은 보다 일반적으로 모델의 모수(parameters라고 한다. 단순선형모델은 여러 가지 방식으로 정교해질(복잡해질) 수 있으며, 다음과 같은 내용들을 포함할 수 있다. 추가적인 예측변수들(Additional predictors) \\(y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\cdots + \\beta_k x_k + \\mathrm{error}\\) 벡터-매트릭스 식으로는 \\(y = X\\beta + \\mathrm{error}\\)라고 쓸 수 있다. 비선형모델(Nonlinear models): \\(\\log y = a + b \\log x + \\mathrm{error}\\). 비가산모델(Nonadditive models) 예측변수 \\(x_1\\)과 \\(x_2\\) 간의 상호작용을 포함 \\(\\log y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + \\beta_3 x_1 x_2 + \\mathrm{error}\\). 일반화선형모델(Generalized linear models) 정규분포인데다 다른 예측변수들에 독립적인 오차들을 가지고 있어 적합이 되지 않는 이산형 종속변수나 다른 데이터에 사용하는 선형회귀모델. 비모수모델(Nonparametric models) 주어진 \\(x\\)에 따라 \\(y\\)의 예측값에 대해 자의적인 곡선을 그릴 수 잇게 하는 수많은 모수들을 포함하는 모델. 멀티레벨모델(Multilevel models) 회귀모델의 계수는 집단 또는 시뮬레이션에 따라서 변할 수 있다. 멀티레벨 모델은 하나 이상의 분석수준을 가진 모델을 의미한다. 측정-오차 모델(Measurement-error models) 예측변수 \\(x\\)와 결과변수 \\(y\\)가 오차와 함께 측정되고, 핵심 통계치 간의 관계를 추정하고자 할 때 사용하는 모델. Gelman, Hill, and Vehtari (2020) 에서는 선형회귀모델 중 가산형(additive), 비선형(nonlinear), 비가산형(nonadditive, 곱산형; multiplicative), 그리고 일반화 선형 모델에 대해 다룬다. 6.2 Fitting a simple regression to fake data 20개의 관측치를 가지는 페이크데이터 \\(y_i\\)가 예측변수 \\(x_i\\)는 1부터 20까지의 값을 가지고, 절편은 \\(a = 0.2\\), 기울기는 \\(b=0.3\\), 오차는 평균 0, 표준편차(\\(\\sigma\\))가 0.5인 정규분포를 따르는 모델 \\(y_i = a + b x_i + \\epsilon_i\\)로부터 시뮬레이션된다고 하자. 우리는 이 모델로부터 약 2/3에 해당하는 관측치들이 \\(\\pm \\text{표준오차}\\) 범주에 위치한다고 할 때, 이같은 페이크데이터는 다음과 같이 만들 수 있다. library(tidyverse) x &lt;- 1:20 n &lt;- length(x) a &lt;- 0.2 b &lt;- 0.3 sigma &lt;- 0.5 y &lt;- a + b * x + sigma * rnorm(n) 6.2.1 Fitting a regression and displaying the results 모델을 적합하기 위해서 예측변수와 종속변수를 포함하는 데이터프레임, fake를 만들어보자. fake &lt;- data.frame(x, y) Gelman, Hill, and Vehtari (2020) 은 stan_glm()을 이용해서 일반화선형모델을 추정, 시뮬레이션된 계수의 중앙값과 mad sd를 계산해서 제시한다. 하지만 여기서는 일반적으로 사용하는 lm()을 사용하여 회귀모델을 추정한다. fit_1 &lt;- lm(y ~ x, data = fake) summary(fit_1) ## ## Call: ## lm(formula = y ~ x, data = fake) ## ## Residuals: ## Min 1Q Median 3Q Max ## -1.13428 -0.38216 -0.05455 0.43228 1.05894 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.21588 0.29055 0.743 0.467 ## x 0.30394 0.02425 12.531 2.51e-10 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.6255 on 18 degrees of freedom ## Multiple R-squared: 0.8972, Adjusted R-squared: 0.8914 ## F-statistic: 157 on 1 and 18 DF, p-value: 2.506e-10 분석 결과, 추정된 절편은 약 0.16의 불확성을 가지고 평균적으로 0.29의 값을 가진다. 추정된 기울기는 0.01의 불확실성을 가지고 0.3의 평균값을 가진다. 잔차의 표준오차는 0.34이다. fitted_1 &lt;- broom::augment(fit_1) a_hat &lt;- coef(fit_1)[1] b_hat &lt;- coef(fit_1)[2] fitted_1 %&gt;% ggplot(aes(x, y)) + geom_point(size = 2, shape = 21) + geom_abline(intercept = a_hat, slope = b_hat) + labs(subtitle = &quot;Data and fitted regression line&quot;) + geom_text(aes(x = mean(x) + 3, y = a_hat + b_hat*mean(x)), label = paste(&quot;y =&quot;, round(a_hat, 2), &quot;+&quot;, round(b_hat, 2), &quot;* x&quot;)) + scale_y_continuous(breaks = c(seq(1, 7, 1))) + theme_bw() Figure 6.1: Simple example of a regression line fit to fake data. The 20 data points were simulated from the model, \\(y = 0.2 + 0.3x + \\text{error}\\), with errors that were independent and normally distributed with mean 0 and standard deviation 0.5. 6.2.2 Comparing estimates to assumed parameter values 페이크데이터에 모델을 적합하면, 모수에 대한 추정치와 가정된 값 간의 비교가 가능하다. 이 리딩노트에서는 stan을 이용한 시뮬레이션을 수행한 것이 아니기 때문에 \\(\\sigma\\)에 대한 불확실성은 추정되지 않는다. Table 6.1: After simulating 20 fake data points from a simple linear regression, \\(y_i = a + b x_i + \\epsilon_i\\) , with errors \\(\\epsilon_i\\) drawn from a normal distribution with mean 0 and standard deviation \\(\\sigma\\), we then fit a linear regression to these data and obtain estimates and uncertainties for the three parameters from the model. We can then see that the estimates are roughly consistent with the specified parameter values Parameter Assumed value Estimate Uncertainty \\(a\\) 0.2 0.29 0.16 \\(b\\) 0.3 0.30 0.01 \\(\\sigma\\) 0.5 0.34 NA 결과를 해석해보면 다음과 같다. 우리는 모집단에서의 절편 \\(a\\)가 0.2일 것으로 기대했고, 페이크데이터로 모델이 추정한 결과는 0.29, 불확실성은 0.16이다. 추정된 절편값과 모수로 가정한 값의 차이는 0.09이다. 하지만 절편에 대한 불확실성은 0.16이다. 즉, 추정치와 실제 값(모수) 간의 차이는 1 표준오차보다 작다. 두 값의 차이는 불확실성으로 인해 나타날 수 있는 차이에 비해 오히려 작은 것이다. 과연 이 경우에 우리는 추정된 결과가 불확실성으로 인한 것일지 혹은 진짜 모수와 표본으로부터 얻은 결과가 차이가 있어서 나타난 차이일지 구분할 수 있을까? 6.3 Interpret coefficients as comparisons, not effects 회귀계수는 종종 “효과”라고 불리지만, 이 용어는 오해의 소지가 있다. 1816명의 응답자를 대상으로 한 설문데이터로 키(인치), 성별로 연간 소득(천 달러)을 예측하는 회귀모델을 적합하는 예제를 살펴보자. earnings$earnk &lt;- earnings$earn/1000 fit_2 &lt;- lm(earnk ~ height + male, data=earnings) summary(fit_2) ## ## Call: ## lm(formula = earnk ~ height + male, data = earnings) ## ## Residuals: ## Min 1Q Median 3Q Max ## -31.99 -12.47 -3.53 7.05 368.66 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) -25.8722 11.9615 -2.163 0.03068 * ## height 0.6470 0.1852 3.493 0.00049 *** ## male 10.6327 1.4683 7.241 6.53e-13 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 21.39 on 1813 degrees of freedom ## Multiple R-squared: 0.09962, Adjusted R-squared: 0.09862 ## F-statistic: 100.3 on 2 and 1813 DF, p-value: &lt; 2.2e-16 위의 분석 결과를 바탕으로 적합된 모델을 다시 써보면 다음과 같이 나타낼 수 있다. \\[ \\text{earnings} = -25.9 + 0.6 \\times \\text{height} + 10.6 \\times \\text{male} + \\text{error}. \\] \\(\\sigma\\), 잔차의 표준편차는 21.4로 나타나는데 이 결과는 연간 소득 관측치의 약 68%가 선형 예측변수의 \\(\\pm \\$21,400\\) 범주 안에 위치하고, 약 95% 관측치가 \\(2\\pm2\\times\\$21,400 = \\$42,800\\)의 범주 안에 위치할 것이라는 점을 보여준다. 이때, 이 68%, 95%는 정규분포에 대한 특징에서 유도된 것이다. 데이터의 표준편차와 추정된 설명변동량의 비율을 비교하면 잔차의 표준편차에 대해 감을 잡을 수 있다. R2 &lt;- 1 - sigma(fit_2)^2 / sd(earnings$earnk)^2 \\(R^2=0.10\\)은 이 데이터에서 선형모델이 연간소득 변수의 약 10%를 설명한다는 것을 의미한다. 즉, 성별과 키만 가지고는 연간소득의 약 10%만 설명할 수 있다는 것이다. 한편, 적합된 모델을 과대해석하지 않도록 주의를 기울여야만 한다. 많은 가정들을 제외하더라도 예측변수와 결과변수 간의 관계-회귀계수를 “효과”라고 표현하는 것은 부적절하다. 왜냐하면 “효과”란 어떠한 “처치”나 “개임”과 관련되어 나타나는 변화로 정의하기 때문이다. “키가 연간 소득에 미치는 효과”가 $600이라고 말하는 것은 누군가의 키를 1인치 늘리면 그의 연간소득이 약 $600 증가할 것이라고 기대할 수 있다는 것을 의미한다. 그러나 이는 모델에서 추정된 결과는 아니다. 오히려 모델에서 추정된 것은 관측데이터를 통해 볼 수 있는 패턴-그 표본에서는 키가 큰 사람일수록 평균적으로 더 높은 연간소득을 가질 것이라는 것에 불과하다. 왜냐하면 실험 설계와 다르게 앞선 선형회귀모델에서는 키와 연간소득의 관계에서 연간소득에 영향을 미칠 수 있는 다른 변수들의 효과가 완벽하게 통제되지 않았기 때문이다. 그렇다면 적합된 모델에서 키에 대한 계수를 어떻게 생각할 수 있을까? “적합된 모델에서, 연간소득의 평균차이는 동일한 성별을 가지고 있지만 1인치 차이가 나는 두 사람을 비교했을 때, $600이다.”라고 말할 수 있다. 즉, 회귀모델의 가장 안전한 해석은 비교로 해석하는 것이다. 마찬가지로 추정된 “성별의 효과”가 $10,600이라고 말하는 것은 부적절하다. “적합된 모델에 따르면, 동일한 키를 가지고 있지만 성별만 다른 두 사람을 비교했을 때, 남성의 연간소득이 평균적으로 여성의 연간소득보다 $10,600 더 높을 것이다.”라고 해석하는 것이 적절하다. 정리하자면, 회귀모델은 예측을 위한 수리적 도구이다. 회귀계수는 때론 효과로 해석될 수 있지만, 그보다는 평균의 비교로 해석되는 것이 더 바람직하다. 6.4 Historical origins of regression 회귀(regression)이라는 개념을 Francis Galton으로부터 유래되었는데, 그는 사람의 키가 유전되는 것인지를 이해하기 위해 선형 모델을 적합해본 사람이다. 아이의 키가 부모로부터 유전되는가를 예측하면서, 그는 키가 큰 부모를 둔 아이의 키가 키가 작은 부모를 둔 아이들에 비하여 평균적으로 더 키가 큰 것을 확인하였다. 그 반대의 경우도 마찬가지였다. 즉, 사람의 키는 세대가 지남에 따라서 “평균으로 회귀”한다는 것을 발견했고, 회귀가 통계적 용어로 사용되기 시작한 것이다. 6.4.1 Daughters’ heights “regressing” to the mean 1903년 Karl Pearson과 Alice Lee의 유전에 관한 고전적 연구를 살펴보자. Figure 6.2: (a) Scatterplot adapted from data from Pearson and Lee (1903) of the heights of mothers and their adult daughters, along with the regression line predicting daughters’ from mothers’ heights. (b) The regression line by itself, just to make the pattern easier to see. The line automatically goes through the mean of the data, and it has a slope of 0.54, implying that, on average, the difference of a daughter’s height from the average (mean) of women’s heights is only about half the difference of her mother’s height from the average. Figure 6.2a는 엄마와 딸의 키에 대한 데이터를 엄마의 키로부터 딸의 키를 예측하는 가장 잘 맞는 선-회귀선(regression line)에 따라서 배열한 것이다. 회귀선은 \\(x\\)와 \\(y\\)의 평균을 지나간다. Figure 6.2b는 회귀선, \\(y = 30 + 0.54x\\)만을 보여준다. \\(y = 30 + 0.54x + \\text{error}\\)라고도 쓸 수 있다. 여기서 오차를 포함하는 이유는 모델이 각각의 관측치들에 완벽하게 들어맞지는 않는다는 것을 강조하기 위함이다. Figure 6.3: (a) Fitted regression line, \\(y = 30 + 0.54 x\\), graphed using intercept and slope. (b) Difficulty of the intercept-slope formulation in the context of the data in the height example. The intercept of 30 inches corresponds to the predicted height of a daughter whose mother is a meaningless 0 inches tall. Figure 6.3a는 회귀분석 결과를 절편-기울기의 형태로 나타내며 가장 시각화하기 쉬운 방식이다. 하지만 현실 세계를 기술하는 데 있어서 이러한 회귀선은 문제를 야기할 수 있다. Figure 6.3b를 보면 실제 데이터를 예측한 회귀선이 데이터가 존재하지 않는 지점까지 뻗어나가는 것을 확인할 수 있다. 현실 세계에서 키가 0인 사람은 존재하지 않는다. 선형모델을 통한 예측을 했을 때, 그 결과는 데이터에 미루어 합리적인 것이어야 한다. 어디까지가 우리가 실질적으로 이해할 수 있는 함의를 제공하는지를 판단하는 것은 연구자의 몫이 될 것이다. 6.4.2 Fitting the model in R 앞서 \\(y = 30 + 54x\\)가 가장 잘 들어맞는 선에 근사한다고 말했는데, 이때 “가장 잘 들어맞는다”는 것은 오차의 제곱합을 최소화하는 선(minimizing the sum of squared errors)이라는 것을 의미한다. 즉, 알고리즘에 따라 \\(\\sum^n_{i=1}(y_i - (a + bx_i))^2\\)를 최소화하는 \\(a\\)와 \\(b\\)의 값을 구하는 것이다. 한 번 R을 통ㅎ애 알아보자. id daughter_height mother_height 1 52.5 59.5 2 52.5 59.5 3 53.5 59.5 4 53.5 59.5 5 55.5 59.5 그러면 이제 어머니의 키로부터 딸의 키를 예측하는 회귀모델을 적합해보자. 데이터는 엄마-딸의 5524개 쌍의 키이며 모델은 세 개의 모수를 갖는다: 절편, 엄마 키에 대한 계수값, 그리고 잔차의 표준편차. fit_1 &lt;- lm(daughter_height ~ mother_height, data=heights) summary(fit_1) ## ## Call: ## lm(formula = daughter_height ~ mother_height, data = heights) ## ## Residuals: ## Min 1Q Median 3Q Max ## -9.7221 -1.4468 0.0981 1.5532 9.0981 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 29.79841 0.79034 37.70 &lt;2e-16 *** ## mother_height 0.54494 0.01264 43.12 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.262 on 5522 degrees of freedom ## Multiple R-squared: 0.2519, Adjusted R-squared: 0.2518 ## F-statistic: 1860 on 1 and 5522 DF, p-value: &lt; 2.2e-16 데이터를 가지고 그래프를 한 번 그려보자. 1인치 단위로 산포도를 그리되, 각 변수를 확률변수로 만들 수 있다. fig_1prac &lt;- tibble( n = nrow(heights), mother_height_jitt = heights$mother_height + runif(n, -0.5, 0.5), daughter_height_jitt = heights$daughter_height + runif(n, -0.5, 0.5)) 여기에다가 회귀모델에서 계수들을 추출해서 예측선을 플롯에 더해주면 된다. a_hat &lt;- coef(fit_1)[1] b_hat &lt;- coef(fit_1)[2] fig_1prac %&gt;% ggplot(aes(mother_height_jitt, daughter_height_jitt)) + geom_point(size = 1, shape = 21, alpha = 2/3) + geom_abline(intercept = a_hat, slope = b_hat) + labs(x = &quot;Mother&#39;s height (inches)&quot;, y = &quot;Adult daughter&#39;s height (inches)&quot;) + theme_bw() 이 결과는 위의 Figure 6.2a와 동일하다. 6.5 The paradox of regression to the mean 그렇다면 과연 “키가 평균으로 회귀하는가?” Figure 6.2에서 나타나는 0.54라는 기울기는, 아니 사실 1보다 큰 모든 기울기는 사실 모순적으로 보인다. 만약 키가 큰 어머니가 키가 큰 딸을 가질 가능성이 크고, 키가 작은 어머니는 키가 작은 딸을 가질 가능성이 크다면, 딸들은 어머니들보다 평균에 수렴하고, 그러다보면 종래에는 모두 평균키가 된다는 이야기가 될 수 있다. 회귀모델의 함정이 이곳에 숨어잇다. 어머니의 키에 비해서 자녀의 예측된 키는 평균에 더 가까워지지만, 그것이 실제 키가 예측과 완벽하게 동일하다는 것을 의미하지는 않는다. 왜냐하면 현실 세계에서는 우리가 항상 모델에서 예측하지 못하는 “오차”가 존재하기 때문이다. 우리의 점추정치(점예측; 어떠한 한 점의 값으로 예측 한 것)은 평균으로 회귀하므로 그 계수값은 1보다 커질 수 있다. 그리고 점차 그 변동성(variation)은 감소한다(=평균과의 차이가 감소한다). 하지만 동시에 모델의 오차(예측의 불완전성)가 변동성을 더해 한 세대가 지나 다음 세대가 되더라도 키에 있어서 전체적인 변동성은 대략 일정해진다. 평균으로의 회귀는 안정적인 환경 하에서 예측이 불완전할 때라면 어떠한 형태로든 반드시 나타난다. 예측의 불완전성은 변동성을 초래하고, 전체적인 변동성을 일관되게 유지하기 위해 점추정치(예측)에 있어서의 회귀가 요구된다. 간단히 말하자면, 우리는 점점 평균키가 어느 정도인지에 대해서는 정확한 정보를 가지게 되지만 현실 세계 속에서 사람들의 키는 다양하게(오차를 가지고) 분포하기 때문에 전체적인 변동성-세대의 키는 한 세대가 지난다고 해서 모델처럼 뚜렷하게 변화하는 것이 아니다. 즉, 우리는 모델을 통해서 평균 키의 변화를 예측할 수 있지만, 그렇다고 해서 그것이 모든 관측치들-자녀들의 키가 다 평균으로 변해버린다는 것을 의미하지는 않는다. 6.5.1 How regression to the mean can confuse people about causal inference; demonstration using fake data 평균으로의 회귀라는 개념은 때로는 헷갈릴 수 있고, 종종 인과성으로 받아들여지는 오류를 야기한다. 이번에는 두 가지 종류의 시험을 치른 학생들에 대한 예제를 살펴보자. Figure 6.4는 1,000명의 학생들의 중간고사와 기말고사 성적에 대한 가설적 데이터를 보여준다. 실제 데이터를 사용하기보다는 아래의 절차에 따라서 오차를 포함한 시뮬레이션된 시험 성적 데이터를 만들었다. 각 학생들은 평균 50, 표준편차 10이라는 분포에 실제 실력이 위치하고 있을 것으로 가정한다. 각 학생들의 중간고사 성적은 두 가지 요소의 합이다: 학생의 실제 실력과 평균 0, 표준편차가 10인 분포를 따르는 주어진 시험에 대한 성적에서 나타날 수 있는 예측불가능한 확률적 요소가 바로 그것이다. 중간고사는 완벽한 측정도구라고 보기는 힘들다. 예측이 불가능한 요소가 반영되어 있으니까. 마찬가지로 기말고사 점수도 실제 실력과, 그와는 독립적인 확률적 요소로 이루어져 있다. 가설적인 시험 데이터를 한 번 만들어보자. set.seed(2243) n_sims &lt;- 1000 exams &lt;- tibble( true_ability = rnorm(n_sims, mean = 50, sd = 10), noise_1 = rnorm(n_sims, mean = 0, sd = 10), noise_2 = rnorm(n_sims, mean = 0, sd = 10), midterm = true_ability + noise_1, final = true_ability + noise_2 ) 그리고 이제 데이터의 분포를 산포도를 통해 보여주고, 동시에 적합된 회귀선을 그려보자. Figure 6.4: Scatterplot of simulated midterm and final exam scores with fitted regression line, which has a slope of 0.45, implying that if a student performs well on the midterm, he or she is expected to do not so well on the final, and if a student performs poorly on the midterm, he or she is expected to improve on the final; thus, regression to the mean. 회귀분석 결과는 다음과 같다. summary(fit) ## ## Call: ## glm(formula = final ~ midterm, data = exams) ## ## Deviance Residuals: ## Min 1Q Median 3Q Max ## -37.732 -7.733 -0.233 7.275 35.487 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 24.82407 1.33986 18.53 &lt;2e-16 *** ## midterm 0.50864 0.02558 19.89 &lt;2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## (Dispersion parameter for gaussian family taken to be 134.3792) ## ## Null deviance: 187250 on 999 degrees of freedom ## Residual deviance: 134110 on 998 degrees of freedom ## AIC: 7742.5 ## ## Number of Fisher Scoring iterations: 2 추정된 기울기는 약 0.5로 1보다 작다-평균으로의 회귀를 보여주는 결과이다. 중간고사에서 높은 점수를 받은 학생은 평균에 비해 약 절반 이상 높은 점수를 기말고사에 받는 경향이 나타났다. 중간고사에서 낮은 성적을 받은 학생은 기말고사에서도 평균보다 낮은 점수를 받는 경향이 나타났다. 예를 들어, Figure 6.4에서 중간고사에서 0점을 받은 두 학생이 기말고사에서 각각 34, 42점을 받은 것을 확인할 수 있고, 반대로 중간고사에서 91점을받은 학생이 기말고사에서는 61점과 75점 사이를 받은 것을 확인할 수 있다. 이 결과를 인과적으로 해석하는 것은 자연스러워 보인다. 즉, 중간고사에서 점수를 잘 받은 학생들이 더 실력이 좋지만 실력에 자만해서 기말고사에서는 썩 잘하지 못한다는 식으로 말이다. 한편, 이러한 인과적 추론에 따르면 중간고사에서 성적이 나빴던 학생이 더 열심히 해서 기말고사에서는 성적을 높였다라고 할 수도 있다. 그러나 사실 데이터는 어떠한 효과를 목적으로 하는 모델에서 시뮬레이션된 것은 아니다. 중간고사와 기말고사 모두 실제 실력에 무작위 잡음(random noise; 오차)이 반영되었을 뿐이다. 평균으로의 회귀라는 경향성은 첫 번째와 두 번째 관측치들 간의 변동성에 따른 결과이다: 중간고사에서 점수를 매우 잘 받은 학생이 운이 좋거나 실력이 더 좋을 가능성이 크다. 마찬가지로 중간고사에서 망한 애들이 기말고사에서 열심히 준비해 평균보다 더 나은 성적을 냈다는 것도 말이 된다. 이 문제에서 핵심은 Figure 6.4의 데이터에 대한 “순진한” 해석이 종종 허위적인(spurious) 효과를 추론하도록 연구자를 유인할 수 있다는 것이다. 이 경우는 “중간고사를 잘 본 친구는 기말고사에 나태해져서 성적이 더 잘 안나오고, 중간고사를 망친 학생은 더 열심히 공부해서 기말고사에 더 나아졌을 것이다”라는 진술로 이해할 수 있다. 이러한 오류를 “회귀의 오류(regression fallacy)”라고 한다. 실제 사례로는 심리학자 Amos Tversky와 Daniel Kahneman의 1973년 연구가 있다. 항공학교에서 심리학자들의 조언에 따라 칭찬을 통해 성과를 제고하는 일종의 교육방침을 수립했는데, 강사들이 주장하기를 심리학자들이 이야기한 것과는 달리 칭찬해주니까 그 다음에 잘 못하더라는 것이었다. 이에 대한 설명은 다음과 같다. 항공 조작에 있어서 회귀란 필연적이다. 왜냐하면 조작 성과는 완벽하게 안정적이지 않고(reliable), 연이은 조작 간에 있어서 실력 향상은 더디기 때문이다. 따라서 한 번의 시도에 유독 좋은 성과를 낸 파일럿이 있다고 하더라도 다음 시도에서는 상대적으로 더 못할 가능성이 크다. 이는 첫 번째 성공에 대한 강사들의 반응(칭찬)에 무관하게 그러하다.\\(\\cdots\\) 보통 뭘 잘할 때 칭찬하고, 못할 때 처벌한다. 하지만 회귀의 관점에서 보자면 처벌받고 난 이후에 더 잘할 가능성이 있고, 보상을 받고 난 이후에 더 못할 수 있다. 결과적으로, 처벌에 대한 보상, 그리고 보상에 대한 처벌에 일생동안 노출되어 있는 것이다. 이 이야기의 핵심은 예측에 대한 양적 이해(quantitative understanding)는 변동성(variation)과 인과성(causality)에 대한 근본적인 질적 혼동(qualitative confusion)을 명확하게 한다는 것이다. 순수하게 수리적 관점에서 가장 조작을 잘 하는 파일럿은 실력이 다른 파일럿에 비하여 점점 떨어질 것이고, 가장 못하는 파일럿은 점차 잘 할 것이다. 마찬가지로 모든 키 큰 엄마로부터 나온 딸들은 평균적으로 엄마들만큼은 크지 않을 것이고 평균으로 수렴하게 될 것이다. 6.5.2 Relation of “regression to the mean” to the larger themes of the book 앞서 설명한 회귀의 오류는 비교에 대한 잘못된 해석의 한 사례라고 볼 수 있다. 인과추론에 있어 보다 핵심적인 것은, “같은 것끼리 비교해야 한다”는 것이다. 중간고사와 기말고사 성적에 관련된 예제를 다시 생각해보자. 인과적 주장은 “중간고사에서 잘 못한 학생이 동기부여가 되어서 기말고사에 더 열심히 준비한 반면, 중간고사에서 잘 한 학생은 안심하고 노는 바람에 기말고사를 망치고 말았을 것이다”라고 할 수 있다. 이 비교에서 종속변수인 \\(y\\)는 기말고사 점수이고 예측변수 \\(x\\)는 중간고사 점수이다. 문제는 \\(x\\)에 있어서 한 단위가 변화한 학생을 비교할 때, \\(y\\)에 있어서 \\(\\frac{1}{2}\\)만큼의 차이를 기대할 수 있다는 것에 있다. 이 결과는 기울기가 1인 경우와 비교되었기 때문에 나타난 결과이다. 회귀분석 결과와 Figure 6.4에서 나타난 경험적 패턴은 암묵적인 디폴트 모델, 중간고사와 기말고사 성적이 모두 같다라고 보는 모델과 비교한 것이다. 그러나 기울기가 1인 모델과 0.5인 모델 간의 비교는 부적절하다. 왜냐하면 디폴트 모델 자체가 문제가 있기 때문이다. 우리는 중간고사 기말고사가 어떠한 의도적 개입이 존재하지 않았을 때, 완전히 동일할 것이라고 생각할 그 어떠한 근거도 가지고 있지 않기 때문이다. 결국 Gelman, Hill, and Vehtari (2020) 은 이 부분에서 회귀분석이 경험적 경향성에 대한 정보는 줄 수 있지만 인과적 관계를 담보해주지 않는다는, “Association does not mean causation”이라는 말을 굉장히 돌려돌려 여러가지 방식으로 다른 표현을 가지고 설명해주고 있다. References "],["linear-regression-with-a-single-predictor.html", "Chapter 7 Linear regression with a single predictor 7.1 Example: predicting presidential vote share from the economy 7.2 Checking the model-fitting procedure using fake-data simulation 7.3 Formulating comparisons as regression models", " Chapter 7 Linear regression with a single predictor 회귀분석이란 본질적으로 주어진 설명변수들, \\(x_1, x_2, \\dots, x_n\\)로부터 결과변수 \\(y\\)를 예측하는 기법이다. 이 챕터에서는 하나의 연속형 확률변수 \\(x\\)로 연속형 확률변수 \\(y\\)를 예측하는 선형모델 \\(y_i = a + bx_i + \\text{error}\\)을 데이터 \\((x_i, y_i), i=1, \\cdots, n\\)에 적합하는 절차에 대해서 살펴본다. 7.1 Example: predicting presidential vote share from the economy Figure 7.1은 선거와 경제에 관한 에피소드를 보여준다. 정치학자 Douglas Hibbs가 경제성장 하나만 가지고 선거를 예측하고자 했던 “빵과 평화” 모델에 바탕을 둔 에피소드이다. 추가적인 정보가 더해진다면 더 나은 예측이 가능하겠지만 이 예제는 단순한 모델이 가지는 일종의 미학을 보여준다. Figure 7.1: Douglas Hibbs’s “bread and peace” model of voting and the economy. Presidential elections since 1952 are listed in order of the economic performance at the end of the preceding administration (as measured by inflation-adjusted growth in average personal income). Matchups are listed as incumbent party’s candidate versus other party’s candidate. The better the economy was performing, the better the incumbent party’s candidate did, with the biggest exceptions being 1952 (Korean War) and 1968 (Vietnam War). 7.1.1 Fitting a linear model to data Figure 7.2는 경제와 선거 데이터를 예측의 문제로서 보여준다. 두 정당 중 집권당의 득표율을 vote로, 이전 연도의 개인의 평균 소득 성장을 growth로 코딩한 데이터이다. Figure 7.2: (a) Predicting elections from the economy: the data in Figure 7.1 expressed as a scatterplot, with one data point for each year, (b) the data with the linear fit, \\(y = 46.3 + 3.0x\\). Repeated from Figure 1.1. 7.1.2 Understanding the fitted model lm() 함수로 추정한 모델의 결과는 다음과 같다: summary(model7.2); ## ## Call: ## lm(formula = I(vote * 0.01) ~ I(growth * 0.01), data = hibbs) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.089929 -0.006674 0.002556 0.023225 0.053094 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 0.46248 0.01622 28.514 8.41e-14 *** ## I(growth * 0.01) 3.06053 0.69627 4.396 0.00061 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.03763 on 14 degrees of freedom ## Multiple R-squared: 0.5798, Adjusted R-squared: 0.5498 ## F-statistic: 19.32 on 1 and 14 DF, p-value: 0.00061 sigma(model7.2) ## [1] 0.03763288 결과적으로 회귀선은 \\(y = 46.3 + 3.0x\\)로 표현할 수 있다. \\(x=0\\)일 때(경제성장이 0일 때), 집권당의 후보는 약 46.3%의 득표율을 보일 것으로 예측된다(진다는 뜻; 50% 아래니까). 경제성장이 0이라는 얘기는 집권당이 형편없는 성과를 냈다는 뜻이므로 일종의 경제투표가 이루어졌다고 이해할 수 있다. 0보다 큰 경제성장의 각 퍼센트마다 집권당의 기대득표율은 46.3%보다 3%p씩 높아진다. 계수에 대한 표준오차의 크기가 작다. 일반적으로 절편값에 대한 표준오차는 크게 신경쓰지 않지만 기울기에 대한 표준오차는 추정값의 불확실성에 대한 측정지표이므로 중요하게 간주된다. 계수값의 불확실성이 크다면, 표본을 새롭게 뽑을 때마다 그 결과가 크게 달라질 가능성이 크다는 것을 의미한다. 추정된 잔차의 표준편차는 약 0.038로 이 선형 모델이 선겨 결과를 약 3.8%p 내에서 예측한다는 것을 의미한다. 이는 모델을 통한 예측이 어느 정도 불확실성을 내포하고 있음을 의미한다. 7.1.3 Graphing the fitted regression line 위의 Figure 7.2b와 같이 산포도와 함께 회귀선을 같이 보여줄 수 있다. coef() 함수는 선형모델의 추정된 계수값을 반환한다. 7.1.4 Using the model to predict 위의 모델을 가지고 2016년 민주당의 힐러리 클린턴과 공화당의 도널드 트럼프의 대선에 적용해볼 수 있다. 선형모델은 \\(46.3 + 3.0 * 2.0 = 52.3\\)을 예측한다. 이 예측된 득표율 하나 가지고는 힐러리가 2016년도에 이길 가능성이 얼마나 되는지를 예단하기 힘들다. 우리는 심지어 이 예측 결과에 있어서 존재할 수 있는 불확실성 또한 평가해야 한다. Figure 7.3은 예측 결과가 52.3을 평균으로 하고 3.8을 표준편차로 하는 확률분포로부터 도출된 결과라는 것을 보여주고 이를 어떻게 이해하는 것이 바람직한지를 보여준다. 힐러리가 대중 투표에서 이길 확률을 추정하기 위해서 우리는 득표율에 대한 예측결과를 사용할 수 있다. 힐러리는 50% 이상의 표를 얻으면 승리한다. Figure 7.3에서 음영처리된 부분이 바로 그 확률을 보여준다. R에서도 주어진 통계치로 다음과 같이 확률을 구할 수 있다: 1 - pnorm(50, 52.3, 3.8). 결과인 0.72는 2016년 경제성장률이 2%라고 할 때, 힐러리가 대중투표에서 이길 확률이 약 72%라는 것을 의미한다. Figure 7.3: Forecast distribution for Hillary Clinton’s percentage of the two-party vote in 2016 based on an economic growth rate of 2%. The curve shows a normal distribution centered at the point forecast of \\(46.3 + 3.0 \\times 2.0 = 52.3\\) and with standard deviation of 3.9, the estimated uncertainty based on the model fit. The shaded area indicates the probability (based on the model) that Clinton wins, which is 1-pnorm(50, 52.3, 3.9), or 0.72. 왜 우리는 직접적으로 경제 데이터를 이용해서 누가 선거에서 이길지를 예측하는 것이 아니라 간접적으로 주어진 데이터를 이용해 얼만큼 득표할지를 예측한 뒤, 그 득표값이 승리 득표값에 비해 클 확률을 계산하는, 복잡한 접근법을 취하는 것일까? 단순히 선거의 승리자를 예측하지 않는 이유는 다음과 같은 세 가지 종류의 선거를 고려하는 것으로 확인할 수 있다. 1960년 Kennedy 대 Nixon의 선거와 같이 동등하게 나뉘어진 선거. 이런 유형의 선거의 승자를 예측하고자 하는 것은 합당하지도, 의미가 있지도 않다. 가장 최선의 방법은 실제 선거에서 나타날 득표율에 가장 가까운 결과를 예측하는 것이다. 2008년 Obama 대 McCain의 선거와 같이 어느 정도 경쟁적인 선거. 한 쪽이 승리할 것으로 예측되지만, 다른 한 쪽이 뒤집을 수도 있는 경우. 이 경우, 어떤 한 쪽이 승리할 것이라는 결정주의적인 선언을 하기보다는 득표 범위(vote margin)와 후보의 승리확률을 예측하게 된다. 1984년 Reagan 대 Mondale 선거와 같이 한 쪽이 일방적으로 승리하는 선거. 승자를 예측하는 것에 아무런 의미가 없다. 얼마나 정확하게 예측하는지는 살펴볼만하다. 이 파트를 읽으면서 느낀 점은, 선거는 어떻게 예측하던 앞으로 비슷한 선거에서 참고할만한 시나리오를 만드는 작업으로 귀결되기 마련이라는 것이다. 특정한 시나리오가 맞아 떨어졌다고 해서 그것이 완벽한 예측을 한 것이라 보기는 힘들고, 완전히 다른 예측을 했다고 해서 쓸모없는 시나리오는 아니라는 것이다. 7.2 Checking the model-fitting procedure using fake-data simulation 우리가 사실이라고 알고 있는 조건들을 통제하는 상황에서 회귀모델을 수행하는 예제를 통해 적합 결과를 확인할 수 있다. 7.2.1 Step 1: Creating the pretend world 모델의 모든 파라미터에 대한 값들이 진실값(true values)이라고 가정하는 것에서 시작하자. \\(y = 46.3 + 3.0x + \\text{error}\\)라는 관계가 참이며, 오차는 평균 0, 표준편차 3.8을 가진 정규분포를 따른다고 가정하자. 이제 모델을 통해 얻은 \\(y\\)의 분포가 실제 관측된 \\(y\\)의 분포와 일관된지를 분석할 수 있게 된다. a &lt;- 46.3 b &lt;- 3.0 sigma &lt;- 3.8 x &lt;- hibbs$growth n &lt;- length(x) 7.2.2 Step 2: Simulating fake data 페이크데이터의 벡터 \\(y\\)를 시뮬레이션하고 데이터프레임으로 만들어 보자: y &lt;- a + b*x + rnorm(n, 0, sigma) fake &lt;- data.frame(x, y) 7.2.3 Step 3: Fitting the model and comparing fitted to assumed values 다음 단계는 데이터에 회귀모델을 적합하는 것이다. 회귀모델 적합은 \\(\\alpha, \\beta, \\sigma\\)로 가정한 진실값들을 사용하지 않는다. fit7.4 &lt;- lm(y ~ x, data = fake) summary(fit7.4) ## ## Call: ## lm(formula = y ~ x, data = fake) ## ## Residuals: ## Min 1Q Median 3Q Max ## -6.9143 -3.1267 0.2755 2.9873 5.3633 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.9112 1.6207 29.561 5.11e-14 *** ## x 2.1798 0.6958 3.133 0.00734 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 3.761 on 14 degrees of freedom ## Multiple R-squared: 0.4122, Adjusted R-squared: 0.3702 ## F-statistic: 9.816 on 1 and 14 DF, p-value: 0.007335 추정된 계수값을 가정한 진실값, 46.3과 3.0과 비교해면, 적합된 결과가 충분히 합당하다는 것을 할 수 있다. 추정값은 정확하게 들어맞지는 않지만 오차 범위 내에 존재한다. 회귀분석 결과 객체로부터 계수값에 대한 추정값과 표준오차를 추출해서 비교해보도록 한다. b_hat &lt;- summary(fit7.4)$coef[2,1] b_se &lt;- summary(fit7.4)$coef[2,2] 모수의 진실값 \\(b\\)가 각각 \\(\\pm1\\)이나 \\(\\pm2\\)의 표준오차로 추정된 68%와 95%의 신뢰구간 내에서 얻을 수 있는지를 확인해보자 (Figure 4.1을 생각해보자): cover_68 &lt;- abs(b - b_hat) &lt; b_se cover_95 &lt;- abs(b - b_hat) &lt; 2*b_se cat(paste(&quot;68% coverage: &quot;, cover_68, &quot;\\n&quot;)) ## 68% coverage: FALSE cat(paste(&quot;95% coverage: &quot;, cover_95, &quot;\\n&quot;)) ## 95% coverage: TRUE 7.2.4 Step 4: Embedding the simulation in a loop 신뢰구간이 모수의 진실값을 포함하는가? 이를 확인하기 위해서 정규분포를 사용, 우리는 표집분포를 1000회의 반복문을 통해서 데이터 시뮬레이션, 모델 적합, 그리고 신뢰구간의 범주가 모집단을 포함하는지를 컴퓨팅해서 체크할 수 있다. n_fake &lt;- 1000 cover_68 &lt;- rep(NA, n_fake) cover_95 &lt;- rep(NA, n_fake) for (s in 1:n_fake){ y &lt;- a + b*x + rnorm(n, 0, sigma) fake &lt;- data.frame(x, y) fit7.4 &lt;- lm(y ~ x, data=fake) b_hat &lt;- summary(fit7.4)$coef[2,1] b_se &lt;- summary(fit7.4)$coef[2,2] cover_68[s] &lt;- abs(b - b_hat) &lt; b_se cover_95[s] &lt;- abs(b - b_hat) &lt; 2*b_se } cat(paste(&quot;68% coverage: &quot;, mean(cover_68), &quot;\\n&quot;)) ## 68% coverage: 0.628 cat(paste(&quot;95% coverage: &quot;, mean(cover_95), &quot;\\n&quot;)) ## 95% coverage: 0.915 이 결과는 mean(cover_68) = 67%, mean(cover_95) = 92%로 각 68%, 95%에서 멀리 떨어져 있지 않다는 것을 알 수 있다. 좀 차이가 나는 이유는 표본 규모가 작기 때문이다. 표본 규모를 반영한 자유도 14의 \\(t\\) 분포를 고려해서 추정해보자. n_fake &lt;- 1000 cover_68 &lt;- rep(NA, n_fake) cover_95 &lt;- rep(NA, n_fake) t_68 &lt;- qt(0.84, n - 2) t_95 &lt;- qt(0.975, n - 2) for (s in 1:n_fake){ y &lt;- a + b*x + rnorm(n, 0, sigma) fake &lt;- data.frame(x, y) fit &lt;- lm(y ~ x, data=fake) b_hat &lt;- summary(fit7.4)$coef[2,1] b_se &lt;- summary(fit7.4)$coef[2,2] cover_68[s] &lt;- abs(b - b_hat) &lt; t_68 * b_se cover_95[s] &lt;- abs(b - b_hat) &lt; t_95 * b_se } cat(paste(&quot;68% coverage: &quot;, mean(cover_68), &quot;\\n&quot;)) ## 68% coverage: 1 cat(paste(&quot;95% coverage: &quot;, mean(cover_95), &quot;\\n&quot;)) ## 95% coverage: 1 위의 시뮬레이션 결과는 95% 신뢰구간이 모수의 진리값을 포함하고 있다(TRUE)는 결과를 반환한다. 7.3 Formulating comparisons as regression models 회귀분석으로 비교하기 위해서는 더미변수(dummy variable)15의 개념이 필요하다. 더미변수는 어떤 데이터가 특정한 카테고리에 속하냐 속하지 않느냐에 따라 1 또는 0으로 나타내는 예측변수를 의미한다. 7.3.1 Estimating the mean is the same as regressing on a constant term 평균이 2.0, 표준편차가 5.0인 모집단으로부터 20개의 관측치를 시뮬레이션해보자. 소수점 둘째자리로 반올림한 시뮬레이션 결과는 다음과 같다: n_0 &lt;- 20 y_0 &lt;- rnorm(n_0, 2.0, 5.0) fake_0 &lt;- data.frame(y_0) print(round(y_0, 2)) ## [1] -0.43 0.27 10.66 7.22 1.14 4.33 3.74 -1.02 -5.09 -1.53 8.59 4.76 4.33 4.57 8.41 ## [16] 0.37 -2.74 3.09 -2.04 -1.84 무작위 표본이라는 것을 고려하면 모집단의 평균을 mean(y_0), 표준오차를 sd(y_0)/sqrt(n_0)으로 추정할 수 있다. mean(y_0); #2.3 ## [1] 2.339922 sd(y_0)/sqrt(n_0) # 1.07 ## [1] 0.9617659 절편에 대한 최소자승 회귀분석을 이용하여 동일한 결과를 얻을 수도 있다. fit7.5 &lt;- lm(y_0 ~ 1, data=fake_0) summary(fit7.5);sigma(fit7.5) ## ## Call: ## lm(formula = y_0 ~ 1, data = fake_0) ## ## Residuals: ## Min 1Q Median 3Q Max ## -7.4343 -3.4854 -0.2231 2.2792 8.3225 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.3399 0.9618 2.433 0.025 * ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.301 on 19 degrees of freedom ## [1] 4.301148 모수로서 절편이 2.0, 잔차의 표준편차인 \\(\\sigma\\)가 5.0이라는 것을 아는 상태에서 시뮬레이션을 했지만 작은 표본 규모는 불확실한 추정값(noisy estimates)을 산출한다. 추정값 2.35\\((\\beta)\\), 4.78\\((\\sigma)\\)는 주어진 표준오차 하에서 모수값을 포함한다는 것을 알 수 있다. 7.3.2 Estimating a difference is the same as regressing on an indicator variable 이번에는 새로운 그룹을 추가한다. 평균 8.0, 표준편차 5.0인 모집단으로부터 30개의 관측치를 추출한 집단이다. n_1 &lt;- 30 y_1 &lt;- rnorm(n_1, 8.0, 5.0) 각 집단의 평균을 직접 비교하고 표준오차도 컴퓨팅 할 수 있다: diff &lt;- mean(y_1) - mean(y_0) se_0 &lt;- sd(y_0)/sqrt(n_0) se_1 &lt;- sd(y_1)/sqrt(n_1) se &lt;- sqrt(se_0^2 + se_1^2) 시뮬레이션에 있어서 두 집단의 평균 차이는 6.13, 그 평균 차이의 표준오차는 1.12이다. 이 결과는 실제 모집단에서의 평균 차이인 6.0에 근접한 것이다. 데이터로부터 \\(y\\)라는 하나의 벡터와 더미변수 \\(x\\)를 합쳐서 회귀분석 프레임으로 재구성할 수 있다. 이때, 더미변수 \\(x\\)는 집단 0에 관측치가 속할 경우에 0, 집단 1에 관측치가 속할 때는 1로 코딩되어 있는 변수이다. \\[ x_i = \\begin{cases} 0 &amp; \\text{if observation $i$ is in group 0}\\\\ 1 &amp; \\text{if observation $i$ is in group 1}. \\end{cases} \\] R로 나타내면: n &lt;- n_0 + n_1 y &lt;- c(y_0, y_1) x &lt;- c(rep(0, n_0), rep(1, n_1)) fake &lt;- data.frame(x, y) fit7.6 &lt;- lm(y ~ x, data=fake) summary(fit7.6);sigma(fit7.6) ## ## Call: ## lm(formula = y ~ x, data = fake) ## ## Residuals: ## Min 1Q Median 3Q Max ## -8.4297 -3.2468 0.5283 2.3735 8.7054 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 2.3399 0.9687 2.415 0.019574 * ## x 5.0842 1.2506 4.065 0.000177 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.332 on 48 degrees of freedom ## Multiple R-squared: 0.2561, Adjusted R-squared: 0.2406 ## F-statistic: 16.53 on 1 and 48 DF, p-value: 0.0001772 ## [1] 4.332364 추정된 기울기는 6.13으로 앞에서 살펴본 \\(\\bar y_1 - \\bar y_0\\)의 차이와 동일하다. 표준오차도 거의 동일하지만 약간 다른데, 왜냐하면 두 평균 차이와 각각의 표준오차를 직접 구해서 비교할 경우 \\(se_0\\)과 \\(se_1\\)이라는 별개의 값을 활용해서 계산을 하는 반면, 회귀모델은 하나의 잔차의 표준오차 모수값을 추정하기 때문이다.16 Figure 7.4는 앞서 두 집단에 대한 추정치의 차이를 시각적으로 보여준다. 다른 예측변수들이 없을 때, 최소자승 회귀선은 \\((0, \\bar y_0)\\)와 \\((1, \\bar y_1)\\)의 두 점을 지난다. 회귀선의 기울기는 \\(\\bar y_1 - \\bar_0\\)의 차이를 보여준다. 이 챕터의 페이크데이터 시뮬레이션은 다음과 같은 내용을 보여준다: 직접 비교와 회귀분석의 결과가 동일한지 여부를 직접적으로 확인할 수 있다. 통계적 적합의 특성을 이해할 수 있도록 한다. Figure 7.4: Simulated-data example showing how regression on an indicator variable is the same as computing the difference in means between two groups. References "],["fitting-regression-models.html", "Chapter 8 Fitting regression models 8.1 Least squares, maximum likelihood, and Bayesian inference 8.2 Influence of individual points in a fitted regression 8.3 Least squares slope as a weighted average of slopes of pairs 8.4 Comparing two fitting functions: lm and stan_glm", " Chapter 8 Fitting regression models Gelman, Hill, and Vehtari (2020) 은 예제를 통해 실제로 통계모델을 데이터에 적용해보는 과정을 통해 단순선형회귀모델, 다중선형회귀모델, 비선형모델, 예측모델에 대한 적용과 인과추론에 대한 적용 등의 순으로 회귀분석 모델을 이해하는 데 초점을 두고 있다. 이 챕터는 회귀모델에 대한 추론의 수학적 구조에 관한 내용과 선형회귀모델의 추정법을 이해하는 데 도움이 되는 대수학(algebra)에 대해 살펴본다. 특히, 이 챕터에서 저자들은 stan_glm을 이용한 방법을 통해 전통적인 선형회귀모델과 베이지안 접근법에 입각한 모델 적합이 어떻게 다른지, 각 모델의 기저에 놓인 논리를 함께 설명하고 있다. 전반적으로 lm을 위주로 사용하여 이 책의 내용을 정리하고 있지만, 베이지안 접근법에 대해 숙지할 수 있는 기회라고 생각하여 이 챕터에서는 stan_glm을 함께 사용한 내용을 정리하고자 한다. 8.1 Least squares, maximum likelihood, and Bayesian inference 추론(inference)이란 무엇일까? 회귀모델을 추정하고 그 적합 결과의 불확실성을 평가하는 단계라고 할 수 있다. 데이터에 가장 잘 적합하는 계수값 \\(a\\)와 \\(b\\)의 값을 찾는 추정법인 최소자승법(least square)에서 시작한다. 다음으로는 최소자승법을 포함하여 로지스틱 회귀모델과 일반화 선형모델과 같은 내용들을 다루는 보다 일반적인 틀인 최대가능도(maximum likelihood)에 대해서 논한다. 마지막으로 사전정보(prior information)와 사후 불확실성(posterior uncertainty)에 대한 확률적 표현을 가능하게 하는 베이지안 추론(Bayesian inference)이라는 보다 일반적인 접근법을 학습한다. 8.1.1 Least squares 전통적인 선형회귀모델, \\(y_i = a + bx_i + \\epsilon_i\\)에서 계수값 \\(a\\)와 \\(b\\)는 오차 \\(\\epsilon_i\\)를 최소화하도록 추정된 값이다. 만약 관측치의 개수\\((n)\\)가 2보다 많다면, 일반적으로 데이터를 완벽하게 설명하는(perfect fit) 선을 찾기란 불가능하다. 데이터를 완벽하게 설명하는 회귀선이란 모든 관측치 \\(i = 1, \\dots, n\\)에 대해 구축한 모델 \\(y_i = a + bx_i\\)에 오차가 존재하지 않는다는 것을 의미한다. 대개 추정의 목적은 잔차의 제곱합(sum of the squares of the residuals)을 최소화하는 추정값 \\((\\hat a, \\hat b)\\)를 찾는 것에 있다. 이때, 잔차, \\(r_i = y_i - (\\hat a + \\hat b x_i)\\). 다르게 말하면 개별 관측된 데이터 하나하나와 주어진 \\(x\\)를 모델에 투입해 예측한 값, \\(\\hat y\\) 간의 차이를 말한다. 모델이 예측력이 뛰어나다면 이 잔차의 크기는 매우 작을 것이다. Gelman, Hill, and Vehtari (2020, 103) 은 잔차(\\(\\text{Residuals: }r_i = y_i - (\\hat a + \\hat b x_i)\\))와 오차(\\(\\text{Errors: }\\epsilon_i = y_i - (a + b x_i)\\))를 구별한다. 모델은 오차로 쓰기도, 잔차로 쓰기도 한다. 오차는 모집단 수준에서의 실제와 모델 간의 차이를 의미하며, 잔차는 표본 수준에서의 실제와 모델 간의 차이를 보여준다. 즉, 모집단 수준의 모수인 오차는 또 다른 모수인 \\(a\\), \\(b\\)를 알지 못하듯, 알 수 없기에 계산할 수도 없다. 잔차의 제곱합(Residual sum of squares; RSS)은 다음과 같이 계산할 수 있다: \\[ \\mathrm{RSS}= \\sum^{n}_{i=1}(y_i - (\\hat a + \\hat b x_i))^2. \\] \\(\\mathrm{RSS}\\)를 최소화하는 \\((\\hat a, \\hat b)\\)는 최소제곱 또는 일반화최소제곱(ordinary least squares), 또는 OLS 추정값이라고 불리며 다음과 같이 행렬 방식으로도 쓸 수 있다. \\[ \\hat \\beta = (X^t X)^{-1}X^t y. \\] 이때 \\(\\beta = (a, b)\\)는 계수값을 나타내는 벡터이고 \\(X = (1, x)\\)는 회귀모델에서 예측변수의 행렬을 의미한다. 이 행렬에서 1은 1로 이루어진 열을 보여주는, 회귀모델의 상수항(constant term)으로 회귀모델을 추정할 때 기울기와 함께 절편값도 추정하므로 반드시 포함되어야 하는 열이다. 위의 행렬은 예측변수의 수가 몇이든 간에 최소자승 회귀모델에 적용할 수 있다. 일단 예측변수가 하나인 모델만 두고 보면 다음과 같이 기울기와 절편을 구할 수 있다. \\[ \\begin{aligned} \\hat b =&amp;\\frac{\\sum^n_{i=1}(x_i-\\bar x)y_i}{\\sum^n_{i=1}(x_i-\\bar x)^2}\\\\ \\hat a =&amp;\\bar{y}-\\hat b\\bar x \\end{aligned} \\] 최소제곱 회귀선은 다음과 같이 나타낼 수 있다. \\[ y_i = \\bar y + \\hat b(x_i-\\bar x) + r_i \\] 이 회귀선은 \\((\\bar x, \\bar y)\\), 데이터의 평균을 지난다. 8.1.2 Estimation of residual standard deviation \\(\\sigma\\) 회귀모델에서 오차 \\(\\epsilon_i\\)는 평균이 0이고 표준편차가 \\(\\sigma\\)인 분포를 따른다. 평균이 0인 것은 오차의 정의에 따른 것이고, 오차의 표준편차는 데이터로부터 추정될 수 있다. \\(\\sigma\\)를 추정하는 가장 일반적인 방법은 잔차의 표준편차를 구하는 것이다: \\(\\sqrt{\\frac{1}{n}\\sum^n_{i=1}r^2_i} = \\sqrt{\\frac{1}{n}\\sum^n_{i=1}(y_i-(\\hat a + \\hat b x_i))^2}\\). 하지만 위와 같은 공식을 이용할 경우, 잔차의 제곱합을 최소화하기 위해 데이터에 기초해 \\(\\hat a\\)와 \\(\\hat b\\)를 구하기 때문에 과적합(overfitting)으로 인해 \\(\\sigma\\)를 과소추정할 가능성이 크다. 이 과적합의 문제를 해결하기 위해, 빈도주의적 접근법에서는 잔차의 표준편차를 구할 때 \\(n-2\\)를 분포로 취하여 추정한다: \\[ \\hat \\sigma = \\sqrt{\\frac{1}{n-2}\\sum^n_{i=1}(y_i - (\\hat a + \\hat b x_i))^2}. \\] 위의 공식은 예측변수가 여러 개, 예를 들어 \\(k\\)개 일 때에 보다 일반적으로 사용될수 있다. 즉, \\(y = X\\beta + \\epsilon\\)은 \\(n\\times k\\text{개의 예측변수인 행렬 }X\\)는 다음과 같이 나타낼 수 있다. \\[ \\hat \\sigma = \\sqrt{\\frac{1}{n-k}\\sum^n_{i=1}(y_i - (X_i\\hat\\beta))^2}. \\] 8.1.3 Computing the sum of squares directly 공식에 따라서 최소자승법을 통한 계수값을 컴퓨팅으로 직접 추정할 수 있다. 잔차의 제곱합(residual sum of squares)에 대한 rss의 함수를 작성한다. rss &lt;- function(x, y, a, b){ # x and y are vectors, a and b are scalars resid &lt;- y - (a + b*x) return(sum(resid^2)) } rss 함수의 조건은 \\(x\\)와 \\(y\\)가 같은 길이의 벡터여야 하며, 결측치(NA)가 없어야 한다는 것이다. \\((a, b) = (46.2, 3.1)\\)을 최소자승법으로 구한 추정치라고 할 때, 잔차의 제곱합은 위의 함수로 평가할 수 있다: rss(hibbs$growth, hibbs$vote, 46.3, 3.0). 8.1.4 Maximum likelihood 선형모델로 구한 오차가 독립적이고 정규분포를 따른다면, 즉 \\(y_i \\sim N(a+bx_i, \\sigma^2)\\)라고 하면 최소자승법으로 구한 \\((a, b)\\)에 대한 추정값은 최대가능도 추정치(maximum likelihood estimate; MLE)가 된다. 회귀모델에서 가능도 함수(likelihood function)는 주어진 모수와 예측변수로 이루어진 데이터의 확률 밀도로 정의된다. \\[ \\Pr(y|a, b, \\sigma, X) = \\prod^{n}_{i=1}\\mathrm{N}(y_i|a + bx_i, \\sigma^2) \\] 이때, 가능도 함수에서 \\(\\mathrm{N(\\cdot|\\cdot, \\cdot)}\\)은 정규확률밀도 함수이다: \\[ \\mathrm{N}(y|m, \\sigma^2) = \\frac{1}{2\\pi\\sigma}\\mathrm{exp}\\bigg(-\\frac{1}{2}\\Big(\\frac{y-m}{\\sigma}\\Big)^2\\bigg). \\] 첫 번째, 가능도 함수는 가능도를 최대화하는 것의 필요조건이 잔차의 제곱합을 최소화하는 것이라는 의미이다. 따라서 최소자승법으로 구한 추정치 \\(\\hat \\beta = (\\hat a, \\hat b)\\)는 정규분포를 가정한 모델에서 최대가능도 추정값으로 간주할 수 있다. 일반적인 OLS로 잔차의 표준편차를 구했을 때와, \\(\\sigma\\)에 대한 최대가능도 추정량을 구했을 때의 차이는 아래의 두 식에서 구별할 수 있다: \\[ \\begin{aligned} \\text{OLS: }&amp;\\hat \\sigma = \\sqrt{\\frac{1}{n-2}\\sum^n_{i=1}(y_i - (\\hat a + \\hat b x_i))^2}\\\\ \\text{MLE: }&amp;\\hat \\sigma = \\sqrt{\\frac{1}{n}\\sum^n_{i=1}(y_i - (\\hat a + \\hat b x_i))^2} \\end{aligned} \\] 즉, MLE로 구할 때에는 예측변수의 개수에 따른 일종의 조정이 이루어지지 않는다는 것을 확인할 수 있다. 그렇다면 OLS에 비해 MLE로 조건이 동일한 상황에서 선형회귀모델을 추정할 경우, MLE는 \\(\\hat \\sigma\\)를 미세하게 과소추정할 수 있다(분모가 조금 더 크니까; \\(n &gt; n-2\\)). 베이지안 추론에서는 모델의 각 파라미터에 대한 불확실성이 자동적으로 다른 모수들의 불확실성을 설명한다. 베이지안 추론의 이와 같은 속성은 예측변수의 수가 많을 경우 분석의 장점을 가지며 보다 복잡하거나 위계성을 가진 모델을 추정할 때 유리하다. 8.1.5 Where do the standard errors come from? Using the likelihood surface to assess uncertainty in the parameter estimates 최대가능도추정법에서 가능도 함수는 최대가능도 추정량이 가장 클 때를 보여주는 역할을 수행한다고 볼 수 있다. fit8.1 &lt;- lm(vote ~ growth, data = hibbs) arm::display(fit8.1) ## lm(formula = vote ~ growth, data = hibbs) ## coef.est coef.se ## (Intercept) 46.25 1.62 ## growth 3.06 0.70 ## --- ## n = 16, k = 2 ## residual sd = 3.76, R-Squared = 0.58 Figure 8.1은 계수값 \\(a\\)와 \\(b\\)에 대한 함수로 가능도의 예제를 보여준다. 엄밀하게 말하면, 이 모델은 세 개의 파라미터(\\(a, b, \\sigma\\))를 가지고 있다. 그러나 간명하게 보여주기 위하여 추정된 \\(\\hat \\sigma\\)의 조건 하에서 \\(a\\)와 \\(b\\)의 가능도를 보여주었다. Figure 8.1: Likelihood function for the parameters \\(a\\) and \\(b\\) in the linear regression \\(y = a + bx + \\text{error}\\), of election outcomes, \\(y_i\\) , on economic growth, \\(x_i\\). Figure 8.2a는 \\((\\hat a, \\hat b) = (46.2, 3.1)\\)가 최대가능도 추정값이라는 것을 보여준다. Figure 8.1에서 가능도가 최고였을 때의 값, \\(a\\)와 \\(b\\)인 것이다. Figure 8.2a는 파마리터에 대해 \\(\\pm 1\\) 표준오차에서의 불확실성도 함께 보여주고 있다. 가능도 함수는 최대값과 범주만 가지는 것이 아니라 상관관계도 가지고 있다. 가장 큰 가능도를 둘러싼 영역(area)은 Figure 8.2b에서와 같이 나타낼 수도 있다. 불확실성의 타원 형태는 우리로 하여금 데이터에 대한 정보나 두 파라미터의 결합에 관한 모델의 정보를 제시한다. 여기에서는 두 파라미터 값은 부의 상관관계를 가진다. Figure 8.2: (a) Mode of the likelihood function (that is, the maximum likelihood estimate \\((\\hat a, \\hat b)\\)) with \\(\\pm 1\\) standard error bars shown for each parameter. (c) Mode of the likelihood function with an ellipse summarizing the inverse-second-derivative-matrix of the log likelihood at the mode. 추론적 상관관계를 이해하기 위해서 산포도와 회귀선을 하나의 플롯으로 그려보았다. Figure 8.3b는 데이터에 따른 선의 가능한 범위를 보여준다. 즉, 시뮬레이션을 통해 표본이 다를 때 나타날 수 있는 선의 가능한 형태들을 함께 보여준다고 이해할 수 있다. Figure 8.3: (a) Election data with the linear fit, \\(y = 46.3 + 3.0x\\), repeated from Figure 7.2b. (b) Several lines that are are roughly consistent with the data. Where the slope is higher, the intercept (the value of the line when \\(x = 0\\)) is lower; hence there is a negative correlation between a and b in the likelihood. 8.1.6 Bayesian inference 최소자승법이나 최대가능도는 데이터에 최적합하는 모수값을 찾지만 적합하는 방식 그 자체를 제약하거나 혹은 어떠한 방식으로 유도하지는 않는다. 하지만 Section 9.3에서 더 자세히 논의하겠지만, 베이지안 접근법은 모델에 포함되는 모수값에 대한 사전정보를 가진다. 베이지안 추론은 모수에 대한 외부적 정보를 확률적으로 보여주는 사전분포에 대한 가능도와 곱하는 식으로 사전 정보와 데이터 간의 일종의 조정한 결과를 산출하는 접근법을 취한다. 이와 같이 가능도와 사전분포를 결합한 결과로 얻어지는 것을 사후분포(posterior distribution)이라고 하며, 사후분포는 데이터를 본 이후에 모수에 대한 우리의 지식을 요약해서 보여준다. 즉, 간단하게 얘기하면 빈도주의가 모수는 어떤 분포에서 도출되었다는 모집단에 대한 가정에서 시작하는 반면, 베이지언 접근법은 그러한 가정을 일종의 사전정보로 받아들이고 실제로 관측하는 데이터에 대한 정보를 그 사전정보와 결합시켜 나가며 사후분포를 산출해 나가는 것이다. 앞서 언급한 바와 같이 사후분포는 가능도 함수로부터 유도된 것이다. 최대가능도추정법을 일반화하면 제한된 최대가능도 추정법(maximum penalized likelihood estimation)이라고 할 수 있는데, 이는 사전분포를 일종의 “제약 함수”(penalty function)으로 간주하여 모수를 잘 반영하지 않는 값에 대한 가능도를 일종의 저평가(downgrade)하는 것이다. 다른 말로 사전분포와 데이터에서만 얻은 것 사이의 어딘가를 추정하는 것이다. 사전분포를 고정시키기 때문에 제한된 최대가능도 추정량은 순수 최대가능도 또는 최소자승법 추정량에 비해 더 안정적일 수 있다.17 사전정보를 더하는 것 외에도 베이지언 추론은 확률에 대한 불확실성을 표현한다는 점에서 빈도주의적 접근과 차이가 있다. 예를 들어 stan_glm을 통해 모델을 적합할 때, 우리는 사후분포를 보여주는 일련의 시뮬레이션 추출 결과를 얻을 수 있고, 그 사후분포의 중앙값, 중앙값 절대편차, 시뮬레이션에 기초한 불확실성 구간 등을 요약해서 제시할 수 있다. Gelman, Hill, and Vehtari (2020) 이 베이지안 방법을 선호하는 이유는 확률과 시뮬레이션을 이용한 불확실성의 표현이 보다 유연하다는 것과 사전정보를 추론에 포함하는 것을 바탕으로 안정적 추론이 가능하다고 보기 때문이다. 8.1.7 Point estimate, mode-based approximation, and posterior simulations 데이터에 전반적으로 최적합하는 계수값의 벡터인 점추정량(point estimate)는 최소자승법으로 구한 해(solution)이다. 베이지언 모델에서는 이 점추정량에 해당하는 것이 데이터와 사전분포에 전반적으로 최적합하는 사후 최빈값(posterior mode)라고 할 수 있다. 하지만 우리가 원하는 것은 추정량뿐만이 아니다. 추정량을 둘러싼 불확실성도 알고자 하는데, 이는 빈도주의적 접근처럼 표준오차의 개념으로 접근할 수 있지만 베이지언에서는 다변량 불확실성으로 나타나는 확률분포를 통해 시뮬레이션된 추정량의 사후분포를 얻을 수 있기 때문에 분위값으로 직접 제시할 수 있게 된다. 8.2 Influence of individual points in a fitted regression 얼마나 \\(y_i\\)의 변화가 \\(\\hat b\\)의 변화로 이어지는지를 통해 데이터의 개별 관측치의 영향력을 살펴본다. \\(y_i\\)에서의 1 증가로 나타나는 \\(\\hat b\\)에서의 변화를 \\((x_i - \\bar x)\\)에 대한 비율로 나타낸다. 만약 \\(x_i = \\bar x\\)라면, 회귀계수에 대한 \\(i\\)의 영향력은 0이다. 왜냐하면 \\((\\bar x - \\bar x) = 0\\)이니까. \\(x_i &gt; \\bar x\\)이면, \\(i\\) 지점에서의 관측치는 정의 영향력(positive influence)을 가지고 있고, \\(x_i\\)가 평균으로부터 멀어질수록 \\(x_i\\)의 영향력이 커진다고 할 수 있다. \\(x_i &lt; \\bar x\\)이면, \\(i\\) 지점에서의 관측치는 부의 영향력(negative influence)을 가지고 있고, \\(x_i\\)가 평균으로부터 멀어질수록 \\(x_i\\)의 절대적인 영향력이 커진다고 할 수 있다. Figure 8.4는 회귀분석에 있어서 개별 관측치의 영향력을 이해하는 시각화의 방법을 보여준다. 회귀계수 \\(\\hat \\beta\\)에 대해 추정된 벡터는 데이터 벡터 \\(y\\)와 일반화 선형모델의 선형 함수에 따라 산출된 결과인 것이다. Figure 8.4: Understanding the influence of individual data points on the fitted regression line. Picture the vertical lines as rubber bands connecting each data point to the least squares line. Take one of the points on the left side of the graph and move it up, and the slope of the line will decrease. Take one of the points on the right side and move it up, and the slope will increase. Moving the point in the center of the graph up or down will not change the slope of the fitted line. 8.3 Least squares slope as a weighted average of slopes of pairs 회귀모델 \\(y = a + bx + \\text{error}\\) 중 \\(x\\)가 더미변수일 때, 최소자승법으로 구한 추정값, 계수 \\(b\\)는 \\(x\\)가 0일 때와 1일 때, 각 집단의 결과변수의 평균 차이이다: \\(\\bar y_1 - \\bar y_0\\). \\(x\\)가 연속형일 경우에는 기울기의 가중평균으로 추정된 \\(\\hat b\\)를 나타낼 수 있다: \\[ \\text{slope}_{ij} = \\frac{y_j - y_i}{x_j - x_i}. \\] 최적합하는 회귀곡선의 기울기는 개별 곡선들의 평균으로 정의된다. 관측치가 있다고 할 때, \\(i\\)와 \\(j\\)라고 할 수 있는 두 관측치 간의 선, 그 기울기를 모든 관측치를 대상으로 구한 뒤 그 평균을 구하는 것이다. 그리고 그 때, 그 평균을 \\((x_j - x_i)^2\\), 두 값의 차이에 제곱(음수 부호를 없애주는 과정)한 값으로 가중치를 부여하는 것이다. \\[ \\begin{aligned} \\text{weighted average of slopes}&amp;=\\frac{\\sum_{i,j}(x_j-x_i)^2\\frac{y_j-y_i}{x_j-x_i}}{\\sum_{i,j}(x_j-x_i)^2}\\\\ &amp;=\\frac{\\sum_{i,j}(x_j-x_i)(y_j-y_i)}{\\sum_{i,j}(x_j-x_i)^2} \\end{aligned} \\] 8.4 Comparing two fitting functions: lm and stan_glm R에서 선형회귀모델을 추정하는 두 가지 방법: lm: 전통적인 최소자승법을 사용한 회귀분석모델로 추정량과 표준오차를 적합하는 함수이다. stan_glm: 베이지언 추론으로 분석하며, 추정량과 표준오차, 그리고 사후 시뮬레이션을 제시한다. stan_glm을 사용하는 두 가지 이유: stan_glm으로 자동적으로 컴퓨팅되는 시뮬레이션 결과는 불확실성을 제시함으로써 현재 우리가 가진 데이터, 앞으로 가지게 될 데이터, 그리고 모수에 대한 어떤 함수든 간에 표준오차와 예측분포를 얻을 수 있게 해준다. 시뮬레이션을 통한 베이지언 추론은 더 안정적인 추정량과 사전정보를 포함한 예측을 제시한다. 베이지언 추론은 데이터가 빈약하거나(small-n), 강한 사전정보가 있을 때, 빈도주의적 접근과는 다른 결과를 가져올 가능성이 높다. 또한 모델이 복잡하거나 위계성을 가지고 잇을 경우에는 전통적 접근과 베이지언 추론 간 결과 차이가 있을 수 있다. 8.4.1 Reproducing maximum likelihood using stan_glm with flat priors and optimization 베이지언 추정량과 전통적인 추정량(빈도주의적 추정량)을 한 번 R 코드로 살펴보자. mydata라는 데이터가 있다고 하자. stan_glm(y ~ x, data = mydata) 사전정보가 설정되지 않은 채로 stan_glm()를 돌리면, 디폴트로 약한 사전정보(계수값이 0에 수렴한다는)를 가지고 회귀모델을 적합한다. 전통적 추론에 가까운 결과를 얻고 싶으면 평탄한 사전정보(flat prior)를 사용할 수 있고, 이 경우 사후분포는 가능도와 같아진다. 아래의 코드를 보자. stan_glm(y ~ x, data=mydata, prior_intercept=NULL, prior=NULL, prior_aux=NULL) stan_glm의 세 파라미터에 NULL을 부여했다는 것은ㅇ 각기 절편, 계수값, 그리고 \\(\\sigma\\) 모두에 평탄한 사전정보(각각이 서로 다르다거나 특정한 값을 가진다는게 아니라 무던~하다는)를 부여했다는 것을 의미한다. 그리고 stan_glm으로 기존의 lm과 가까운 결과를 얻고 싶다면 표집(sampling) 대신에 최적화(optimization)를 하면 된다. 그 결과는 제한 최대가능도 추정량을 산출하기 때문이다. stan_glm(y ~ x, data=mydata, prior_intercept=NULL, prior=NULL, prior_aux=NULL, algorithm=&quot;optimizing&quot;) 8.4.2 Running lm 확률적 예측 필요없이 최대가능도 추정량만 필요하다고 하면 R의 lm() 함수로 추정하면 된다. lm(y ~ x, data = mydata) 8.4.3 Confidence intervals, uncertainty intervals, compatibility intervals 신뢰구간이란 기본적으로 추론의 불확실성을 보여주는 것이다. 불편향(unbiased), 정규분포된 추정량에 대한 가정을 바탕으로 그 추정량으로부터 \\(\\pm 1\\) 표준오차에 약 68%의 확률로 모수의 진실값을 포함할 확률이 높다고 보는 것이며, \\(\\pm 2\\) 표준오차에는 95% 확률로 그러할 것이라고 생각하는 것이다. 선형회귀모델에 있어서 잔차의 표준편차인 \\(\\sigma\\) 그 자체는 오차로 추정된다. 만약 \\(k\\)개의 회귀계수를 갖는 회귀모델이 \\(n\\)개의 데이터 관측치에 대해 적합하고자 한다면, \\(n-k\\) 자유도를 가진다고 할 수 있으며, 이때 회귀계수에 대한 신뢰구간은 \\(t_{n-k}\\) 분포에 따라 구할 수 있다. 만약 stan_glm으로 적합한다면 68%와 95% 신뢰구간 각각은 중위값에 \\(\\pm 1, \\pm 2\\)에 해당하는 중위값 표준편차 값을 구해주면 되고, 이 경우에 시뮬레이션을 통해 직접 그 구간을 산출할 수 있다. 예제를 한 번 살펴보자. x &lt;- 1:10 y &lt;- c(1,1,2,3,5,8,13,21,34,55) fake &lt;- data.frame(x, y) fit &lt;- stan_glm(y ~ x, data=fake, refresh = 0) print(fit) ## stan_glm ## family: gaussian [identity] ## formula: y ~ x ## observations: 10 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) -13.4 6.8 ## x 5.1 1.1 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 9.9 2.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 그리고 이 결과로부터 시뮬레이션을 추출할 수 있다. sims &lt;- as.matrix(fit) head(sims, n = 20) ## parameters ## iterations (Intercept) x sigma ## [1,] -3.8449564 3.475038 8.672660 ## [2,] -1.9260153 3.112200 9.016874 ## [3,] -21.9069149 6.176655 8.969247 ## [4,] -22.8506122 6.476414 8.811992 ## [5,] -13.2238727 5.607535 7.529085 ## [6,] -10.1305772 4.124203 6.679642 ## [7,] -17.4239561 5.901466 11.963498 ## [8,] -2.2007477 3.239140 10.885391 ## [9,] -3.0689087 3.474375 11.093255 ## [10,] -15.7840689 5.101348 10.520168 ## [11,] -9.5194438 3.396553 8.755429 ## [12,] -12.4910217 3.895171 8.923379 ## [13,] -38.6189464 7.996241 24.078604 ## [14,] -39.9440771 8.035341 21.344225 ## [15,] -31.8740525 7.211540 20.329915 ## [16,] -24.4038354 6.208415 10.279084 ## [17,] -10.4630620 4.980395 9.864549 ## [18,] -10.9709236 4.639559 10.787506 ## [19,] -5.5585543 3.733700 9.888777 ## [20,] 0.8256187 2.690757 10.205194 이때, 이 시뮬레이션 결과는 세 개의 열을 포함하는데 각각 절편, \\(x\\)에 대한 계수값, 그리고 잔차의 표준편차 \\(\\sigma\\)에 대한 시뮬레이션 결과이다. 95% 구간을 추출하기 위해서는 다음의 코드를 사용하면 된다. quantile(sims[,2], c(0.025, 0.975)); ## 2.5% 97.5% ## 2.614573 7.519634 quantile(sims[,&quot;x&quot;], c(0.025, 0.975)) ## 2.5% 97.5% ## 2.614573 7.519634 모든 신뢰구간은 불확실성을 보여주는 구간이라고 볼 수 있으며, 추정된 통계량에 대한 불확실성을 보여준다. References "],["prediction-and-bayesian-inference.html", "Chapter 9 Prediction and Bayesian inference 9.1 Propagating uncertainty in inference using posterior simulations 9.2 Prediction and uncertainty: predict, posterior_linpred, and posterior_predict 9.3 Prior information and Bayesian synthesis 9.4 Example of Bayesian inference: beauty and sex ratio 9.5 Uniform, weakly informative, and informative priors in regression", " Chapter 9 Prediction and Bayesian inference 베이지언 추론은 전통적인 추정법에서 다루지 않는 세 단계를 더 다루고 있다. 데이터와 모델은 모델의 파라미터들에 대한 일련의 시뮬레이션으로 요약하는 사후분포(posterior distribution)를 구성하기 위해 결합된다. 이 사후분포를 가지고 추정량에 대한 불확실성을 확인할 수 있다. 모델 파라미터의 불확실성을 설명하는 관측되지 않은, 또는 앞으로의 결과에 대한 시뮬레이션에 기초한 예측들을 얻을 수 있다. 사전분포를 사용해 모델에 추가적인 정보를 포함할 수 있다. 9.1 Propagating uncertainty in inference using posterior simulations 일단은 베이지언 시뮬레이션이 추론과 예측에 있어서의 불확실성을 표현하는 하나의 방법이라고만 이해를 하자. 예를 들어, 챕터 7에서 선거와 경제 간의 관계를 살펴보았던 예제를 다시 살펴보자. M9.1 &lt;- stan_glm(vote ~ growth, data = hibbs, refresh = 0) M9.1 %&gt;% print() ## stan_glm ## family: gaussian [identity] ## formula: vote ~ growth ## observations: 16 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 46.3 1.7 ## growth 3.0 0.7 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 3.9 0.8 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 이 숫자들은 각각 절편/기울기/잔차의 표준편차를 나타내는 파라미터 벡터 \\((a, b, \\sigma)\\)의 서로 다른 가능한 값들을 나타내는 시뮬레이션의 행렬을 요약한 것이다. 그 결과, 단 하나의 점추정값을 제시하기보다는 모수에 대한 불확실성을 반영한 사후시뮬레이션 결과들을 갖게 된다. 아래 sims가 시뮬레이션된 결과들을 행렬로 저장한 내용이며, 우린 이 행렬로부터 필요한 통계량을 추출할 수 있다. sims &lt;- as.matrix(M9.1) # Simulation results Median &lt;- apply(sims, 2, median) MAD_SD &lt;- apply(sims, 2, mad) print(cbind(Median, MAD_SD)) ## Median MAD_SD ## (Intercept) 46.252913 1.7292656 ## growth 3.040811 0.7275287 ## sigma 3.936428 0.7714837 편의상 사후 중앙값 표준편차를 표준오차라고 부르기도 한다(엄밀하게 두 개념은 다른 것이다). 9.1.1 Uncertainty in the regression coefficients and implied uncertainty in the regression line 불확실성 분포에 대한 베이지언의 개념을 이해하기 위해서는 계수값의 시뮬레이션 추출을 그래프로 나타내는 것이 도움이 될 수 있다. Figure 9.1은 선거를 예측하는 모델 적합 결과에 대한 절편과 기울기의 사후 시뮬레이션 값의 히스토그램을 보여준다. Figure 9.1: Posterior simulations of \\(a\\) and \\(b\\) from the regression model, \\(y = a + bx + \\text{error}\\). For each parameter, we display the simulation draws produced by stan_glm and also the posterior median \\(\\pm 1\\) and \\(2\\) mad sd’s. Figure 9.2a는 사후분포를 보여주는 산포도이다. Figure 9.2b는 \\((a, b)\\) 점들을 잇는 선 100개를 보여준다. 이 그래프는 적합된 회귀모델에 있어서 추론의 불확실성을 보여준다. 표본의 규모가 커질수록 계수값의 표준오차는 감소하며, Figure 9.2b는 하나의 선으로 수렴하게 될 것이다. 9.1.2 Using the matrix of posterior simulations to express uncertainty about a parameter estimate or function of parameter estimates 시뮬레이션을 통해 추론을 요약하여 제시하는 것의 실질적인 장점은 바로 직접적으로 추론을 이끌어내기 위해 시뮬레이션한 값들을 사용할 수 있다는 것에 있다. a &lt;- sims[,1] %&gt;% as.matrix() b &lt;- sims[,2] %&gt;% as.matrix() z &lt;- a/b print(c(median(z), mad(z))) ## [1] 15.177925 4.014095 9.2 Prediction and uncertainty: predict, posterior_linpred, and posterior_predict \\(y = a + bx + \\text{error}\\)라는 회귀모델을 적합한 이후에, 우리는 적합 결과를 새로운 데이터, 예측변수 \\(x^{\\text{new}}\\)로 예측하는 데 사용할 수 있다. 점예측치(\\(\\hat a + \\hat b x^{\\text{new}}\\)) 적합된 모델에 기초하여 새로운 \\(x\\)의 값에 대한 \\(y\\)의 평균 값을 가장 잘 추정하는 점추정치. \\(\\hat a\\)와 \\(\\hat b\\)는 불확실성을 반영하지 않은 점예측값이다. 불확실성을 포함한 선형예측변수(\\(a + b x^{\\text{new}}\\)) \\((a, b)\\)에 대한 추론의 불확실성을 나타낸다. 새로운 예측변수 \\(x^{\\text{new}}\\)에 대한 \\(y\\)의 기대값 또는 평균값의 불확실성의 분포를 제시한다. 새로운 관측값에 대한 예측 분포(\\(a + b x^{\\text{new}} + \\text{error}\\)) \\(x^{\\text{new}}\\)라는 새로운 예측변수와 새로운 관측치 \\(y\\)에 대한 불확실성을 보여준다. 표본 규모가 커질수록(\\(\\rightarrow \\infty\\)), 계수 \\(a\\)와 \\(b\\)는 더 정확하게 추정되며, 선형 예측변수의 불확실성은 0에 수렴하게 된다. 그러나 표본 규모가 커지더라도 새로운 관측값에 대한 예측분포의 불확실성은 0에 수렴하는 것이 아니라 잔차의 표준편차, \\(\\sigma\\)에 수렴한다. 9.2.1 Point prediction using predict 선거와 경제 데이터를 바탕으로 경제성장률 2.0%일때의 집권당의 득표율을 예측하고자 한다고 하자. 먼저 우리는 \\(x\\)의 가상의 값에 대한 데이터셋을 만들어야 한다. new &lt;- data.frame(growth = 2.0) 그럼 이제 점예측값을 컴퓨팅할 수 있다. y_point_pred &lt;- predict(M9.1, newdata=new) y_point_pred ## 1 ## 52.36415 마찬가지로 직접 컴퓨팅할 수도 있다. a_hat &lt;- coef(M9.1)[1] b_hat &lt;- coef(M9.1)[2] y_point_pred &lt;- a_hat + b_hat*new y_point_pred ## growth ## 1 52.33453 두 결과 모두 \\(46.3 + 3.0 \\times 2 = 52.3\\)이라는 값을 반환한다. 9.2.2 Linear predictor with uncertainty using posterior_linpred or posterior_epred posterior_linpred 함수를 이용해 적합된 회귀선의 값에 대한 불확실성을 얻을 수 있다. # Use function y_linpred &lt;- posterior_linpred(M9.1, newdata=new) y_linpred %&gt;% head(n = 20) ## ## iterations 1 ## [1,] 53.28234 ## [2,] 52.48851 ## [3,] 51.40536 ## [4,] 53.87927 ## [5,] 53.33107 ## [6,] 52.59851 ## [7,] 52.48331 ## [8,] 53.08895 ## [9,] 51.61434 ## [10,] 53.30091 ## [11,] 51.32071 ## [12,] 53.28453 ## [13,] 52.69170 ## [14,] 51.77340 ## [15,] 52.71569 ## [16,] 52.02432 ## [17,] 52.69049 ## [18,] 51.93764 ## [19,] 52.70163 ## [20,] 52.30842 # Compute by hand sims &lt;- as.matrix(M9.1) a &lt;- sims[,1] b &lt;- sims[,2] y_linpred &lt;- a + b*new y_linpred %&gt;% head(n = 20) ## growth ## 1 53.28234 posterior_linpred 함수는 평균이 점예측치와 같고 표준편차는 적합된 모델의 불확실성을 보여주는 분포로부터 얻어진 사후 시뮬레이션의 벡터를 반환한다. 마찬가지로 새로운 데이터 관측치를 가지고 기대 예측값을 구하는 posterior_epred 함수를 이용할 수 있다. 9.2.3 Predictive distribution for a new observation using posterior_predict 마지막으로 어떤 한 선거에서의 예측 불확실성을 나타내는 벡터를 계산할 수 있다. # Use function y_pred &lt;- posterior_predict(M9.1, newdata=new) y_pred %&gt;% head(n = 20) ## 1 ## [1,] 53.34335 ## [2,] 47.02423 ## [3,] 48.78543 ## [4,] 53.64529 ## [5,] 51.61796 ## [6,] 56.55096 ## [7,] 55.16892 ## [8,] 53.07260 ## [9,] 48.68477 ## [10,] 56.08386 ## [11,] 53.87223 ## [12,] 53.65538 ## [13,] 48.41906 ## [14,] 49.75108 ## [15,] 50.91417 ## [16,] 50.11859 ## [17,] 54.03190 ## [18,] 52.44453 ## [19,] 49.66674 ## [20,] 48.83045 # By hand n_sims &lt;- nrow(sims) sigma &lt;- sims[,3] y_pred &lt;- as.numeric(a + b*new) + rnorm(n_sims, 0, sigma) y_pred %&gt;% head(n = 20) ## [1] 43.09430 58.78669 50.27444 57.70791 62.74808 54.80009 54.70959 48.98187 51.49506 55.78395 ## [11] 54.79901 53.23100 51.02962 52.14421 59.38839 59.74599 51.92007 51.10829 51.82106 47.73279 이 두 결과 모두 시각적으로 요약하여 제시할 수 있다. hist(y_pred) 또는 요약통계치를 이용하여 숫자로 보여줄 수도 있다. y_pred_median &lt;- median(y_pred) y_pred_mad &lt;- mad(y_pred) win_prob &lt;- mean(y_pred &gt; 50) # 결과는 다음과 같다. cat(&quot;Predicted Clinton percentage of 2-party vote: &quot;, round(y_pred_median,1), &quot;, with s.e. &quot;, round(y_pred_mad, 1), &quot;\\nPr (Clinton win) = &quot;, round(win_prob, 2), sep=&quot;&quot;) ## Predicted Clinton percentage of 2-party vote: 53.1, with s.e. 4 ## Pr (Clinton win) = 0.78 9.2.4 Prediction given a range of input values predict, posterior_linpred, posterior_predict를 이용해서 예측값의 범위를 계산할 수 있다. 예를 들어, -2%부터 +4% 사이의 경제성장률의 가능한 값의 범위에서 선거 결과를 예측하는 것 등이 가능해진다. new_grid &lt;- data.frame(growth=seq(-2.0, 4.0, 0.5)) y_point_pred_grid &lt;- predict(M9.1, newdata=new_grid) y_linpred_grid &lt;- posterior_linpred(M9.1, newdata=new_grid) y_pred_grid &lt;- posterior_predict(M9.1, newdata=new_grid) 결과적으로 길이가 13인 벡터, y_point_pred_grid와 경제성장률을 보여주는 13개 각 값에 대한 예측값인 \\(n_sims\\times 13\\)인 두 행렬, y_linpred_grid와 y_pred_grid를 얻게 된다. 9.2.5 Propagating uncertainty 선거 결과의 불확실성은 경제성장에 대해 미리 설정된 여러 값들에 조건적으로 나타난다. 선거 전에 경제성장률이 2.0%였을 경우의 가장 최선의 추정량이 약간의 불확실성, 표준편차 0.3%의 정규분포로 나타난다고 해보자. 우리는 우리의 불확실성을 더 완벽하게 표현하는 미래의 분포를 얻기 위해 예측변수의 불확실성을 이용할 수 있다. x_new &lt;- rnorm(n_sims, 2.0, 0.3) y_pred &lt;- rnorm(n_sims, a + b*x_new, sigma) 마찬가지로 요약해보면 다음과 같다: cat(&quot;Predicted Clinton percentage of 2-party vote: &quot;, round(median(y_pred), 1), &quot;, with s.e. &quot;, round(mad(y_pred), 1), &quot;\\nPr (Clinton win) = &quot;, round(mean(y_pred &gt; 50), 2), sep=&quot;&quot;) ## Predicted Clinton percentage of 2-party vote: 52.3, with s.e. 4.1 ## Pr (Clinton win) = 0.72 점예측값은 52.3%로 변하지 않았지만 표준편차가 약간 높아져서 추가적인 불확실성을 반영하고 있는 것을 확인할 수 있다. 9.2.6 Simulating uncertainty for the linear predictor and new observations 이번에는 earnings라는 설문조사 결과를 가진 데이터로 키(인치)로 몸무게(파운드)를 예측하는 모델을 분석해보자. fit_1 &lt;- stan_glm(weight ~ height, data=earnings, refresh = 0) print(fit_1) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ height ## observations: 1789 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) -173.5 11.8 ## height 5.0 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 29.0 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 절편은 해석이 어렵다. 키가 0인치일 때의 예측되는 몸무게를 의미하기 때문이다. 현실적으로 존재하지 않는 상황이기는 하다. 따라서 다음과 같이 데이터를 좀 손을 보자. earnings$c_height &lt;- earnings$height - 66 fit_2 &lt;- stan_glm(weight ~ c_height, data=earnings, refresh = 0) print(fit_2) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ c_height ## observations: 1789 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 153.4 0.7 ## c_height 5.0 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 29.0 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 위와 같이 변수를 중심화(centering)해주면, 회귀모델의 예측변수는 66인치에 비례한 키의 변화를 설명한다. 그 결과, 우리는 회귀계수에 대한 조금 더 안정적이고 해석가능한 추론을 도출할 수 있다. 기울기와 표준편차-오차에 대한 추론은 달라지지 않지만 절편값이 달라진다. 절편값은 이제 66인치인 사람에 대한 예측 몸무게에 대응하는 결과로 이해할 수 있다. 적합된 모델에서 우리는 모집단에서 66인치의 키를 가진 사람들의 평균 몸무게를 153.2ㅇ 파운드로, 0.6의 불확실성을 가졌다고 추정한다. 그러나 만약 우리가 모집단에서 무작위로 선택된 66인치의 키를 가진 사람 한 명을 특정해서 그 몸무게를 예측하고 싶다면, 29.1로 추정된 표준편차 예측 불확실성을 포함할 필요가 있다. 일반적으로 적합된 회귀모델을 새로운 데이터 관측치, \\(x^{\\text{new}}\\)에 적용할 때, 우리는 선형 예측변수 \\(a + bx^{\\text{new}}\\)에 대한 추론을 하게 되거나 예측값 \\(y^{\\text{new}} = a + bx^{\\text{new}} + \\epsilon\\)에 대한 추론을 하게 된다. 예를 들어 키가 70인치인 사람의 무게를 예측한다고 하자, 이때 c_height = height - 66 = 4가 된다. \\[ \\begin{aligned} \\text{Linear predictor: }&amp;a + 4.0b,\\\\ \\text{Predicted value: }&amp;a + 4.0b + \\epsilon. \\end{aligned} \\] 즉, 위의 모델에서 70인치인 사람의 몸무게에 대한 점예측치는 \\(153.2 +4.0 \\times 4.9 = 172.8\\) 파운드라고 할 수 있다. \\(y = a + bx + \\text{error}\\)라는 회귀모델에서 선형 예측변수 \\(a + bx\\)에 대한 표준편차는 다음과 같다: \\[ \\hat \\sigma_{\\text{linpred}} = \\hat \\sigma \\sqrt{\\frac{1}{n} + \\frac{(x^{\\text{new}}-\\bar x)^2}{\\sum^{n}_{i=1}(x_i-\\bar x)^2}}. \\] 예측값 \\(a + bx + \\epsilon\\)에 대한 표준편차는 다음과 같다: \\[ \\hat \\sigma_{\\text{prediction}} = \\hat \\sigma \\sqrt{ 1 + \\frac{1}{n} + \\frac{(x^{\\text{new}}-\\bar x)^2}{\\sum^{n}_{i=1}(x_i-\\bar x)^2}}. \\] 복잡한 공식을 이용하기보다는 R에서 시뮬레이션을 활용해 예측 불확실성을 컵퓨팅 해볼 수 있다. 적합된 회귀모델에서 표본 규모 \\(n\\)의 크기가 커질수록, 선형 예측변수의 표준편차는 0으로 수렴한다. 반면에 예측값의 표준편차는 0이 아닌 \\(\\sigma\\)의 값에 수렴한다. 적합된 모델의 파라미터들에 대해 완벽하게 알고있다고 하더라도 새로운 데이터 관측치를 예측하는 것에 대한 불확실성이 존재한다. stan_glm으로 모델을 적합한 이후에 우리는 두 가지 종류의 예측값을 posterior_linpred와 posterior_predict의 사후 시뮬레이션을 얻을 수 있다. 키와 몸무게 예제에서 베이지한 회귀모델 fit_2를 이용하여 70인치 키를 가진 사람의 몸무게를 추정해보자(키는 현재 중심화되어 4.0인치): new &lt;- data.frame(c_height=4.0) 점예측값을 컴퓨팅할 수도 있다. y_point_pred_2 &lt;- predict(fit_2, newdata=new) 그리고 선형 예측값의 시뮬레이션을 컴퓨팅할 수 있다. y_linpred_2 &lt;- posterior_linpred(fit_2, newdata=new) \\(a+4.0b\\)의 가능한 값들을 보여주는 벡터를 계수값의 사후 불확실성으로부터 오는 변동성과 함께 산출할 수 있다. 키가 70인치인 사람에 대한 사후 예측 시뮬레이션을 컴퓨팅해보자. y_postpred_2 &lt;- posterior_predict(fit_2, newdata=new) y_postpred_2 %&gt;% head(n = 20) ## 1 ## [1,] 223.2700 ## [2,] 138.3257 ## [3,] 157.0671 ## [4,] 146.7843 ## [5,] 169.6717 ## [6,] 204.0569 ## [7,] 121.0978 ## [8,] 159.2177 ## [9,] 158.5409 ## [10,] 171.3633 ## [11,] 207.0446 ## [12,] 142.9946 ## [13,] 155.0257 ## [14,] 184.9185 ## [15,] 161.9425 ## [16,] 187.5145 ## [17,] 199.4316 ## [18,] 170.5425 ## [19,] 242.3656 ## [20,] 160.3882 y_postpred_2는 \\(a + 4.0b + \\epsilon\\)이 취할 수 있는 가능한 값들을 보여주는 시뮬레이션 벡터를 산출한다. 이 벡터의 중앙값, 중앙값 표준편차, 히스토그램 등을 요약해서 보여줄 수 있다. 9.3 Prior information and Bayesian synthesis 전통적인 통계방법은 단 하나의 데이터셋에 기초하여 요약 결과와 추론을 수행한다. 베이지언 방법은 사전정보와 획득한 데이터를 결합해 필요한 요약 자료와 추론을 제시한다. 9.3.1 Expressing data and prior information on the same scale 우리가 추정하고자 하는 연속형 파라미터, \\(\\theta\\)의 정규분포에 대한 베이지언 추론의 공식에서부터 시작해보자. 여기서의 목적은 사전 표준오차(prior standard error, \\(\\text{se}_\\text{prior}\\))를 갖는 사전 추정량(prior estimate) \\(\\hat \\theta_{\\text{prior}}\\)과 표준오차, \\(\\text{se}_\\text{data}\\)를 갖는 데이터 추정량(data estimate), \\(\\hat \\theta_{\\text{data}}\\)를 결합하는 것에 있다. 그 결과로 얻을 수 있는 베이지언 추정량, \\(\\hat \\theta_{\\text{Bayes}}\\)은 표준오차 \\(\\text{se}_\\text{Bayes}\\)를 갖는다: \\[ \\begin{aligned} \\hat \\theta_{\\text{Bayes}}&amp;=\\bigg(\\frac{1}{\\text{se}^2_{\\text{prior}}}\\hat \\theta_{\\text{prior}}+\\frac{1}{\\text{se}^2_{\\text{data}}}\\hat \\theta_{\\text{data}} \\bigg)\\bigg/\\bigg(\\frac{1}{\\text{se}^2_{\\text{prior}}} + \\frac{1}{\\text{se}^2_{\\text{data}}} \\bigg),\\\\ \\text{se}_\\text{Bayes}&amp;=1\\bigg/\\sqrt{\\frac{1}{\\text{se}^2_{\\text{prior}}} + \\frac{1}{\\text{se}^2_{\\text{data}}}}. \\end{aligned} \\] 위의 공식은 베이지언 추론이 사전정보와 데이터 간의 어떠한 조정을 통해 도출된다는 것을 보여준다. 9.3.2 Bayesian information aggregation 사전 정보에 대한 값을 설정한다. theta_hat_prior &lt;- 0.524 se_prior &lt;- 0.041 새로운 데이터 추정량을 설정한다. n &lt;- 400 y &lt;- 190 theta_hat_data &lt;- y / n se_data &lt;- sqrt((y / n) * (1 - y / n) / n) 사전 정보와 데이터로부터 사후분포의 값을 컴퓨팅한다. Figure 9.3a는 사전 분포와 가능도(데이터로부터 얻은 정보)에 관한 내용을 보여준다. Figure 9.2: (a) Likelihood (distribution representing data estimate and standard error) and prior distribution for the example combining estimate from a poll (the data) with the forecast from a fitted model (the prior). In this case, the data estimate is 0.475 with standard error 0.025, and the prior estimate is 0.524 with prior standard error 0.041. (b) Bayesian inference yields the posterior distribution, which is a compromise between the likelihood and the prior. In this example, the data are more informative than the prior, and so the posterior distribution is closer to the likelihood than the prior distribution. Figure 9.3a에 있어서 우리는 사전 정보와 데이터 추정량을 결합하면서 핵심적인 가정을 하고 있다. 바로 사전정보와 데이터가 서로 다른 정보 출처를 보여주고 있다는 가정이다. 보다 정확하게 이 가정은 두 추정량에 있어서의 불확실성이 통계적으로 독립적이라는 것을 의미한다. 이 예제에서 사전 분포는 과거 선거/현재 경제성과에 바탕을 둔 예측된 결과이며, 이때 예측의 불확실성은 적합된 모델의 0이 아닌 잔차로부터 유래한 것이다. 더불어 이 예제에서 사전 표준오차는 4.1%이며 데이터의 표준오차는 2.5%이므로 데이터는 사전 정보보다 더 많은 정보를 담고 있다. 따라서 베이즈 추정량은 데이터에 점차 더 가까워질 것이다. 쉽계 계산해볼 수 있다. theta_hat_prior &lt;- 0.524 se_prior &lt;- 0.041 n &lt;- 400 y &lt;- 190 theta_hat_data &lt;- y/n se_data &lt;- sqrt((y/n)*(1-y/n)/n) theta_hat_bayes &lt;- (theta_hat_prior/se_prior^2 + theta_hat_data/se_data^2) / (1/se_prior^2 + 1/se_data^2) theta_hat_bayes ## [1] 0.4882564 se_bayes &lt;- sqrt(1/(1/se_prior^2 + 1/se_data^2)) se_bayes ## [1] 0.02132543 \\(\\hat \\theta_{\\text{Bayes}} = 0.488\\), \\(\\text{se}_{\\text{Bayes}}=0.021\\)을 얻을 수 있다. 이 추정량은 사전 정보와 데이터 추정량 사이에 위치하며, 데이터 추정량에 보다 가깝다. Figure 9.3b에서 시각적으로 확인할 수 있다. 더 불확실한 데이터를 가지고 동일한 분석을 수행한다고 해보자. 점추정량은 그대로여도 표준오차가 0.025에서 0.075로 증가한다고 할 때, 페이즈 추정량은 0.512가 되며, 사전정보에 보다 더 가까워지는 것이다. 9.3.3 Different ways of assigning prior distributions and performing Bayesian calculations 통계학에서 헥살릴 수 있는게 다른 방식으로 수행되는 비슷한 분석이다. 회귀분석 모델링에서 일반적인 예제를 보면, 실제로는 종종 계수값에 대한 거의 알지 못한다는 약한 사전정보, 또는 어떠한 강한 가정을 수립하지 않는다든지 하는 등의, 모든 계수값들에 대해 사전 정보를 특정해야만 한다(Gelman, Hill, and Vehtari 2020: 121). 9.4 Example of Bayesian inference: beauty and sex ratio 우리는 잡음(noise)-불확실성이 존재하는 연구로부터 추정량을 조정하기 위해 사전 정보를 사용할 수 있다(Gelman, Hill, and Vehtari 2020: 121). 이 예제는 Kanazawa의 연구에서 기인한 것이다. 먼저 sexratio.rda 데이터를 불어오자. load(&quot;data/ros-master/SexRatio/data/sexratio.rda&quot;) head(sexratio) ## x y ## 1 -2 50 ## 2 -1 44 ## 3 0 50 ## 4 1 47 ## 5 2 56 다섯 가지 매력점수는 x열에, 성인 중 여자아이를 가진 부모의 비율을 y열에 저장되어 있다. 9.4.1 Prior information 하지만 더 많은 정보를 사용할 수 있다. 예를 들어, 현재 미국에서 보고된 인종별 성비 등을 이용할 수도 있다. 주어진 매력점수 그 자체는 주관적인 지표이므로 우리는 종속변수에 영향을 미칠 것으로 기대되는 다른 정보들을 탐색하여 모델에 반영할 수 있다. 9.4.2 Prior estimate and standard error Gelman, Hill, and Vehtari (2020, 122) 은 평균 0%, 표준편차 0.25%의 \\(\\theta\\)에 대한 사전분포를 과학적 지식으로 표현한다. 사전분포의 평균이 0이라는 것은 데이터를 실제로 보기 전에 우리가 여아의 출생률에 대한 어떠한 사전적 기대를 가질 이유가 없다는 것을 의미한다. 사전 표준편차 0.25%는 \\(\\theta\\)에 대한 진실값이 0.5% 혹은 -0.5% 사이에 위치할 가능성이 매우 높다는 의미이다. 9.4.3 Data estimate and standard error 위의 예제에서 표준오차 \\(\\text{se}_\\text{data} = 3\\%\\)를 갖는 추정량 \\(\\hat_{\\text{data}} = 8\\%\\)가 있다고 할 때, 우리는 사전 정보가 데이터보다 더 많은 정보를 준다는 것을 확인할 수 있다: 데이터의 표준오차는 사전 불확실성(prior uncertainty)의 10배 이상이다. 9.4.4 Bayes estimate 앞서 베이지언 \\(\\theta\\)와 표준오차를 공식에 따라 계산하면 다음과 같은 결과를 얻을 수 있다: \\(\\hat \\theta_\\text{Bayes} = 0.06\\%\\) with \\(\\text{se}_\\text{Bayes} = 0.25\\%\\). 즉, 아름다운 부모와 아름답지 않은 부모로부터 여아가 출생할 확률의 차이에 대한 추정량은 0.06%인 것이다. 그리고 그 추정량의 불확실성은 표준오차인 0.25%이다. 추정량의 크기는 작고, 그 결과는 표준오차보다 작다. 따라서 설문조사 데이터는 성비(sex ratio)의 변동성에 대해서는 아무것도 알려주지 못한다. 9.4.5 Understanding the Bayes estimate 표본 규모가 3,000이고 전체 성비가 약 0.5라고 하자. 약 0.5라는 비율에 대한 표준오차를 컴퓨팅할 수 있다: \\(\\sqrt{.5 \\times .5 / 3{,}000} = 0.009\\). 두 집단의 차이에 대한 표준오차는 각 1,500명인 집단에 대해 \\(\\sqrt{p_1 (1 - p_1) / 1{,}500 + p_2 (1 - p_2) / 1{,}500}\\)를 컴퓨팅함으로써 얻을 수 있다. \\(p_1 \\approx p_2 \\approx .5\\)를 시뮬레이션한 상황에서, \\(\\sqrt{2 \\times .5 \\times .5 / 1{,}500} = 0.018\\)가 된다. 실제로는 두 집단의 표본 크기가 서로 동일하지 않기 때문에, 표준오차는 조금 더 커질 수 있다. 만약 “매력적인”(부모가 예쁜) 집단의 \\(n = 300\\)이라면(즉, 10% of 3,000), \\(\\sqrt{(.5 \\times .5 / 300) + (.5 \\times .5 / 2{,}700)} = 0.03\\)라는 결과를 얻을 수 있다. 9.5 Uniform, weakly informative, and informative priors in regression 베이지언 추론에서는 가능도와 사전 분포를 곱해서 사후 분포를 산출한다. 이 사후 분포를 통해 연구자는 주어진 모델과 데이터로부터 추론에 대한 요약된 정보를 얻을 수 있다. 9.5.1 Uniform prior distribution stan_glm()를 가지고 적절한 사전정보에 대한 정의가 없음, NULL, 균일 사전분포(uniform priors)를 적합할 수 있다. stan_glm(data = hibbs, vote ~ growth, prior_intercept = NULL, prior = NULL, prior_aux = NULL) 9.5.2 Default prior distribution stan_glm은 기본적으로 약한 사전분포를 취한다. stan_glm으로 적합한 모델의 사전분포를 보고 싶다면 prior_summary() 함수를 이용하면 된다. 디폴트 사전정보를 이해하기 위해서는 회귀계수가 예측변수 \\(x\\)의 한 단위 변화에 따른 비교대상 두 사람의 결과, \\(y\\)의 차이의 기대값이라는 것을 떠올릴 필요가 있다. 만약 \\(x\\)와 \\(y\\)가 모두 표준화된다면, 계수값은 \\(x\\)의 1 표준편차 변화에 따른 \\(y\\)의 표준편차의 기대값의 차이라고 볼 수 있다. 디폴트 사전분포는 다음과 같이 특정할 수 있다: M1 &lt;- stan_glm(vote ~ growth, data=hibbs, refresh = 0) 혹은 보다 명시적으로 다음과 같은 코드로 나타낼 수 있다: sd_x &lt;- sd(hibbs$growth) sd_y &lt;- sd(hibbs$vote) mean_y &lt;- mean(hibbs$vote) M1a &lt;- stan_glm(vote ~ growth, data=hibbs, prior=normal(0, 2.5*sd_y/sd_x), prior_intercept=normal(mean_y, 2.5*sd_y), prior_aux=exponential(1/sd_y), refresh = 0) 위의 두 모델은 M1a가 사전분포를 직접적으로 특정하고 있다는 것을 제외하고는 동일하다. 9.5.3 Weakly informative prior distribution based on subject-matter knowledge 디폴트 사전분포는 추론을 안정적으로 하게끔 하기 위한 장치이다. 많은 문제들에서 사전 정보를 그 문제에 맞게끔 특정해서 포함하는 것만으로도 더 나은 결과를 얻을 수 있다(Gelman, Hill, and Vehtari 2020: 124). 아래는 이전 예제에서 사전 정보로 기울기는 평균 5에 표준편차 5인 정규분포, 절편은 평균 50에 표준편차 10인 정규분포를 따르고 있을 것이라는 사전 분포를 가정한 것이다. M4 &lt;- stan_glm(vote ~ growth, data=hibbs, prior=normal(5, 5), prior_intercept=normal(50, 10), refresh = 0) print(M4) ## stan_glm ## family: gaussian [identity] ## formula: vote ~ growth ## observations: 16 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 46.1 1.7 ## growth 3.1 0.7 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 3.9 0.7 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 9.5.4 Example where an informative prior makes a difference: Beauty and sex ratio 부모의 매력이 여자 아이의 출산율로 이어지는 것을 예측한 OLS 모델이 있다고 하자. lm(data = sexratio, y ~ x) %&gt;% summary() ## ## Call: ## lm(formula = y ~ x, data = sexratio) ## ## Residuals: ## 1 2 3 4 5 ## 3.6 -3.9 0.6 -3.9 3.6 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 49.400 1.944 25.409 0.000134 *** ## x 1.500 1.375 1.091 0.355025 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 4.347 on 3 degrees of freedom ## Multiple R-squared: 0.2841, Adjusted R-squared: 0.04545 ## F-statistic: 1.19 on 1 and 3 DF, p-value: 0.355 데이터와 모델의 관계를 다음과 같은 그래프로 살펴보자. Figure 9.3: (a) Data from a survey showing the percentage of girl births among parents of five different attractiveness categories; (b) data with fitted regression line. Figure 9.6 shows different expressions of uncertainty in the fit. 이번에는 정보량이 충분한 사전정보를 가지고 회귀모델을 적합해보자. set.seed(1224) fit_bayes_inform &lt;- stan_glm( y ~ x, data = sexratio, refresh = 0, prior = normal(location = 0, scale = 0.2), prior_intercept = normal(location = 48.8, scale = 0.5) ) fit_bayes_inform ## stan_glm ## family: gaussian [identity] ## formula: y ~ x ## observations: 5 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 48.8 0.5 ## x 0.0 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 4.3 1.3 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 사전 분포에 대한 요약 정보는 다음과 같다: prior_summary(fit_bayes_inform) ## Priors for model &#39;fit_bayes_inform&#39; ## ------ ## Intercept (after predictors centered) ## ~ normal(location = 49, scale = 0.5) ## ## Coefficients ## ~ normal(location = 0, scale = 0.2) ## ## Auxiliary (sigma) ## Specified prior: ## ~ exponential(rate = 1) ## Adjusted prior: ## ~ exponential(rate = 0.22) ## ------ ## See help(&#39;prior_summary.stanreg&#39;) for more details 정보량이 충분한 사전분포를 가지고 사후 시뮬레이션을 돌린 결과는 다음과 같다: ## Error in validate_data(data, if_missing = environment(formula)): object &#39;sex_ratio&#39; not found ## Error in as_tibble(fit_bayes_default): object &#39;fit_bayes_default&#39; not found ## Error in coef(fit_bayes_default): object &#39;fit_bayes_default&#39; not found ## Error in is.data.frame(data): object &#39;sex_ratio&#39; not found ## Error in ggplot(., aes(`(Intercept)`, x)): object &#39;sims_default&#39; not found ## Error in ggplot(., aes(x, y)): object &#39;sex_ratio&#39; not found ## Error in fortify(data): object &#39;sims_default&#39; not found ## Error in ggplot(., aes(x, y)): object &#39;sex_ratio&#39; not found ## Error in eval(expr, envir, enclos): object &#39;fig9.6a&#39; not found 위의 그래프는 \\((a, b)\\)에 대한 사후 시뮬레이션 결과와 그에 따른 회귀선, \\(y = a + bx\\)를 각각 디폴트 사전분포(default prior)/정보 사전분포(informative prior)에 따라 보여준다. 이 경우 사전분포는 데이터보다 더 많은 정보를 제공한다. References "],["linear-regression-with-multiple-predictors.html", "Chapter 10 Linear regression with multiple predictors 10.1 Adding predictors to a model 10.2 Interpreting regression coefficients 10.3 Interactions 10.4 Indicator variables 10.5 Formulating paired or blocked designs as a regression problem 10.6 Example: uncertainty in predicting congressional elections 10.7 Mathematical notation and statistical inference 10.8 Weighted regression 10.9 Fitting the same model to many datasets", " Chapter 10 Linear regression with multiple predictors 단순한 모델, \\(y = a + bx + \\text{error}\\)로부터 좀 더 일반적인 모델, \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots + \\text{error}\\)로 넘어가게 되면, 모델에 어떤 예측변수, \\(x\\)를 포함할 것인가, 계수값에 대한 해석을 어떻게 할 것인가, 그 결과들이 어떻게 상호작용하며 이산성(discreteness)와 비선형성(nonlinearity)을 보여주는 기존 변수로부터 새로운 예측변수를 어떻게 구성할 것인지 등을 고려해야 한다. 10.1 Adding predictors to a model 회귀계수는 통상적으로 여러 개의 예측변수를 해석하는 것이 더 까다롭다. 왜냐하면 주어진 계수값은 어디까지나 모델 내 다른 변수들의 영향력을 고려한 부분적인 결과물이기 때문이다. 계수 \\(\\beta_k\\)는 다른 모든 예측변수들이 동일할 때, 예측변수 \\(x_k\\)의 한 단위 변화가 나타난 두 사람을 비교했을 때의 결과 \\(y_k\\)의 평균 혹은 기대값의 차이라고 할 수 있다. 성인 미국 여성과 아이들에 대한 설문조사로부터 얻은 데이터를 통해 어머니의 특성들이 조건주어졌을 때, 미취학 아동들의 인지시험성적을 예측하기 위한 일련의 회귀모델들을 적합해본다고 하자. file_kids &lt;- here::here(&quot;data/ros-master/KidIQ/data/kidiq.csv&quot;) kidiq &lt;- read_csv(file_kids) 10.1.1 Starting with a binary predictor 엄마가 고등학교를 졸업했냐 하지 못했냐를 보여주는 더미변수가 주어졌을 때, 아이들의 시험 성적을 모델링해보자. fit_1 &lt;- stan_glm(kid_score ~ mom_hs, data=kidiq, refresh = 0) print(fit_1) ## stan_glm ## family: gaussian [identity] ## formula: kid_score ~ mom_hs ## observations: 434 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 77.5 2.1 ## mom_hs 11.8 2.4 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 19.9 0.7 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 위의 코드는 다음과 같이 쓸 수 있다. \\[ \\text{kid_score} = 78 + 12 \\times \\text{mom_hs} + \\text{error}. \\] 이 모델은 엄마가 고등학교를 졸업한 아이들과 그렇지 않은 아이들 간의 평균 시험 성적의 차이를 보여준다. Figure 10.1은 그 회귀선이 두 집단의 평균을 지나가는지를 보여준다. ## Error in ggplot(., aes(mom_hs, kid_score)): object &#39;kids&#39; not found 10.1.2 A single continuous predictor 만약 더미변수가 아니라 연속형 변수, 엄마의 IQ 점수를 예측변수로 모델에 포함하였다면, 이는 다음과 같이 다시 쓸 수 있다. \\[ \\text{kid_score} = 26 + 0.6\\times \\text{mom_iq} + \\text{error}. \\] 이 모델을 시각화하면 Figure 10.2처럼 나타낼 수 있다. Figure 10.2의 선은 엄마의 IQ 수준의 각 관측치에 따른 아이들의 예측된 인지성적을 보여준다고 이해할 수 있다. 만약 우리가 엄마의 IQ가 1점 다른 두 집단에서의 아이들의 인지성적 점수의 평균을 비교한다면, 엄마의 IQ가 더 높은 집단의 아이들이 평균적으로 0.6 높은 인지성적 수준을 보여줄 것이다. 그리고 여기에서 절편-상수항을 이해하려면, 모든 예측변수들이 0인 상황을 가정해야 한다. ## Error in validate_data(data, if_missing = environment(formula)): object &#39;kids&#39; not found ## Error in coef(fit_2)[[&quot;mom_iq&quot;]]: subscript out of bounds ## Error in ggplot(., aes(mom_iq, kid_score)): object &#39;kids&#39; not found 10.1.3 Including both predictors 이번에는 두 개의 예측변수로 아이의 시험 성적을 예측하는 선형회귀모델을 고려해보자. 이 모델은 다음과 같이 나타낼 수 있다. \\[ \\text{kid_score} = 26 + 6.0 \\times \\text{mom_hs} + 0.6\\times \\text{mom_iq} + \\text{error}. \\] fit_3 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq, data=kidiq, refresh = 0) print(fit_3) ## stan_glm ## family: gaussian [identity] ## formula: kid_score ~ mom_hs + mom_iq ## observations: 434 ## predictors: 3 ## ------ ## Median MAD_SD ## (Intercept) 25.8 5.9 ## mom_hs 5.9 2.3 ## mom_iq 0.6 0.1 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 18.2 0.6 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 10.1.4 Understanding the fitted model ## Error in ggplot(., aes(mom_iq, kid_score, color = factor(mom_hs))): object &#39;kids&#39; not found 엄마의 IQ 성적이 아이들의 인지시험 성적에 미치는 효과-회귀모델의 기울기는 엄마의 교육 수준에 따라 나뉜 두 집단에 따라 동일하다. 뒤에 이어지는 Section 10.3에서는 두 선의 기울기가 달라질 수 있는 상호작용 모델을 고려해볼 것이다. 일단 여기서 모델을 해석하자면 다음과 같다. 절편: 만약 아이가 IQ가 0인 엄마를 가지고 있고 또한 그 엄마가 고등학교를 졸업하지 않았다면, 아이의 인지시험 성적은 26점일 것이라고 예측된다. 하지만 이 예측은 유용하지 않다. 왜냐하면 현실적으로 쉽게 찾아보기 힘든 경우이기 때문이다. 엄마의 고등학교 졸업에 대한 계수: 동일한 IQ의 엄마를 가졌지만 한 쪽은 고등학교를 졸업, 다른 한 쪽은 졸업하지 않은 두 아이가 있다고 할 때, 모델은 이 두 아이의 인지성적 차이가 6점일 것으로 예측한다. 엄마의 IQ에 대한 계수: 엄마의 고등학교 졸업 여부가 같을 때, 엄마의 IQ 수준이 1점 차이가 날 때, 아이의 시험 성적은 평균적으로 0.6점 차이가 난다고 예측한다. 10.2 Interpreting regression coefficients 10.2.1 It’s not always possible to change one predictor while holding all others constant 우리는 다른 예측변수가 동일한 수준으로 고정되어 있을 때, 한 예측변수의 변화에 따른 개인들의 결과변수를 비교하는 것으로 회귀계수를 해석한다. 10.2.2 Counterfactual and predictive interpretations 다중선형회귀모델에서 어떻게 계수값을 해석할 것인지를 생각해볼 때, 우리는 회귀계수에 대한 해석 방식을 두 가지로 구분한다. 예측적 해석(predictive interpretation) 다른 모든 예측변수들이 동일할 때, 특정 예측변수의 한 단위 변화가 서로 다른 두 집단의 결과변수에 있어서 평균적으로 어떠한 차이를 가져오는지에 초점을 맞추어 해석한다. 선형모델에서 계수값은 두 관측치에 있어서 \\(y\\)의 기대값의 차이라고 이해할 수 있다. 반사실적 해석(counterfactual interpretation) 개인들 간의 비교라기보다는 개인들 내의 변화로 이해할 수 있다. 모델에서 다른 예측변수들이 변화하지 않을 때, 한 예측변수의 한 단위 변화가 \\(y\\)에 가져오는 기대값의 변화로 이해하는 것이다. 하지만 명확하게 말하면 데이터만 가지고는 회귀모델은 오직 단위 간의 비교만을 말할 수 있을 뿐, 단위 내의 변화에 대해서는 구분할 수 없다. 따라서 비교의 맥락에서 회귀계수를 해석하는 것이 더 안전한 방법이라고 할 수 있다. 10.3 Interactions 앞서서는 엄마의 IQ 점수와 고등학교 졸업 유무가 서로 독립적으로 아이의 시험성적에 영향을 미치는 것으로 모델링되었다면, 이번에는 그 둘이 서로 상호작용하는, 그래서 기울기가 실질적으로 다르게 나타나는 경우를 살펴본다: mom_hs와 mom_iq 간의 상호작용항을 포함하는 것이다. fit_4 &lt;- stan_glm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, data=kidiq, refresh = 0) print(fit_4) ## stan_glm ## family: gaussian [identity] ## formula: kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq ## observations: 434 ## predictors: 4 ## ------ ## Median MAD_SD ## (Intercept) -10.3 13.8 ## mom_hs 49.5 15.5 ## mom_iq 1.0 0.2 ## mom_hs:mom_iq -0.5 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 18.0 0.6 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 이러한 상호작용을 포함한 모델은 주효과(main effects)와 그 상호작용 효과, mom_hs:mom_iq을 포함하고, 다음과 같이 나타낼 수 있다. \\[ \\text{kid_score} = −11 + 51 \\times \\text{mom_hs} + 1.1 \\times \\text{mom_iq} − 0.5 \\times \\text{mom_hs}\\times \\text{mom_iq} + \\text{error}, \\] Figure 10.4a와 같이 엄마의 교육 수준에 따라 정의되는 하위 집단으로 회귀선을 각기 추정할 수 있다. 한편 Figure 10.4b는 절편을 보여주는 \\(x\\) 축이 0까지 확장된 그래프이다. ## Error in ggplot(., aes(mom_iq, kid_score, color = factor(mom_hs))): object &#39;kids&#39; not found ## Error in ggplot(., aes(mom_iq, kid_score, color = factor(mom_hs))): object &#39;kids&#39; not found ## Error in eval(expr, envir, enclos): object &#39;fig10.4a&#39; not found 상호작용 모델의 경우에는 계수값 해석에 주의를 기울여야 한다. 특정한 하부집단 내/간(within/across) 평균 또는 예측된 시험 성적을 분석함으로써 우리는 적합한 모델로부터 함의를 이끌어낼 수 있다. 절편: 엄마가 고등학교를 마치지 못했거나 IQ가 0인, 현실적으로 의미없는 시나리오의 경우에 아이들의 예측된 시험 성적을 보여준다. mom_hs에 대한 계수: 엄마가 고등학교를 마치지 못했고 IQ가 0인 엄마를 가진 아이들과 고등학교는 마쳤지만 IQ 수준이 0인 엄마를 가진 아이들 간 인지시험 성적의 예측값의 차이라고 할 수 있다. 보통 IQ 수준이 0인 경우를 상정할 수 없기 때문에 쉽게 해석하기는 어렵다. mom_iq에 대한 계수: 엄마가 고등학교를 마치지 못했던 아이와 고등학교를 마친 엄마를 가진 아이 간에 IQ 성적 1점 차이가 아이의 인지시험 성적 평균의 차이에 있어서 얼마만큼의 변화를 가지고 오는지를 보여준다. 상호작용항에 대한 계수: 엄마가 고등학교를 마치거나 마치지 못한 아이들 간의 mon_iq에 대한 기울기의 차이를 보여준다. 즉, Figure 10.4에서 두 기울기의 차이를 의미한다. 고등학교를 마친 엄마와 그렇지 못한 엄마를 가진 아이들 각각에 대해 별도의 회귀선을 수식으로 살펴보면 다음과 같다. \\[ \\begin{aligned} \\text{mom_has = 0}:\\:\\text{kid_score}&amp;=-11+51\\times0+1.1\\times\\text{mom_iq}-0.5\\times0\\times\\text{mom_iq}\\\\ &amp;=-11+1.1\\times\\text{mom_iq}\\\\ \\text{mom_has = 1}:\\:\\text{kid_score}&amp;=-11+51\\times1+1.1\\times\\text{mom_iq}-0.5\\times1\\times\\text{mom_iq}\\\\ &amp;=40+0.6\\times\\text{mom_iq}\\\\ \\end{aligned} \\] 고등학교를 마치지 못한 엄마를 가진 아이들에 대한 추정된 기울기 1.1과 고등학교를 마친 엄마를 가진 아이들에 대한 추정된 기울기 0.6은 직접적으로 해석이 가능하다. 10.3.1 When should we look for interactions? 상호작용은 중요할 수 있다. 우리는 대개 상호작용을 포함하지 않았을 때, 예측변수들의 계수갑싱 매우 크게 나타날 경우에 상호작용이 존재할지 탐색한다. 상호작용을 포함하는 것은 모델을 또 다른 데이터의 서브셋을 이용해 적합하는 것과 같다. 여기서 두 가지 접근법이 이따: 서로 구별되는 집단에 대해 별도로 모델을 적합하거나 혹은 전체 표본을 대상으로 상호작용을 고려한 모델을 적합하는 것이다. 10.3.2 Interpreting regression coefficients in the presence of interactions 우리는 각 예측변수들을 평균 혹은 용이한 기준점을 가지고 중심화(centering)함으로써 상호작용항을 가진 모델을 보다 쉽게 해석할 수 있게 된다. 10.4 Indicator variables 더미변수가 회귀모델에 포함되어 있을 때의 비교를 한 번 살펴보자. 설문 자료에 바탕을 두고 있을 때, 몸무게와 다른 변수들을 가지고 그 사람의 키를 예측하고자 하는 모델이 있다고 하자. 일단 데이터를 살펴보자. earnings %&gt;% head(n = 10) ## # A tibble: 10 x 17 ## height weight male earn earnk ethnicity education mother_education father_education walk ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 74 210 1 50000 50 White 16 16 16 3 ## 2 66 125 0 60000 60 White 16 16 16 6 ## 3 64 126 0 30000 30 White 16 16 16 8 ## 4 65 200 0 25000 25 White 17 17 NA 8 ## 5 63 110 0 50000 50 Other 16 16 16 5 ## 6 68 165 0 62000 62 Black 18 18 18 1 ## 7 63 190 0 51000 51 White 17 17 17 3 ## 8 64 125 0 9000 9 White 15 15 15 7 ## 9 62 200 0 29000 29 White 12 12 12 2 ## 10 73 230 1 32000 32 White 17 17 17 7 ## # ... with 7 more variables: exercise &lt;dbl&gt;, smokenow &lt;dbl&gt;, tense &lt;dbl&gt;, angry &lt;dbl&gt;, age &lt;dbl&gt;, ## # sex &lt;chr&gt;, c_height &lt;dbl&gt; 일단 몸무게(파운드)로 키(인치)를 예측해보자. fit_1 &lt;- stan_glm(weight ~ height, data = earnings, refresh = 0) print(fit_1) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ height ## observations: 1789 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) -173.4 11.9 ## height 5.0 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 29.0 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 적합된 회귀선은 다음과 같이 나타낼 수 있다: \\(\\text{weight} = -172.9 + 4.9 \\times \\text{hegiht}\\). 키가 1인치 다른 두 사람을 비교했을 때, 그들의 몸무게의 기대된 차이(expected difference)는 4.9 파운드이다. 키가 0인치 인 사람의 몸무게 예측값은 -172.9 파운드이다. 하지만 큰 의미는 없는 값이다. 왜냐하면 실제로 키가 0인 사람은 없기 때문이다. 따라서 미국 성인의 평균 키가 66인치라고 할 때의 몸무게의 예측값을 구해보자: \\(-172.9 + 4.9 \\times 66\\). # one-way coefs_1 &lt;- coef(fit_1) predicted_1 &lt;- coefs_1[1] + coefs_1[2]*66 # another way new &lt;- data.frame(height=66) pred &lt;- posterior_predict(fit_1, newdata=new) 다음과 같은 결과를 얻을 수 있다. cat(&quot;Predicted weight for a 66-inch-tall person is&quot;, round(mean(pred)), &quot;pounds with a sd of&quot;, round(sd(pred)), &quot;\\n&quot;) ## Predicted weight for a 66-inch-tall person is 153 pounds with a sd of 29 10.4.1 Centering a predictor 적합된 모델의 더 나은 해석을 위해서 키를 중심화한 변수를 예측변수로 사용해보았다. earnings$c_height &lt;- earnings$height - 66 fit_2 &lt;- stan_glm(weight ~ c_height, data=earnings, refresh = 0) print(fit_2) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ c_height ## observations: 1789 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 153.3 0.7 ## c_height 5.0 0.2 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 29.0 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 10.4.2 Including a binary variable in a regression 이번에는 성별에 관한 더미변수를 포함해보자. fit_3 &lt;- stan_glm(weight ~ c_height + male, data=earnings, refresh = 0) print(fit_3) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ c_height + male ## observations: 1789 ## predictors: 3 ## ------ ## Median MAD_SD ## (Intercept) 149.6 0.9 ## c_height 3.9 0.3 ## male 11.8 2.0 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 28.7 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 남성일 경우의 계수값 12.0은 이 데이터에서 동일한 키를 가진 여성에 비교했을 때 남성이 12파운드 더 무거울 것이라고 예측된다는 것과 같은 의미를 가진다. 70인치의 키를 가진 여성의 예측된 몸무게를 컴퓨팅하는 것도 같은 방식으로 할 수 있다. # one-way coefs_3 &lt;- coef(fit_3) predicted &lt;- coefs_3[1] + coefs_3[2]*4.0 + coefs_3[3]*0 # another way new &lt;- data.frame(c_height=4.0, male=0) pred &lt;- posterior_predict(fit_3, newdata=new) 그 결과는 다음과 같다: cat(&quot;Predicted weight for a 70-inch-tall woman is&quot;, round(mean(pred)), &quot;pounds with a sd of&quot;, round(sd(pred)), &quot;\\n&quot;) ## Predicted weight for a 70-inch-tall woman is 166 pounds with a sd of 28 70인치의 남성의 몸무게에 대한 예측값은 mean(posterior_predict(fit_3, newdata = data.frame(c_height = 4.0, male = 1)))로, 177파운드라는 결과이며 같은 키를 가진 여성에 비해 12 파운드 더 무거운 결과이다. 10.4.3 Using indicator variables for multiple levels of a categorical predictor 회귀모델에 인종을 포함해보자. 인종은 네 가지 그룹으로 이루어져 있다. table(earnings$ethnicity) %&gt;% knitr::kable() Var1 Freq Black 180 Hispanic 104 Other 38 White 1494 우리는 회귀모델에서 인종을 일종의 요인(factor)으로 포함한다. fit_4 &lt;- stan_glm(weight ~ c_height + male + factor(ethnicity), data=earnings, refresh = 0) print(fit_4) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ c_height + male + factor(ethnicity) ## observations: 1789 ## predictors: 6 ## ------ ## Median MAD_SD ## (Intercept) 154.2 2.3 ## c_height 3.9 0.3 ## male 12.1 2.0 ## factor(ethnicity)Hispanic -6.0 3.7 ## factor(ethnicity)Other -12.1 5.2 ## factor(ethnicity)White -5.0 2.3 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 28.6 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 인종은 모두 네 가지 수준으로 측정되어 있다. 그런데 분석 결과를 보면 3개의 계수값만이 나타난다. 추정되지 않은 집단은 흑인(Blacks)이다. Black은 기준카테고리로 취급되어 다른 변수들의 비교 대상일 뿐이기에 계수가 추정되지 않은 것이다. 따라서 히스패닉에 대한 계수값, -5.9는 동일한 키와 성별을 가진 흑인에 비교할 때, 히스패닉이 몸무게가 평균적으로 5.9파운드 덜 나간다는 것을 의미한다. 10.4.4 Changing the baseline factor level 회귀모델의 요인변수는 카테고리 중 어떤 것이든 원하는 것을 기준변수로 삼을 수 있다. R은 알파벳 순서에 따라 기준변수를 삼는다. earnings$eth &lt;- factor(earnings$ethnicity, levels=c(&quot;White&quot;, &quot;Black&quot;, &quot;Hispanic&quot;, &quot;Other&quot;)) fit_5 &lt;- stan_glm(weight ~ c_height + male + eth, data=earnings, refresh = 0) print(fit_5) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ c_height + male + eth ## observations: 1789 ## predictors: 6 ## ------ ## Median MAD_SD ## (Intercept) 149.1 1.0 ## c_height 3.8 0.3 ## male 12.1 2.0 ## ethBlack 5.2 2.2 ## ethHispanic -0.9 2.9 ## ethOther -7.1 4.7 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 28.6 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 변수의 순서를 조정하면 White가 기준 카테고리가 된다. 절편값 154.1은 c_height = 0, male = 0, ethnicity = Black인 사람에 대한 예측된 몸무게라고 할 수 있다. 기준변수를 바꾸었을 경우의 절편 149.1은 c_height = 0, male = 0, ethnicity = White인 사람의 예측된 몸무게이다. height와 male에 대한 계수는 변하지 않는다. 요인변수에서의 각 카테고리의 계수값은 기준카테고리가 어떻게 되느냐에 따라 달라진다. 한편, 인종 집단을 직접적으로 개별 더미변수로 만들어서 분석에 투입할 수도 있다. earnings$eth_White &lt;- ifelse(earnings$ethnicity==&quot;White&quot;, 1, 0) earnings$eth_Black &lt;- ifelse(earnings$ethnicity==&quot;Black&quot;, 1, 0) earnings$eth_Hispanic &lt;- ifelse(earnings$ethnicity==&quot;Hispanic&quot;, 1, 0) earnings$eth_Other &lt;- ifelse(earnings$ethnicity==&quot;Other&quot;, 1, 0) 이 경우, 기준카테고리로 삼을 변수 하나를 제외하고 회귀모델에 포함, 적합하면 된다. fit_6 &lt;- stan_glm(weight ~ height + male + eth_Black + eth_Hispanic + eth_Other, data=earnings, refresh = 0) print(fit_6) ## stan_glm ## family: gaussian [identity] ## formula: weight ~ height + male + eth_Black + eth_Hispanic + eth_Other ## observations: 1789 ## predictors: 6 ## ------ ## Median MAD_SD ## (Intercept) -105.2 16.8 ## height 3.9 0.3 ## male 12.1 2.0 ## eth_Black 5.2 2.3 ## eth_Hispanic -0.9 2.9 ## eth_Other -7.1 5.1 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 28.6 0.5 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 10.4.5 Using an index variable to access a group-level predictor 때로 우리는 집단 수준에서의 예측변수를 가지고 개인 수준에서 회귀모델을 적합하기도 한다. 예를 들면, 학생들의 시험 성적을 개별 학생들의 개인적 배경에 해당하는 변수들, 그리고 그 학생들이 속한 학교의 학부모 평균 소득 수준 등으로 예측하고자 하는 것과 비슷하다. school_income &lt;- income[school] stan_glm(score ~ pretest + age + male + school_income, data=students) 10.5 Formulating paired or blocked designs as a regression problem 이제까지 계속해서 회귀계수를 비교로 해석할 수도 있다고 설명해왔다. 이 말은 즉, 회귀분석을 비교로 표현하는 것이 유용하다는 것이다. 10.5.1 Completely randomized experiment \\(n\\) 명의 사람들이 무작위로 처치집단과 통제집단에 배정되었다는 단순한 실험을 생각해보자. 그리고 각 집단에는 \\(n/2\\)명 씩 속해 있다. 처치효과에 대한 추정량은 \\(\\bar y_T-\\bar y_C\\)이며, 이때의 표준오차는 \\(\\sqrt{\\text{sd}^2_T/(n/2) + \\text{sd}^2_C/(n/2)}\\)이다. 집단 더미변수를 예측변수로 사용해서 회귀분석의 틀로 추론을 표현할 수 있다: 계수에 대한 최소자승법을 통한 추정량은 단순하게 차이, \\(\\bar y_T-\\bar y_C\\)라고 할 수 있고, 표준오차는 평균차(difference-in-means)로부터 얻을 수 있는 값에 가깝다. 이때, 표준오차는 분산 추정량이 전체 집단을 대상으로 하느냐에 따라서 약간 차이가 있을 수 있다. 매우 단순한 처치-전 예측변수들의 사례에서는 회귀모델을 통한 추론이나 실험설계를 바탕으로 한 평균차에서 도출한 추론이나 크게 다르지 않다. 하지만 회귀분석은 보다 복잡한 조건들을 일반화하는 데 장점이 있다. 10.5.2 Paired design \\(n\\)명의 사람들이 짝지어져 있고, 각 짝마다 두 명의 사람들이 무작위로 처치와 통제집단에 배속된다고 생각해보자. 각 짝에서의 차이를 컴퓨팅하고 이를 \\(z_i,\\:i = 1,\\dots,n/2\\)라고 할 때, 처치효과는 \\(\\bar z\\)로, 표준오차는 \\(\\text{sd}(z)/\\sqrt{n/2}\\)이다. 짝을 설계한 데이터는 회귀모델을 통해 분석될 수 있다. 모든 \\(n\\) 개의 데이터에 대해 처치집단 여부를 나타내는 더미변수와 짝을 나타내는 더미변수를 포함하는 모델을 적합함으로써 우리는 보다 복잡한 모델을 추정할 수 있다. fit &lt;- stan_glm(y ~ treatment + factor(pairs), data=expt, refresh = 0) 이때, factor() 함수를 사용해서 회귀모델에서 \\(n/2\\)개의 더미변수를 만들어낸다. 따라서 회귀모델은 \\((n/2) + 1\\)개의 예측변수를 갖는다: 상수항, 처치더미(treatment indicator), 그리고 \\((n/2)-1\\)의 짝 집단을 보여주는 카테고리 변수. 10.5.3 Block design 일반적인 원칙은 결과변수를 예측하는 데 적절할 수 있는 사전 처치 정보는 가능한한 다 포함하는 것이다. \\(n\\)명의 사람들이 \\(J\\)개의 집단에 속해있고, 각 집단마다 있는 처치집단과 통제집단에 무작위 배정하는 블록 설계를 생각해보자. 우리는 기준카테고리가 되는 집단을 제외한 \\(J-1\\)개 집단에 대한 카테고리 변수에 처치더미에 바탕을 두고 결과변수를 예측하는 회귀모델을 적합할 수 있다. 처치효과를 추정하기 위해서는 어떠한 집단을 기준집단으로 삼느냐는 중요하지 않다. 만약 다른 사전 처치 변수들이 가용하다면, 회귀모델에 가능한 추가적인 예측변수들을 포함하여 추정하는 것이 바람직하다. 10.6 Example: uncertainty in predicting congressional elections 미 의회에 대한 선거 모델의 맥락에서 시뮬레이션에 기초한 예측값들을 설명해보자. 먼저 1986 선거로부터 1988 선거 결과를 예측하는 모델을 구축하고 1988년 선거로부터 1990년 선거를 예측하는 것에 적용해보자. 그리고 실제 1990년 선거 결과와 예측값을 확인해보자. 10.6.1 Background 미국은 435개 지역구로 나뉘어 있고, 결과변수 \\(y_i, \\: i = 1, \\dots, n = 435\\)는 1988년 지역구 \\(i\\)에서의 두 정당의 득표 대비 민주당의 정당득표율을 보여준다. Figure 10.5는 데이터 \\(y\\)에 대한 히스토그램을 보여준다. Figure 10.1: Histogram of congressional election data from 1988. The spikes at the left and right ends represent uncontested Republicans and Democrats, respectively. 데이터의 변동성은 어떻게 이해할 수 있을까? 하원 선거 결과를 예측하는 데 적절한 정보로는 무엇이 있을까? 다음의 예측변수를 포함한 회귀모델을 수립해보자: 상수항(constant term) 이전 선거에서 지역구 \\(i\\)의 두 정당 득표에 대한 민주당의 득표율 현직-재선(incumbency): 지역구 \\(i\\)가 1988년에 민주당 의원의 것이었고, 그가 재선거에 출마한 것이라면 +1로 코딩, 재선거에 공화당 의원이 출마했다면 -1로 코딩, 만약 누가 출마할 지 모르는 상황이라면 0으로 코딩한다. 즉, 1988년 당시에 해당 의석이 재선거 의석이 아닌 경우를 의미한다. 현직-재선 예측변수는 카테고리칼이다. 따라서 우리는 하나의 산포도에 민주당 현직자와 공화당 현직자, 둘 모두가 다 아닌 경를 각각 다르게 마킹해서 산포도로 그릴 수 있다. Figure 10.6a가 바로 그것이다. 선형회귀모델을 적합한다고 할 때, 이 변수는 이산형 변수이지만 각 지역구에서의 득표율은 연속형 변수이다. Figure 10.2: (a) Congressional election data from 1986 and 1988. Crosses correspond to elections with Republican incumbents running in 1988, dots correspond to Democratic incumbents, and open circles correspond to open seats. The “incumbency” predictor in the regression model equals 0 for the circles, +1 for the dots, and &lt;U+2212&gt;1 for the crosses. Uncontested election outcomes (at 0 and 1) have been jittered slightly. (b) Data for the regression analysis, with uncontested 1988 elections removed and uncontested 1986 election values replaced by 0.25 and 0.75. The \\(y = x\\) line is included as a comparison on both plots. 10.6.2 Data issues 이전 선거 결과와 재선거에 출마한 현직의원인지 여부를 조건으로 지역구 단위로 결과를 예측해보았다. 이때, 많은 선거들이 비교하고자 하는 두 해 각각에 있어서 경합지역이 아닌 경우가 있다. 즉, 득표율이 0 또는 1로 나타나게 되는 것이다. 하지만 0과 1이 아니라 공화당이 비경합적인 지역에 0.25, 민주당의 비경합적 지역에 0.75라는 값으로 대체한다면, 우리는 약 선거에에서 마치 실제로 경합한 것과 같이 민주당 후보가 받은 표의 비율을 근사하게 되는 것이다. 보다 일반적으로 우리는 비경합지에 앞서 경합지 선거 결과의 분포로부터 무작위 값들을 대체할 수 있다. 이렇게 조정한 결과가 바로 Figure 10.6b이다. 10.6.3 Fitting the model 주어진 past_vote와 incumbency에서 vote를 예측하기 위한 회귀모델을 수립했을 때, 1986년 선거로 1988년 선거를 예측할 때 데이터셋에서 적절한 변수들을 골라보자. data88 &lt;- data.frame(vote=congress$v88_adj, past_vote=congress$v86_adj, inc=congress$inc88) fit88 &lt;- stan_glm(vote ~ past_vote + inc, data=data88, refresh = 0) print(fit88) ## stan_glm ## family: gaussian [identity] ## formula: vote ~ past_vote + inc ## observations: 435 ## predictors: 4 ## ------ ## Median MAD_SD ## (Intercept) 0.3 0.0 ## past_vote 0.5 0.0 ## incOpen -0.1 0.0 ## incRepublican -0.2 0.0 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 0.1 0.0 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 이 모델에는 약간 문제가 있다. Figure 10.6b의 전후 그래프를 비교해보면, 현직 재선 출마자가 공석인 선거의 경우 대부분이 회귀선에서 빠져나와 있다: 즉, 가능하다면 상호작용항을 포함할 것이 요구된다. 이는 현직 재선 출마자가 나온 선거구와 공석인 선거구 간의 기울기가 다를 것이라는 것을 의미한다. 그리고 현직 재선 출마자가 없는 선거구의 비경합적 선거의 투표율의 불확실성을 고려하지 않았다는 문제가 있다. 그럼에도 불구하고 이 예제는 시뮬레이션에 기초한 예측적 추론의 원칙들을 입증하는 데에는 충분하다. 10.6.4 Simulation for inferences and predictions of new data points ## Error in validate_data(data, if_missing = environment(formula)): object &#39;data_88&#39; not found Table 10.1: Simulation results for the congressional election forecasting model. The predicted values \\(\\tilde y_i\\) correspond to the 1990 election. \\(\\beta_0\\) \\(\\beta_1\\) \\(\\beta_2\\) \\(\\beta_3\\) \\(\\sigma\\) 0.32 0.54 -0.10 -0.18 0.07 0.32 0.54 -0.08 -0.19 0.07 0.34 0.52 -0.10 -0.20 0.07 0.34 0.51 -0.11 -0.19 0.07 0.34 0.52 -0.09 -0.21 0.07 0.37 0.46 -0.09 -0.22 0.07 0.36 0.50 -0.10 -0.21 0.06 0.35 0.49 -0.09 -0.20 0.06 0.29 0.59 -0.07 -0.17 0.07 0.32 0.55 -0.06 -0.18 0.06 0.34 0.51 -0.10 -0.19 0.07 0.33 0.52 -0.06 -0.19 0.07 0.33 0.53 -0.08 -0.19 0.07 0.34 0.51 -0.08 -0.19 0.07 0.33 0.52 -0.09 -0.20 0.06 0.34 0.52 -0.08 -0.19 0.07 0.34 0.53 -0.09 -0.19 0.07 0.33 0.52 -0.06 -0.19 0.07 0.33 0.52 -0.05 -0.20 0.07 0.33 0.53 -0.10 -0.19 0.07 위의 표는 시뮬레이션된 파라미터를 보여준다. 시뮬레이션을 이용해서 1988년의 데이터와 1990년 현직-재선 출마자에 대한 정보에 따라 1990년 지역구별 선거결과를 예측할 수 있다. 새로운 예측변수, \\(\\tilde X\\)를 만들어보자. data90 &lt;- data.frame(past_vote=congress$v88_adj, inc=congress$inc90) 새로운 결과의 벡터에 대한 예측 시뮬레이션을 해보자. pred90 &lt;- posterior_predict(fit88, newdata=data90) 10.6.5 Predictive simulation for a nonlinear function of new data 1990년에 민주당에 의해 승리한 선거의 수는 \\(\\sum^{\\tilde n}_{i=1}I(\\tilde y_i &gt; 0.5\\)로 나타낼 수 있다. dems_pred &lt;- rowSums(pred90 &gt; 0.5) 각 행은 서로 다른 무작위 시뮬레이션의 결과이다: dems_pred &lt;- rep(NA, n_sims) for (s in 1:n_sims) { dems_pred[s] &lt;- sum(pred90[s,] &gt; 0.5) } head(dems_pred) ## [1] 260 259 263 258 261 262 10.6.6 Combining simulation and analytic calculations 몇몇 조건에 있어서는 수학적 분석을 바탕으로 시뮬레이션에 기초한 추론이 큰 도움이 된다(Gelman, Hill, and Vehtari 2020: 144). 10.7 Mathematical notation and statistical inference 특정한 예제를 설명할 때, 기술변수 이름을 사용하는 것이 도움이 된다. 하지만 보다 일반적인 이론과 데이터 관리에 대해 논의하기 위해 여기서는 수학적 용어들을 사용하고자 한다(Gelman, Hill, and Vehtari 2020: 144). 10.7.1 Predictors \\(X\\) 행렬에서 열에 대해 예측변수라는 표현을 사용한다. 예를 들어, 엄마의 교육수준과 IQ 수준의 상호작용을 포함한 모델을 생각해보자. \\[ \\text{kid_score} = 58 + 16 \\times \\text{mom_hs} + 0.5 \\times \\text{mom_iq} − 0.2 \\times \\text{mom_hs} \\times \\text{mom_iq} + error. \\] 여기서 예측변수는 세 개이다: \\(\\text{mom_hs}\\), \\(\\text{mom_iq}\\), 그리고 \\(\\text{mom_hs} \\times \\text{mom_iq}\\). 10.7.2 Regression in vector-matrix notation 회귀분석은 벡터-행렬로도 나타낼 수 있다.\\(y_i\\)의 \\(i^{\\text{th}}\\) 관측치는 결정주의적 예측으로는 \\(X_i\\beta = \\beta_1X_{i1}+\\cdots+\\beta_kX_{ik}\\)로 나타낼 수 있다. 일단 \\(X_{i1}\\)은 상수항으로 절편값을 의미한다. \\(\\epsilon_i\\)은 평균 0에 표준편차 \\(\\sigma\\)인 정규분포를 따르며, 오차를 의미한다. 즉, \\(\\mathrm{N}(0, \\sigma^2)\\)로 나타낼 수 있다. 잔차는 실제 관측치와 추정된 예측값 간의 차이를 보여준다: \\(y - X \\hat \\beta\\). 주어진 예측변수의 데이터 \\(\\tilde X\\)일 때, 모델로부터 얻은 예측값 \\(\\tilde y\\)는 Figure 10.7로 확인할 수 있다. Figure 10.3: Notation for regression modeling. The model is fit to the observed outcomes \\(y\\) given predictors \\(X\\). As described in the text, the model can then be applied to predict unobserved outcomes \\(\\tilde y\\) (indicated by small question marks), given predictors on new data \\(\\tilde X\\). 10.7.3 Two ways of writing the model 전통적인 선형회귀모델은 수학적으로 다음과 같이 쓸 수 있다: \\[ y_i = \\beta_1 X_{i1} + \\cdots + \\beta_k X_{ik} + \\epsilon_i \\] 이때, 오차는 평균이 0이고 표준편차가 \\(\\sigma\\)이며 독립적인 정규분포를 따른다. 행렬을 이용하면, \\[ y_i = X_i\\beta + \\epsilon_i \\] 로 나타낼 수 있고, 이때 \\(X\\)는 \\(n\\times k\\)의 행렬이라고 할 수 있다. 이는 다음과도 동일하다. \\[ y_i \\sim \\mathrm{N}(X_i\\beta, \\sigma^2) \\] 마지막으로 더 축약하면 다음과 같이 쓸 수 있다. \\[ y \\sim \\mathrm{N}(X\\beta,\\sigma^2I). \\] ### Least squares, maximum likelihood, and Bayesian inference 최소자승법을 통한 추정량은 잔차의 제곱합, \\(\\mathrm{RSS}= \\sum^n_{i=1}(y_i-X\\hat\\beta)^2\\)를 최소화하는 \\(\\hat \\beta\\)의 벡터를 구하는 것에서부터 시작한다. 여러 개의 예측변수를 가진 표준 선형회귀모델에서는 오차는 독립적이고 등분산(equal variance)을 가지며 정규적으로 분포되어 있다. 그리고 최소자승의 해(solution)은 이때 최대가능도로 구한 추정량과 같다. OLS와 MLE 결과의 차이는 잔차의 표준편차에 대한 추정일 뿐이다. \\[ \\hat \\sigma = \\sqrt{\\mathrm{RSS}/(n-k)} \\] 이때, \\(k\\)는 회귀계수의 숫자이다. 10.7.4 Nonidentified parameters, collinearity, and the likelihood function 최대가능도에서 가능도를 바꾸지 않으면 파라미터는 바뀔 수 있기 때문에 파라미터는 식별되지 않는다. 즉, 만약 단 하나로만 추정될 수 있는 파라미터를 포함하지 않는다면, 모델은 “식별불가능하다(nonidentifiable).” 이후 챕터에서 본격적으로 다룰 내용이다. 10.7.5 Hypothesis testing: why we do not like \\(t\\) tests and \\(F\\) tests 간단하게 얘기하면 \\(t\\) 검정은 회귀계수가 0과 유의미하게 통계적으로 다른지를 입증하는 것이며, 명시적으로는 특정한 계수값 \\(\\beta_j\\)가 0과 같은지를 의미하는 영가설에 대한 검정을 수행하는 것이다. 특정한 가정 하에서 표준화 회귀계수인 \\(\\hat \\beta_j/\\text{s.e.}_j\\)는 \\(t_{n-k}\\) 분포를 따른다. \\(F\\) 검정은 회귀모델 전체에 대한 경험적 근거를 입증하는 데 사용된다. 이때의 영가설은 모델 내 상수항을 제외한 모든 회귀계수의 값이 0과 같을 것이라는 진술이다. 특정한 가정 하에서 잔차의 제곱합에 대한 전체 변동량의 비율은 \\(F\\) 분포를 따르며, 만약 제곱합의 비율이 어느 수준을 넘으면, 표본 규모 \\(n\\)과 예측변수의 수 \\(k\\)에 따라 영가설은 기각될 수 있다. 10.8 Weighted regression 오차가 등분산을 가지고 독립적이고 정규적으로 분포되어 있다고 할 때, 최소자승법을 이용한 회귀모델은 최대가능도 추정법과 같은 결과를 제시한다. 잔차의 제곱합에 있어서 각 항(terms)에는 동일한 가중치가 부여된다. 그러나 몇몇 조건 하에서 모델을 적합할 때, 일부 데이터 관측치에 가중치를 부여해야할 필요가 있다. 이때, 우리는 가중치를 부여한 최소자승법으로 \\(\\hat \\beta_{\\text{wls}}\\)를 추정하고, 이는 \\(\\sum^n_{i=1}w_i(y_i-X_i\\beta)^2\\)를 최소화하는 결과이며, 이때 가중치 \\(w = (w_1, \\dots, w_n)\\)는 음수가 아닌 가중치이다. OLS처럼 행렬대수를 이용해서 가중치를 부여한 최소제곱 추정량을 다음과 같이 구할 수 있다. \\[ \\hat \\beta = (X^tW^{-1}X)^{-1}X^tW^{-1}y \\] 이때, \\(W\\)는 가중치의 행렬, \\(W = \\text{Diag}(w)\\)을 의미한다. 10.8.1 Three models leading to weighted regression 가중치를 부여한 최소자승법은 세 가지의 서로 다른 모델로부터 유도될 수 있다: 관측된 데이터를 이용해 더 큰 모집단을 대표 회귀모델에 가중치를 부여하는 가장 일반적인 방식. 전체 모집단에 적합했을 때 얻어지는 가중치가 부여되지 않은(unweighted) 선형모델을 추정하기 위해 표본 데이터에 일정한 가중치를 부여-대표성 있는 표본으로 만들어 적합한 결과 중복된 관측치(duplicate observations): 특정한 값이 중복된다는 것은 과대대표된다는 것을 의미. 제약이 가해진 데이터셋, \\((x, y, w)\\)에 대한 가중치가 부여된 회귀모델은 원데이터에 대한 가중치가 부여되지 않은 회귀분석과 동등하다. 이분산(unequal variances) 독립적이고 정규적으로 분포한 오차가 분산이 일정하지 않은 회귀모델에 대한 최대 가능도 추정량은 가중치가 부여된 최소제곱 추정량이라고 할 수 있다. 그리고 이때, 오차의 표준편차, \\(\\text{sd}(\\epsilon_i)\\)은 \\(1\\sqrt{w_i}\\)에 비례한다. 모델을 적합할 때, 더 큰 분산을 가질 경우, 작은 가중치를 부여하는 식이다. 위의 세 모델은 동일한 점추정치를 산출하지만 서로 다른 표준 오차와 예측분포를 가진다. 대개의 경우, 가중치는 표본과 모집단 간의 차이를 보정하기 위해 사용되며, 한 번 가중치가 적용되고 나면 가중치를 평균 1을 가지는 벡터로 재정규화한다(R에서는 w &lt;- w/mean(w)로 설정). 그리고 나서 회귀모델에 다음과 같이 가중치를 부여할 수 있다: stan_glm(y ~ x, data = data, weights = w. 10.8.2 Using a matrix of weights to account for correlated errors 가중치 행렬 \\(W\\)를 이용해서 공분산행렬 \\(W^{-1}\\)를 가진 정규적으로 분포된 오차 모델에 대한 최대가능도 추정량을 산출할 수 있고, 이를 일반화 최소자승이라고 불린다. 상관성을 가지는 모델은 시계열, 공간통계, 클러스터 표본 등 다른 구조화된 데이터에서 찾아볼 수 있다. 10.9 Fitting the same model to many datasets 회귀모델을 반복적으로 서로 다른 데이터셋에 적합하거나 기존 데이터셋의 서브셋에 적합시키는 것은 흔하다. 이와 같은 반복된 모델링 방법은 거의 사용되지는 않는다. Gelman, Hill, and Vehtari (2020) 은 그 이유가 교차사례 분석과 같은 자료들에 내재된 문제들을 해결하지 못하기 때문이다. 교차사례나 시계열 등의 자료에서 각 변수들 간의 상관과 같이 동일한 모델을 반복적으로 적용하는 데에는 제약이 있다. 10.9.1 Predicting party identification Figure 10.9는 시간에 따라 추적한 추정된 계수값의 변환을 보여준다. 이념과 인종이 가장 중요하고 그 그 둘의 계수값은 시간이 바뀔 때마 마찬가지로 변화해왔다. Figure 10.9는 여러 모델을 추정하는 것이 어떻게 유용한지를 보여준다. 여러 예측변수에 기초해서 모델을 쪼개어보는 결과, 각 패널마다의 평균적인 경향성이 드러나는 것을 확인할 수 있기 때문이다. ## Error in select(., year, partyid7, real_ideo, race_adj, age_discrete, : unused arguments (year, partyid7, real_ideo, race_adj, age_discrete, educ1, female, income) ## Error in select(., !age_discrete): unused argument (!age_discrete) ## Error in select(., !c(data, fit)): unused argument (!c(data, fit)) ## Error in select(., !c(data, fit)): unused argument (!c(data, fit)) Figure 10.4: Estimated coefficients \\(\\pm 0.67\\) standard errors (thus, 50% intervals) for the regression of party identification on political ideology, ethnicity, and other predictors, as fit separately to poll data from each presidential election campaign from 1976 through 2000. The plots are on different scales, with the predictors ordered roughly in declining order of the magnitudes of their coefficients. The set of plots illustrates the display of inferences from a series of regressions. References "],["assumptions-diagnostics-and-model-evaluation.html", "Chapter 11 Assumptions, diagnostics, and model evaluation 11.1 Assumptions of regression analysis 11.2 Plotting the data and fitted model 11.3 Residual plots 11.4 Comparing data to replications from a fitted model 11.5 Example: predictive simulation to check the fit of a time-series model 11.6 Residual standard deviation \\(\\sigma\\) and explained variance \\(R^2\\) 11.7 External validation: checking fitted model on new data 11.8 Cross validation", " Chapter 11 Assumptions, diagnostics, and model evaluation 이 챕터에서는 회귀모델의 가정과 그 가정들이 합당한지에 대해 평가할 수 있는 진단에 대해 살펴본다. 가장 중요한 가정은 연구대상에 대한 연구자의 지식이며, 가용한 데이터 하나만을 가지고 가정을 직접적으로 검증할 수 없다. 모델의 바탕에 놓은 개념들을 이해하고, 실제 세계와 시뮬레이션된 데이터의 사례들의 맥락 속에서 방법들을 발전시키는 것이 필요하다. Gelman, Hill, and Vehtari (2020) 은 적합된 모델로부터 예측 시뮬레이션에 기초한 진단을 통해 여러 예측변수를 포함한 회귀모델을 구축하고, 해석하고, 평가하는 데 사용할 일련의 도구들을 제시하고자 한다. 11.1 Assumptions of regression analysis Gelman, Hill, and Vehtari (2020, 153) 는 중요도 순으로 회귀모델의 가정들을 나열하고 있다. 타당성(Validity) 분석에 사용하는 데이터가 풀고자 하는 연구문제와 들어맞는 것이어야 한다. 결과변수는 우리가 풀고자 하는/관심을 가지는 현상을 정확하게 반영하여 측정하여야 하고, 모델은 모든 적절한 예측변수들을 포함해야 한다는 것을 의미한다. 나아가 모델은 적용되는 사례들에 대해 일반화할 수 있어야 한다. 회귀모델에 어떤 변수들을 넣을지 결정하는 것은 종종 분석에 있어서 가장 까다로운 문제이다. 적절한 모든 예측변수들을 포함할 것을 권하지만 과연 어떤 변수가 필수적인지를 결정하는 것과 표준오차가 큰 계수값의 결과를 해석하는 것은 어려운 문제이다. 경험과학 연구에서 사용되는 데이터들은 표본과 모집단 간의 대표성을 확보하기 어렵다. 그러나 이러한 목표를 지향하는 것은 연구자가 신뢰할만한 답을 할 수 있는 혹은 할 수 없는 유형의 연구문제에 대해 보다 정확한 견해를 취할 수 있도록 한다. 대표성(representativeness) 연구자는 데이터에 회귀모델을 적합하여 보다 큰 모집단에 대한 추론을 이끌어내는 데 사용한다. 이때, 회귀계수를 해석하는 데 있어서의 묵시적 가정은 표본이 모집단의 대표적 사례라는 것이다. 우리가 가지고 있는 표본, 데이터는 [모집단에서] 모델에 포함된 예측변수들 \\(x_1, x_2, \\dots, x_n\\)이 주어졌을 때의 결과변수, \\(y\\)의 분포를 대표하는 것이라는 가정이다. 이러한 가정은 연구자로 하여금 가급적 예측변수들을 더 많이 모델에 포하하여 대표성의 가정을 충족시키고자 하는 유인이 된다. 우리는 모집단을 직접 관측할 수 없기 때문에, 결과변수에 영향을 미칠 것으로 기대되는 변수라면 가능한 한 모델에 포함하고자 하는 합당한 유인을 가지게 되는 것이다. 대표성이란 기존에 표본으로 간주되던 데이터가 아닌 경우에도 동일하게 적용된다. 예를 들어, Section 7.1 에서 16개의 연속적인 선거에 대한 데이터를 다루는 예측 모델을 생각해보자. 그 데이터들은 공통된 모집단으로부터 얻은 표본이 아니지만, 우리는 그 모델을 통해 미래의 선거를 예측하고자 하는 목적을 가진다. 미래의 선거를 예측하기 위해 과거 데이터에 회귀모델을 적합하는 것은 수학적으로 관측된 데이터를 가설적인 초모집단(hypothetical superpopulation)으로부터 무작위로 표집한 하나의 표본으로서의 새로운 결과(데이터)와 동일시하는 것이다. 즉, 오차를 정규오차분포로부터 도출된 무작위 표본으로 간주하는 것이다. 어디까지나 일반화(generalization)으로부터 자유롭지 못하다면, 통계적 표집의 개념을 염두에 두어야 하고, 우리가 추론을 이끌어내고자 하는 묵시적/명시적 모집단에 대한 표본의 대표성의 문제 역시 생각해야만 한다. 가산성과 선형성(additivity and linearity) 수리적으로 선형회귀모델의 가장 중요한 가정은 바로 서로 분리된 예측변수들에 대한 선형 함수의 결정적 요인들(deterministic components)이다: \\(y = \\beta_0 + \\beta_1x_1 + \\beta_2x_2 + \\cdots .\\) 가산성이 위배된다면, 데이터를 변환하거나(만약 \\(y = abc\\)라면 \\(\\log y = \\log a + \\log b + \\log c\\)) 상호작용을 더하는 것을 고려해볼 수 있다. 선형성이 위배된다면 예측변수들은 단순히 선형적으로 배열되는 것이 아니라 \\(1/x\\)나 \\(\\log(x)\\)의 형태로 투입될 수 있다. 연구문제들이 비선형적일 수 있지만, 선형회귀모델은 여전히 평균적인 관계 양상을 추정하는 데 있어서 유용할 수 있다. 데이터를 더 많이 얻을수록, 그리고 우리가 가진 연구문제가 비선형적일수록, 모델에 비선형성을 반영하려는 노력이 필요해진다. 오차의 독립성(independence of errors) 단순선형회귀모델은 예측선으로부터의 오차는 서로 독립적이라고 가정하며, 이 가정은 시계열/공간/멀티레벨의 조건에서 위배된다. 시계열에서는 자기상관(autocorrelation), 공간분석에서는 동시상관(contemporaneous correlation), 멀티레벨에서는 레벨 간 상관 등의 문제로 독립성이 위배될 수 있다. 오차의 등분산(equal variance of errors) 오차의 분산이 동일하지 않을 때, 등분산성(equal variance or homoscedasticity)과 대조되는 개념으로 이분산성(heteroscedasticity)이라고 한다. 오차의 이분산성은 회귀모델을 통해 확률적 예측을 수행할 때 문제가 될 수 있다. 하지만 오차의 이분산성은 예측 그 자체의 정확성에는 영향을 미치지 않는다. 즉, 계수값 그 자체를 왜곡시키거나 하는 문제는 아니다. 오차의 이분산성이 존재할 때는 가중치를 부여한 최소자승법을 통해 모델을 더 효율적으로 추정하는 것이 가능하다. 오차의 정규성(normality of errors) 오차항의 분포는 데이터의 개별 관측치들을 예측할 때 중요하다. 회귀선을 추정하고자 할 때, 정규성 가정은 전혀 중요하지 않다. 따라서 Gelman, Hill, and Vehtari (2020) 은 회귀 잔차의 정규성에 대한 진단을 추천하지는 않는다. 그보다 Gelman, Hill, and Vehtari (2020) 은 타당성, 대표성, 가산성, 선형성에 대한 가정을 더 중요하게 생각한다. 보다 중요한 것은 오차항이 예측변수와 독립적이냐 아니냐 하는 것이다. 만약 오차항과 예측변수가 서로 상관관계를 가지고 있다면, 이는 결과변수를 예측하기 위한 적절한 예측변수를 모델에 충분히 포함시키지 못한 결과일 수 있기 때문이다. 11.1.1 Failures of the assumptions 가정이 위배되었을 때는 어떻게 하는가? 모델을 기존의 선형회귀모델에서 다른 관계양상을 설명할 수 있는 모델로 확장할 수 있다. 가정이 합당하도록 데이터 또는 모델을 바꾸는 것이 더 단순할 수 있다. 데이터를 목적에 맞게 전처리하거나, 대표성 가정에 더 들어맞도록 예측변수를 추가하거나 비선형성을 포착하기 위한 상호작용항을 더하거나, 예측변수와 결과변수를 변환하여 가산모델(additive model)이 말이 될 수 있도록 할 수 있다. 실질적으로 연구자는 모델의 확장, 데이터 공정(전처리) 등을 복합적으로 적용하고 데이터 너머의 범위(extrapolation; generalizability 개념과 연동해서)를 함께 생각해볼 수 있다). 11.1.2 Causal inference 회귀계수를 인과적으로 해석하고자 한다면 추가적인 가정들이 필요하다. 이 가정들의 내용은 제4부에서 더 자세히 다룬다. 회귀분석의 맥락에서 인과적 추론은 다양한 예측변수들이 특정한 값에 고정되었을 때 나타날 수 있는 결과에 대한 예측의 형태로 간주된다. 회귀계수에 대한 인과적 해석을 부여하는 것에는 근본적인 오류가 존재한다. 회귀모델은 서로 다른 관측치들로부터 얻은 데이터에 적합한다. 그러나 인과적 질문은 어떤 한 사람에게 벌어진 일에 관한 내용이다. 엄밀하게 말하면 회귀모델의 기울기는 서로 다른 관측치의 차이를 비교하며, 평균 차이를 보여주는 것이다. 그 평균적인 경향성은 반드시 특정 개별 관측치가 반드시 그러할 것이라는 의미를 갖지는 않는다. 11.2 Plotting the data and fitted model 그래픽은 데이터를 시각화하고, 모델을 이해하고, 적합된 모델에서는 설명되지 않은 데이터 내의 패턴들을 드러내는 데 유용하다. 11.2.1 Displaying a regression line as a function of one input variable 아이들의 시험성적 예제를 통해 R에서 적합된 모델의 구체적인 정보들을 살펴보도록 하자. library(rstanarm) library(rstantools) fit_2 &lt;- lm(kid_score ~ mom_iq, data = kidiq) kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point(shape = 21) + geom_smooth(method = &quot;lm&quot;, se = T) + labs(x = &quot;Mother IQ score&quot;, y = &quot;Child test score&quot;) Figure 11.1은 개별 관측치들에 대한 산포도와 적합된 회귀모델로부터 추정된 계수값을 사용한 회귀선-\\(y = \\hat a + \\hat x\\)을 보여준다. 11.2.2 Displaying two fitted regression lines 11.2.2.1 Model with no interaction 두 개의 예측변수를 가진 모델의 경우, 우리는 각 예측변수와 결과변수에 대해 그릴 수 있다. fit_3 &lt;- lm(kid_score ~ mom_hs + mom_iq, data=kidiq) b_hat &lt;- coef(fit_3) kidiq %&gt;% mutate(colors = if_else(mom_hs==1, &quot;black&quot;, &quot;gray&quot;)) %&gt;% ggplot(aes(x = mom_iq, y = kid_score, color = colors)) + geom_point(shape = 21, alpha = 2/3, show.legend = F) + scale_color_manual(values = futurevisions::futurevisions(&quot;mars&quot;)) + geom_abline(intercept = b_hat[1] + b_hat[2], slope = b_hat[3], color = futurevisions::futurevisions(&quot;mars&quot;)[1]) + geom_abline(intercept = b_hat[1], slope = b_hat[3], color = futurevisions::futurevisions(&quot;mars&quot;)[2]) + labs(x = &quot;Mother IQ score&quot;, y = &quot;Child test score&quot;) mom_hs가 연속형 예측변수라면 우리는 kid_score와 mom_iq 간의 관계를 mom_hs의 서로 다른 두 값에 따른 적합된 회귀선으로 비교하여 보여줄 수 있다. 11.2.2.2 Model with interaction 상호작용항을 포함한 모델에 대해 앞서와 동일한 플롯을 그릴 수 있다. 이 경우 다른 점은 두 회귀선이 서로 다른 기울기를 가지게 된다는 것이다. fit_4 &lt;- lm(kid_score ~ mom_hs + mom_iq + mom_hs:mom_iq, data=kidiq) b_hat &lt;- coef(fit_4) kidiq %&gt;% mutate(colors = if_else(mom_hs==1, &quot;black&quot;, &quot;gray&quot;)) %&gt;% ggplot(aes(x = mom_iq, y = kid_score, color = colors)) + geom_point(shape = 21, alpha = 2/3, show.legend = F) + scale_color_manual(values = futurevisions::futurevisions(&quot;mars&quot;)) + geom_abline(intercept = b_hat[1] + b_hat[2], slope = b_hat[3] + b_hat[4], color = futurevisions::futurevisions(&quot;mars&quot;)[1]) + geom_abline(intercept = b_hat[1], slope = b_hat[3], color = futurevisions::futurevisions(&quot;mars&quot;)[2]) + labs(x = &quot;Mother IQ score&quot;, y = &quot;Child test score&quot;) 11.2.3 Displaying uncertainty in the fitted regression Section 9.1에서 추정된 회귀계수에서 어떻게 사후 시뮬레이션이 불확실성을 보여주는지에 대해서 논의하였다. 여기에서는 어떻게 시뮬레이션을 통해 추론의 불확실성을 시각적으로 보여줄 수 있는지를 살펴본다. 다음과 같은 단순한 모델을 생각해보자: fit_2 &lt;- lm(kid_score ~ mom_iq, data=kidiq) 회귀선에 대한 불확실성을 보여주는 10번의 시뮬레이션의 적합된 회귀선을 그려보자. lm 함수를 쓰면 시뮬레이션 값을 가지지 않기 때문에 다변량 무작위 정규분포로부터 계수값에 대한 시뮬레이션을 10개 추출해서 다음과 같이 그래프를 그렸다. library(mvtnorm) sims_2 &lt;- rmvnorm(10, mean = coef(fit_2), sigma = vcov(fit_2)) n_sims_2 &lt;- nrow(sims_2) beta_hat_2 &lt;- apply(sims_2, 2, median) kidiq %&gt;% ggplot(aes(x = mom_iq, y = kid_score)) + geom_point(shape = 21) + geom_abline(intercept = sims_2[1,1], slope = sims_2[1,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[2,1], slope = sims_2[2,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[3,1], slope = sims_2[3,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[4,1], slope = sims_2[4,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[5,1], slope = sims_2[5,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[6,1], slope = sims_2[6,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[7,1], slope = sims_2[7,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[8,1], slope = sims_2[8,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[9,1], slope = sims_2[9,2], color = &quot;gray&quot;) + geom_abline(intercept = sims_2[10,1], slope = sims_2[10,2], color = &quot;gray&quot;) + geom_abline(intercept = beta_hat_2[1], slope = beta_hat_2[2], color = &quot;black&quot;) + labs(x = &quot;Mother IQ score&quot;, y = &quot;Child test score&quot;) Figure 11.1: Data and regression of child’s test score on maternal IQ, with the solid line showing the fitted regression model and light lines indicating uncertainty in the fitted regression. 11.2.4 Displaying using one plot for each input variable 회귀모델이 엄마의 고등학교 수료 여부에 대한 더미변수를 포함하고 있다고 해보자. fit_3 &lt;- lm(kid_score ~ mom_hs + mom_iq, data=kidiq) sims_3 &lt;- rmvnorm(10, mean = coef(fit_3), sigma = vcov(fit_3)) n_sims_3 &lt;- nrow(sims_3) beta_fit_3 &lt;- coef(fit_3) beta_hat_3 &lt;- apply(sims_3, 2, median) 이 시뮬레이션 결과를 바탕으로 Figure 11.2를 그려보자. Figure 11.2: Data and regression of child’s test score on maternal IQ and high school completion, shown as a function of each of the two input variables with the other held at its average value. Light lines indicate uncertainty in the regressions. Values for mother’s high school completion have been jittered to make the points more distinct. 11.2.5 Plotting the outcome vs. a continuous predictor 주어진 처치변수 중 더미변수인 \\(z\\)와 처치 전 연속형 예측변수인 \\(x\\)가 주어졌다고 할 때, 연속형 결과변수 \\(y\\)를 갖는 모델을 다음과 같이 구축했다고 하자. \\[ y = a + bx + \\theta z + error \\] 그리고 이제 가상의 데이터를 시뮬레이션해보자. set.seed(1234) n &lt;- 100; a &lt;- 1; b &lt;- 2 theta &lt;- 5 ;sigma &lt;- 2 data_1 &lt;- tibble( x = runif(n, min = 0, max = 1), z = rep(0:1, n / 2) %&gt;% sample(), y = a + b * x + theta * z + rnorm(n, mean = 0, sd = sigma) ) fit_1 &lt;- lm(y ~ x + z, data = data_1) lines &lt;- tribble( ~z, ~intercept, ~slope, 0, coef(fit_1)[[&quot;(Intercept)&quot;]], coef(fit_1)[[&quot;x&quot;]], 1, coef(fit_1)[[&quot;(Intercept)&quot;]] + coef(fit_1)[[&quot;z&quot;]], coef(fit_1)[[&quot;x&quot;]] ) data_1 %&gt;% ggplot(aes(x, y, color = factor(z))) + geom_point(shape = 21) + geom_abline( aes(slope = slope, intercept = intercept, color = factor(z)), data = lines ) + facet_wrap(~factor(z)) + scale_color_manual(values=futurevisions::futurevisions(&quot;mars&quot;)) + theme(legend.position = &quot;bottom&quot;) + labs( x = &quot;Pre-treatment predictor, x&quot;, y = &quot;Outcome, y&quot;, color = &quot;Treatment&quot; ) Figure 11.3: From a hypothetical study of a pre-treatment variable \\(x\\), treatment indicator \\(z\\), and outcome \\(y\\): data and fitted regression line plotted separately for control and treatment groups. 회귀모델을 적합하고 데이터와 적합된 모델을 그래프로 나타내보자. Figure 11.3은 각각 연속형 \\(x\\), 이산형 \\(z\\)에 대해서 서로 다른 \\(z\\)값에서의 \\(y\\)-\\(x\\)의 관계를 보여준다. 11.2.6 Forming a linear predictor from a multiple regression 이전의 예제를 확장해서 \\(k\\)개의 사전 처치 예측변수들-\\(x_k, k = 1,\\dots,K\\)에 대한 처치 더미변수 \\(z\\)의 경우를 생각해보자. \\[ y = b_0 + b_1x_1 + \\cdots + b_Kx_K + \\theta_z + \\text{error}. \\] 이 데이터의 경우에는 어떻게 시각화를 해줄 수 있을까? 다른 사전 예측변수들의 값을 평균으로 고정시켜둔 상태에서 \\(z=0\\)일 때와 \\(z=1\\)일 때에 대해 \\(y\\)-\\(x_K\\) 관계를 시각화할 수 있다. 통제집단을 \\((z=0)\\)로, 처치 집단을 \\((z=1)\\)인 집단으로 상정하여 결과변수 \\(y\\)에 대한 선형예측, \\(\\hat y = \\hat b_0 \\hat b_1 x_1 + \\cdots + \\hat b_Kx_K + \\hat \\theta z\\)를 각각 두 집단에서 추정하는 방식이 있다. 먼저 페이크데이터를 이용해 \\(K= 10\\)인 예측변수들과 상수항을 가지는 회귀모델을 구축, 시뮬레이션을 해보자. set.seed(1234) n &lt;- 100; k &lt;- 10; a &lt;- 1; b &lt;- 1:k theta &lt;- 5; sigma &lt;- 2 data_2 &lt;- tibble( X = matrix(runif(n * k, min = 0, max = 1), nrow = n, ncol = k), z = rep(0:1, n / 2) %&gt;% sample(), y = as.double(a + X %*% b + theta * z + rnorm(n, mean = 0, sd = sigma)) ) fit_2 &lt;- lm(y ~ X + z, data = data_2) data_2 %&gt;% mutate(pred = predict(fit_2)) %&gt;% ggplot(aes(pred, y, color = factor(z))) + geom_point(show.legend = F) + geom_abline(slope = 1, intercept = 0) + coord_fixed() + facet_wrap(~factor(z)) + scale_color_manual(values = futurevisions::futurevisions(&quot;mars&quot;)) + scale_y_continuous(breaks = scales::breaks_width(10)) + labs( title = &quot;Outcome vs. predicted value&quot;, x = &quot;Predicted value of y&quot;, y = &quot;Outcome, y&quot;, color = &quot;Treatment&quot; ) Figure 11.4: From a hypothetical study of 10 pre-treatment variables \\(X\\), treatment indicator \\(z\\), and outcome \\(y\\): Outcome plotted vs. fitted linear predictor \\(\\hat y\\) (so that the fitted regression line is by definition \\(y = \\hat y\\)), plotted separately for control and treatment groups. Figure 11.4는 예측된 \\(y\\)와 관측된 \\(y\\) 간의 관계를 나타낸다. 오차항 \\(u\\)는선형 예측값, \\(E(y)\\)에 의해 정의된다. 만약 오차가 크지 않다면 관측된 \\(y\\)와 예측값 \\(\\hat y\\)는 동일 선상에 놓이게 될 것이다. 11.3 Residual plots 데이터와 적합된 회귀선을 그래프로 시각화한다면, 우리는 데이터와 모델로 인한 기대값 간의 차이를 살펴보는 것으로 적합이 잘 되었는지를 평가할 수 있다: 그 차이가 바로 잔차(residuals)이다. \\[ r_i = y_i - X_i\\hat \\beta. \\] 잔차를 구해보자: \\(r_i = y_i - (\\hat b_0 + \\hat b_1 x_{i1} + \\cdots + \\hat b_K x_{iK} + \\hat \\theta z_i)\\). 만약 모델이 정확하다면 잔차를 그래프로 나타냈을 때, 우리는 대략적으로 무작위 분포된 잔차의 분포를 볼 수 있게 된다. Figure 11.5를 보자. set.seed(1234) data_2 %&gt;% mutate( pred = predict(fit_2), resid = residuals(fit_2) ) %&gt;% ggplot(aes(pred, resid, color = factor(z))) + geom_hline(yintercept = 0, color = &quot;white&quot;, size = 2) + geom_point(show.legend = F) + facet_wrap(~factor(z)) + geom_hline(yintercept = 0) + scale_color_manual(values = futurevisions::futurevisions(&quot;mars&quot;)) + theme(legend.position = &quot;bottom&quot;) + labs( title = &quot;Residual vs. predicted value&quot;, x = &quot;Predicted value of y&quot;, y = &quot;Residual, r&quot;, color = &quot;Treatment&quot; ) Figure 11.5: Continuing Figure 11.4, the residual, \\(r = y- \\hat y\\), vs. the fitted linear predictor \\(\\hat y\\), plotted separately for control and treatment groups. Figure 11.6은 시험성적 예제에서 엄마의 IQ로 아이의 시험성적을 회귀분석한 데 대한 잔차 그래프를 보여준다. Figure 11.6은 강한 패턴을 보여주지는 않는다. 잔차 그래프는 모델적합도와 관련된 체계적 문제들을 확인할 수 있게 한다. Figure 11.6은 모델로부터 구한 오차가 평균을 0으로 하며 예측변수와 독립적이라는 것을 보여준다. fit_2 &lt;- lm(kid_score ~ mom_iq, data = kidiq) kidiq %&gt;% mutate(resid = residuals(fit_2), upper = resid + sd(resid), lower = resid - sd(resid)) -&gt; newkids newkids %&gt;% ggplot(aes(mom_iq, resid)) + geom_hline(yintercept = 0, color = &quot;black&quot;) + geom_hline(yintercept = mean(newkids$upper), color = &quot;black&quot;, linetype = 2) + geom_hline(yintercept = mean(newkids$lower), color = &quot;black&quot;, linetype = 2) + geom_point() + scale_x_continuous(breaks = scales::breaks_width(10)) + labs(x = &quot;Mother IQ score&quot;, y = &quot;Residual&quot;) Figure 11.6: Residual plot for child test score data when regressed on maternal IQ, with dotted lines showing \\(\\pm 1\\) standard-deviation bounds. The residuals show no striking patterns. 11.3.1 Using fake-data simulation to understand residual plots 모델, \\(y = X\\beta + \\epsilon\\)으로부터 페이크데이터를 시뮬레이션했다고 했을 때, 모델을 시뮬레이션된 데이터에 재적합하고 계수 \\(\\beta\\)에 대한 68%, 95%의 구간을 확인할 수 있다. 11.3.2 A confusing choice: plot residuals vs. predicted values, or residuals vs. observed values? 실제 데이터에 대한 단순한 모델을 적합해보고, 기초통계학 수업(scores)에서 중간고사 성적으로 기말시험 성적을 예측해보자. file_scores &lt;- here::here(&quot;data/ros-master/Introclass/data/gradesW4315.dat&quot;) scores &lt;- file_scores %&gt;% read.table(header = TRUE) %&gt;% as_tibble() fit_1 &lt;- lm(final ~ midterm, data = scores) summary(fit_1) ## ## Call: ## lm(formula = final ~ midterm, data = scores) ## ## Residuals: ## Min 1Q Median 3Q Max ## -36.832 -6.573 2.761 8.880 29.055 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 64.5048 16.9778 3.799 0.000394 *** ## midterm 0.7036 0.2144 3.281 0.001888 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 14.75 on 50 degrees of freedom ## Multiple R-squared: 0.1772, Adjusted R-squared: 0.1607 ## F-statistic: 10.77 on 1 and 50 DF, p-value: 0.001888 sigma(fit_1) ## [1] 14.75195 이제 계수들을 시뮬레이션해서 평균 예측값인 \\(y_i^{\\text{pred}}\\)와 잔차 \\(y_i - y_i^{\\text{pred}}\\)를 구해보자. sims &lt;- rmvnorm(1000, mean = coef(fit_1), sigma =vcov(fit_1)) predicted &lt;- predict(fit_1) resid &lt;- scores$final - predicted Figure 11.7은 모델로부터 얻은 잔차를 두 가지 서로 다른 방식으로 보여준다. 예측값과 잔차 간의 관계를 보여주는 것 관측값과 잔차 간의 관계를 보여주는 것 scores %&gt;% mutate( pred = predict(fit_1), resid = residuals(fit_1) ) -&gt; scores scores %&gt;% ggplot(aes(pred, resid)) + geom_hline(yintercept = 0, color = &quot;black&quot;) + geom_point() + scale_x_continuous(breaks = scales::breaks_width(5)) + labs( title = &quot;Residual vs. predicted value&quot;, x = &quot;Predicted value&quot;, y = &quot;Residual&quot; ) -&gt; panelscore1 scores %&gt;% ggplot(aes(final, resid)) + geom_hline(yintercept = 0, color = &quot;black&quot;) + geom_point() + scale_x_continuous(breaks = scales::breaks_width(10)) + labs( title = &quot;Residual vs. observed value&quot;, x = &quot;Observed value&quot;, y = &quot;Residual&quot; ) -&gt; panelscore2 panelscore1 + panelscore2 + plot_layout(ncol = 2) Figure 11.7: From a model predicting final exam grades from midterms: plots of regression residuals versus predicted and versus observed values. The left plot looks reasonable but the right plot shows strong patterns. How to understand these? An exploration using fake data (see Figure 11.8) shows that, even if the model were correct, we would expect the right plot to show strong patterns. The plot of residuals versus observed thus does not indicate a problem with the model. 하지만 Figure 11.7b는 문제의 소지가 있어보인다. 왜냐하면 잔차 역시도 원래는 관측된 값에 포함된-우리가 관측하지 못한 변동성일 것이기 때문에 관측값과 잔차는 어떻게든 일정한 체계적 관계를 맺기 때문이다. 11.3.3 Understanding the choice using fake-data simulation 주어진 모델 추정량을 바탕으로 계수값과 표준편차를 설정하고 실제 중간고사 성적을 예측변수로 기말고사 성적을 페이크데이터로 시뮬레이션해서 만들어보자. a &lt;- 64.5; b &lt;- 0.7 sigma &lt;- 14.8 n &lt;- nrow(scores) scores$final_fake &lt;- a + b*scores$midterm + rnorm(n, 0, sigma) 페이크데이터에 회귀모델을 적합하고 예측값과 잔차를 컴퓨팅해보자. fit_fake &lt;- lm(final_fake ~ midterm, data=scores) sims &lt;- rmvnorm(1000, mean = coef(fit_fake), sigma = vcov(fit_fake)) predicted_fake &lt;- colMeans(sims[,1] + sims[,2] %*% t(scores$midterm)) Figure 11.8: From fake data: plots of regression residuals versus (a) predicted or (b) observed values. Data were simulated from the fitted family of regression models, and so we know that the pattern on the right does not represent any sort of model failure. This is an illustration of the use of fake data to evaluate diagnostic plots. Compare to the corresponding plots of real data in Figure 11.7. Figure 11.8은 resid_fake 대 predicted_fake와 관측된 final_fake 간의 관계를 보여주는 플롯이다. 우리는 이 플롯을 보고 모델을 평가할 수 있다(좌측을 보고). 11.4 Comparing data to replications from a fitted model 시뮬레이션은 여러 용도로 사용할 수 있다\" 가설적인 확률 모델의 함의를 탐색(Section 5.1) 데이터에 적합된 통계모델의 함의를 탐색(Section 10.6) 알려진 모수의 진실값에 대한 추정량들을 비교함으로서 통계절차의 특성을 연구(Section 7.2와 11.3) 사후 예측분포 확인(posterior predictive checking): 주어진 적합된 모델로 재현된 데이터셋으로 시뮬레이팅한 이후 관측된 데이터와 비교하는 것 11.4.1 Example: simulation-based checking of a fitted normal distribution 모델 적합도(model fit)를 확인하기 위한 가장 기초적인 방법은 재현된 데이터셋을 제시하고 실제 데이터와 비교하는 것이다. Figure 11.9는 Simon Newcomb가 1882년에 광속을 측정하기 위한 실험의 일부로 사용된 데이터를 보여준다. 먼저 예측변수 하나 없이 선형회귀모델을 적합해 데이터에 대한 정규분포를 적합해본다. file_newcomb &lt;- here::here(&quot;data/ros-master/Newcomb/data/newcomb.txt&quot;) newcomb &lt;- read_table2(file_newcomb) fit &lt;- lm(y ~ 1, data = newcomb) 그 다음으로는 적합된 모델로부터 모수를 시뮬레이션하는 것이다. 이 예제에서는 상수항 \\(\\beta_0\\)와 잔차의 표준편차 \\(\\sigma\\)를 얻을 수 있다. fit &lt;- stan_glm(y ~ 1, data=newcomb, refresh = 0) sims &lt;- as.matrix(fit) n_sims &lt;- nrow(sims) 이제 시뮬레이션을 해보자. n &lt;- length(newcomb$y) y_rep &lt;- array(NA, c(n_sims, n)) for (s in 1:n_sims) { y_rep[s,] &lt;- rnorm(n, sims[s,1], sims[s,2]) } posterior_predict() 함수로 재현된 데이터셋에 대한 예측값의 사후분포를 확인해보자. y_rep &lt;- posterior_predict(fit) 11.4.1.1 Visual comparison of actual and replicated datasets Figure 11.9는 Simon Newcomb’s 데이터의 분포를 보여준다. Figure 11.9: Histogram of Simon Newcomb’s measurements for estimating the speed of light, from Stigler (1977). The data represent the amount of time required for light to travel a distance of 7442 meters and are recorded as deviations from 24 800 nanoseconds. Figure 11.10은 무작위로 표집된 데이터셋 중 20개의 관측치에 대한 플롯을 보여준다. Figure 11.10: Twenty replications, \\(y^{rep}\\), of the speed-of-light data from the predictive distribution under the normal model; compare to observed data, \\(y\\), in Figure 11.9. Each histogram displays the result of drawing 66 independent values \\(y_{i}^{rep}\\) from a common normal distribution with mean and standard deviation \\((\\mu, \\sigma)\\) simulated from the fitted model. 실제 데이터와 재현 데이터 간에는 명확한 체계적 차이가 나타난다. 11.4.1.2 Checking model fit using a numerical data summary 데이터를 보여주는 것은 모델 적합도를 확인하기 위한 보다 집중된 검정 통계량을 제안할 수 있다. 검정 통계량 \\(T(y)\\)는 데이터의 최소값과 같으며 이를 바탕으로 우리는 각각의 재현된 데이터셋에 대한 $T(y^{})를 계산하게 된다. test &lt;- function(y) { min(y) } test_rep &lt;- apply(y_rep, 1, test) 재현된 데이터들의 최소값들의 히스토그램을 그리고 관측 데이터의 최소값을 수직선으로 나타내보자. Figure 11.11: Smallest observation of Newcomb’s speed-of-light data (the vertical line at the left of the graph), compared to the smallest observations from each of 20 posterior predictive simulated datasets displayed in Figure 11.10. 이 그래프는 시뮬레이션으로 만든 재현데이터 각각의 최소관측값이 Newcomb의 관측값 중 가장 작은값에 비해 훨씬 더 크다는 것을 보여준다. 11.5 Example: predictive simulation to check the fit of a time-series model 예측 시뮬레이션은 각 시점의 분포가 이전 시점의 데이터에 의해 영향을 받는 시계열 모델에서 더 복잡하다. 여기서는 단순자기회귀(autoregressive) 모델로 설명한다. 11.5.1 Fitting a first-order autoregression to the unemployment series Figure 11.13은 1947년부터 2004년 사이의 미국 내 연간 실업률에 대한 시계열 자료를 보여준다. 얼마나 데이터가 1계 자기회귀에 따라 잘 적합되는지, 즉 이전 연도의 실업률에 대한 회귀모델을 분석해본다. n &lt;- nrow(unemp) unemp$y_lag &lt;- c(NA, unemp$y[1:(n-1)]) fit_lag &lt;- stan_glm(y ~ y_lag, data=unemp, refresh = 0) print(fit_lag) ## stan_glm ## family: gaussian [identity] ## formula: y ~ y_lag ## observations: 69 ## predictors: 2 ## ------ ## Median MAD_SD ## (Intercept) 1.3 0.5 ## y_lag 0.8 0.1 ## ## Auxiliary parameter(s): ## Median MAD_SD ## sigma 1.0 0.1 ## ## ------ ## * For help interpreting the printed output see ?print.stanreg ## * For info on the priors used see ?prior_summary.stanreg 이 결과는 생각보다 데이터에 대한 모델의 적합도에 대해 많은 정보를 알려주지 않는다. 이 적합을 분석하기 위해서 적합된 모델로부터 재현 데이터를 시뮬레이션한다. 11.5.2 Simulating replicated datasets sims &lt;- as.matrix(fit_lag) n_sims &lt;- nrow(sims) 시뮬레이션된 시계열 데이터를 채워넣기 위한 재현 데이터셋의 용기(container)를 만든다. y_rep &lt;- array(NA, c(n_sims, n)) for (s in 1:n_sims){ y_rep[s,1] &lt;- y[1] for (t in 2:n){ y_rep[s,t] &lt;- sims[s,&quot;(Intercept)&quot;] + sims[s,&quot;y_lag&quot;] * y_rep[s,t-1] + rnorm(1, 0, sims[s,&quot;sigma&quot;]) } } 이렇게 얻은 시뮬레이션 결과는 posterior_prect() 함수로 분석을 수행할 수 없는데 시계열 자료에서는 각 연도를 그 전년도에 조건지어서 시뮬레이션을 해야하기 때문이다. 11.5.3 Visual and numerical comparisons of replicated to actual data 첫째로 시뮬레이션된 데이터셋을 시각화하고 실제 데이터와 비교할 수 있다. 실제 데이터를 시각화해보자. Figure 11.12: Time series of U.S. annual unemployment rates from 1947 to 2016. We fit a first-order autoregression to these data and then simulate several datasets, shown in Figure 11.14, from the fitted model. 20개의 시뮬레이션 결과는 서로 다른 패턴들을 보여준다. 자기회귀모델은 시계열을 서로 다른 측면들을 명확하게 보여줄 수 있다. Figure 11.13: Graphing a random sample of the simulated replications of the unemployment series from the fitted autoregressive model. The replications capture many of the features of the actual data in Figure 11.13 but show slightly more short-term variation. 위의 시계열 시뮬레이션 시각화 결과를 보면 재현된 데이터들은 원 데이터에서 보여주지 않는 패턴을 보여준다. 바로 실제 시계열 자료에서 나타나는 보다 부드러운 패턴보다 위아래로 단기의 등폭이 더 심하다는 것이다. 이러한 차이를 수량화해주기 위해서, 실업률의 감소에 뒤이어 바로 증가가 있었던 해의 빈도를 세는 검정통계량을 정의해보고 추정할 수 있다. test &lt;- function(y){ n &lt;- length(y) y_lag &lt;- c(NA, y[1:(n-1)]) y_lag_2 &lt;- c(NA, NA, y[1:(n-2)]) sum(sign(y-y_lag) != sign(y_lag-y_lag_2), na.rm=TRUE) } test_y &lt;- test(unemp$y) test_rep &lt;- apply(y_rep, 1, test) table(test_rep) ## test_rep ## 0 1 ## 141295 138705 실제로 관측된 시계열 자료에서는 26번의 변동이 포착된다. 앞서 수행한 n_sims = 4000인 시뮬레이션에서 99%의 데이터가 26번 이상의 변동을 가지고 있고, 80% 정도에 해당하는 시뮬레이션 데이터들이 [31, 41] 사이에 변동을 보인다. 즉, 모델이 데이터의 특성을 잘 포착하지 못하고 있다는 것을 의미한다. 이 검정은 자기회귀를 기각하지 못하지만, 데이터의 특정한 측면을 보여준다는 데 의의가 있다. 단순히 회귀모델을 적합하는 것에서는 확인할 수 없는 데이터의 경향성에 대한 정보를 제공하는 것이다. 실제 시계열 자료의 변동은 모델에서 기대되는 것보다 훨씬 덜 빈번한 양상을 보였다. 이러한 시각화 노력을 통해 우리는 관측자료와 재현자료(시뮬레이션) 간 체계적 차이를 더 쉽게 포착할 수 있다. 11.6 Residual standard deviation \\(\\sigma\\) and explained variance \\(R^2\\) 잔차의 표준편차, \\(\\sigma\\)는 잔차, \\(r_i = y_i - X_i\\hat \\beta\\)를 요약해서 보여준다. 표준편차의 크기는 결과변수의 총 변동량에 비교했을 때 좀 더 중요한 의미를 가진다. 모델의 적합도는 \\(\\sigma\\)를 요약하는 것으로 보여줄 수 있다. 잔차의 표준편차가 작을수록 더 좋은 모델 적합도를 보인다. 그리고 \\(R^2\\)는 결과변수의 총 변동량에 비해 모델에 의해서 설명되는 분산을 보여준다. 설명되지 않은 분산은 \\(\\sigma^2\\)로 나타내고, 만약 데이터의 표준편차를 \\(s_y\\)라고 한다면 \\(R^2\\)다음과 같이 나타낼 수 있다. \\[ R^2 = 1 - (\\hat \\sigma^2/s^2_y) \\] 모델이 최소자승법을 통해 적합되었다면 아래와 같이 설명된 분산을 직접적으로 표현할 수 있다. \\[ R^2 = V^n_{i=1}\\hat y_i/s^2_y \\] 이때, \\(\\hat y_i = X_i\\hat \\beta\\)이며 \\(V\\)는 표본 분산을 나타낸다. \\[ V^n_{i=1}z_i = \\frac{1}{n-1}\\sum^{n}_{i=1}(z_i-\\bar z)^2, \\text{for any vector } z\\text{ of length }n. \\] \\(R^2\\)를 이해하기 위해서, 하나의 예측변수를 가진 단순회귀모델을 생각해보자: \\(\\hat y = \\hat a + \\hat b x\\). 회귀선이 거의 수평선인 \\(\\bar y\\)와 거의 같다고 해보자. 그렇다면 모든 \\(i\\)에 대해서 \\(\\hat a + \\hat b x_i \\approx \\bar y\\)가 된다. 이 경우에 개별 잔차는 \\(y_i - (\\hat a + \\hat b x_i)\\)로 계산할 수 있고, 이 결과는 거의 \\(y_i - \\bar y\\)와 같게 된다. 따라서 \\(\\sigma \\approx s_y\\)가 된다. 그러므로 \\(R^2 \\approx 0\\)이라고 할 수 있고, 이는 회귀선이 실제로 \\(y\\)의 변동을 설명하는 것이 거의 없다는 의미이다. 이 경우, 추정된 절편 \\(\\hat a\\)는 대략적으로 \\(\\bar y\\)이며, 추정된 기울기 \\(\\hat b\\)는 거의 0에 가깝게 된다. 이번에는 또 다른 시나리오, 회귀선이 거의 완벽하게 모든 관측치를 지나는 경우를 생각해보자. 따라서 이 경우에 잔차는 거의 0이 된다. 그렇다면 \\(\\sigma\\)는 0에 가까워지고 \\(s_y\\)는 훨씬 더 작아지며, \\(R^2 \\approx 1\\)이 된다. 즉, 회귀선은 실질적으로 \\(y\\)의 모든 변동성을 설명한다는 것이며, 일반적으로 \\(R^2\\)가 거의 1에 가까워질수록 모델 적합도가 더 나아진다고 할 수 있다. \\(R^2\\)에 대해서 알아야할 것들이 몇 가지 있다. \\(R^2\\)는 회귀모델의 \\(x\\)나 \\(y\\)를 어떠한 상수와 곱한다고 해서 변화하지는 않는다. 따라서 예측변수의 단위를 변화시키고 싶거나 혹은 해석에 변화를 주더라도 데이터에 대한 모델 적합의 요약 결과를 변화시키기는 못한다. 하나의 예측변수를 가진 최소자승 회귀모델에서 \\(R^2\\)는 \\(x\\)와 \\(y\\) 간의 상관관계의 제곱 값과 동일하다. \\(n-k\\), 데이터 관측치의 개수에서 추정된 계수값을 뺀 것을 잔차 추정에 대한 자유도(degree of freedom)라고 한다. 빈도주의적 접근법에서 추정하는 회귀모델에서는 \\(k\\)는 반드시 \\(n\\)보다 작아야 한다. 그렇지 않으면 데이터는 완벽하게 적합되고 회귀모델의 오차를 전혀 추정할 수 없게 된다. 11.6.1 Difficulties in interpreting residual standard deviation and explained variance 회귀모델에서 우리가 주로 관심을 가지고 있는 것은 변동성을 보여주는 \\(\\epsilon\\)보다 모델의 결정주의적인 요인들-\\(X\\beta\\)이다. 그러나 잔차의 표준편차도 살펴볼 필요가 있다. 동일한 \\(\\hat a _ \\hat b x\\)를 가지고 있더라도 다른 \\(\\sigma\\) 값에 따라서 전달하는 함의가 크게 다를 수 있기 때문이다. 예를 들어, 회귀선은 동일하더라도 \\(\\hat \\sigma = 0.17\\)인 데이터와 \\(\\hat \\sigma = 0.32\\)인 데이터를 놓고 보면 \\(\\hat \\sigma = 0.32\\)인 데이터가 훨씬 관측치들이 넓게 분포하고 있는 것을 확인할 수 있다(Gelman, Hill, and Vehtari 2020: 169). 마찬가지로 회귀선이 동일하더라도 \\(R^2=0.3\\)인 경우와 \\(R^2=0.1\\)인 경우도 전자가 데이터가 회귀선에 더 접하는 면이 많게 분포되어 모델이 \\(y\\)의 변동량을 더 많이 설명하는 차이가 있다는 것을 알 수 있다(Gelman, Hill, and Vehtari 2020: 169). 11.6.2 Bayesian \\(R^2\\) \\(R^2\\)는 적합된 모델의 점추정량에 따라 정의된다. 하지만 베이지언 추론에서는 항상 불확실성에 대해 고민하기 때문에, \\(R^2\\)에 대한 접근 방식이 좀 다르다. 먼저 베이지언 \\(R^2\\)란 단순하게 베이지언 예측, \\(X\\hat\\beta\\)를 만들기 위해 \\(\\beta\\)에 대한 사후평균추정량을 사용해서 잔차의 표준편차를 컴퓨팅하고 그것을 \\(R^2 = 1-(\\hat \\sigma^2/s^2_y)\\)에 대입하거나 평균 예측값의 표준편차를 컴퓨팅해 \\(R^2 = V^n_{i=1}\\hat y_i/s^2_y\\)에 대입하여 베이지언 \\(R^2\\)을 구할 수 있다. 이 방식에는 두 가지 문제점이 있다: 베이지언 컴퓨테이션에서 점추정량을 사용하기 위한 불확실성을 놓쳐버리고 만다. 두 공식 중 두 번째 공식은 때로 \\(R^2\\)가 1보다 큰 결과를 산출할 수 있다. 적합된 모델이 종속변수의 100% 이상을 설명한다는 것은 상식적으로 말이 되지 않는다. 첫 번째 공식의 경우 추정된 잔차의 분산이 실제 데이터 분산보다 커서 추정된 \\(R^2\\)가 0보다 작아질 수 있다는 문제점이 존재한다. Figure 11.14: Simple example showing the challenge of defining \\(R^2\\) for a fitted Bayesian model. (a) Data, least squares regression line, and fitted Bayes line, which is a compromise between the prior and the least squares fit. The standard deviation of the fitted values from the Bayes model (the open circles on the line) is greater than the standard deviation of the data, so the usual definition of \\(R^2\\) will not work. (b) Posterior mean fitted regression line along with 20 draws of the line from the posterior distribution. We compute Bayesian \\(R^2\\) by evaluating formula (11.5) for each posterior simulation draw and then taking the median. 이 예제는 단순한 \\(R^2\\)가 부적절할 수도 있다는 것을 보여준다. \\(y = \\beta_0 + \\beta_1 x + \\text{error}\\)라는 모델이 있고, \\(\\beta\\)에 대한 강한 사전정보가 존재하지만 그에 비해 관측치의 개수는 적다고 하자. 먼저 최소자승회귀모델로 그린 회귀선은 \\(R^2=0.77\\)의 모델 적합도를 갖는다고 하자. 베이지안 모델적합은 강한 사전정보로 \\(\\beta_0\\sim N(0, 0.2)\\)이며, \\(\\beta_1\\sim N(1, 0.2)\\)라고 하자. 베이지안 모델로부터 적합된 값의 표준편차는 1.3이며 데이터의 표준편차는 1.08이다. 따라서 이 경우에 \\(R^2 &gt; 1\\)이 된다. \\(R^2\\)를 데이터의 예측분포를 바탕으로 나타내면 다음과 같다: \\[ \\text{alternative }R^2 = \\frac{\\text{Explained variance}}{\\text{Explained variance + Residual variance}} = \\frac{\\text{var}_\\text{fit}}{\\text{var}_\\text{fit}+\\text{var}_\\text{res}} \\] 첫 번째 통계량은 새로운 데이터로부터 얻은 기대값의 분산이고 두 번째 항은 새로운 잔차로부터 얻은 기대분산이다. 베이지언 추론에서 우리는 일련의 사후 시뮬레이션으로 추출한 결과들을 가지고 작업한다. 각각의 시뮬레이션 추출된 표본 \\(s\\)에 대해서 예측값 \\(\\hat y_i^s = X_i\\beta^s\\)와 잔차의 분산 \\(\\sigma^2_s\\)의 벡터, 그리고 설명변동량의 비율을 컴퓨팅할 수 있다. \\[ \\text{Bayesian } R^2_s = \\frac{V^n_{i=1}\\hat y_i^s}{V^n_{i=1}\\hat y_i^s + \\sigma^2_s}. \\] 이렇게 구한 결과는 항상 0과 1 사이에 위차하게 된다. 베이지언 버전에서는 \\(\\beta\\)에 대한 점추정량보다는 \\(\\beta\\)의 시뮬레이션된 값을 바탕으로 하는 예측값을 보여주게 된다. 11.7 External validation: checking fitted model on new data 모델을 검증하는 가장 기본적인 방법은 예측값과 실제 데이터를 비교하는 것이다. 예측값의 경향이 실제 관측된 데이터의 경향성을 따라가는지 잔차와 예측값의 관계가 서로 독립적인지 잔차의 크기가 어느 정도인지(클수록 모델이 놓치는 부분이 많다는 것) 자세한 예제는 Gelman, Hill, and Vehtari (2020, 172) 를 참고. 11.8 Cross validation 모델을 통해 얻은 예측값과 실제 데이터를 비교함으로써 적합도를 평가할 수도 있지만, 이 경우에는 예측값이 모델의 일반화 정도를 과대평가할 수 있다. 교차 타당화에서는 데이터의 일부를 사용해서 모델을 적합하고 그 일부를 제외한 나머지 데이터를 사용해서 미래의 데이터에 대한 일종의 대리(proxy; hold-out-sest이라고 한다)를 만들어서 추정해 비교한다. 모델링 작업에 따라서 데이터를 나누는 방법은 다양할 수 있다. 개별 관측치를 빼가면서 수행하는 교차 타당화(leave-one-out cross validation) 일단의 관측치를 제외해가는 교차 타당화(leave-one-group-out cross validation) 과거의 데이터로 미래의 관측치를 예측하는 교차 타당화(leave-future-out corss validation) 교차타당화는 추정과 평가에 있어서 동일한 데이터를 사용함에 따라 제기될 수 있는 과적합 문제를 해결하지만 얼마나 많은 수로 데이터를 나누어 적합시키느냐에 따른 비용이 소요될 수 있다. 11.8.1 Leave-one-out cross validation LOO는 개별 관측치를 제외할 때마다 \\(n\\)번 모델을 적합해야 한다. R의 loo 패키지를 이용할 수 있다. n &lt;- 20; x &lt;- 1:n; a &lt;- 0.2; b &lt;- 0.3 sigma &lt;- 1 set.seed(1224) y &lt;- a + b*x + sigma*rnorm(n) fake &lt;- data.frame(x, y) 이 페이크데이터로부터 회귀모델을 하나 추정하고, 18번째 관측치를 빼고 다시 추정해보자. fit_all &lt;- stan_glm(y ~ x, data = fake, refresh = 0) fit_minus_18 &lt;- stan_glm(y ~ x, data = fake[-18,], refresh = 0) 이제 18번째 데이터 관측치에 대한 예측을 평가해보자. 사후 예측분포는 모든 가능한 모수값들에 걸쳐 평균을 내는 것으로 얻을 수 있다. 사후 시뮬레이션 표본추출을 이용해서,관측된 데이터 \\(y\\)와 \\(X\\)에 조건적인 예측변수 \\(x^{new}\\)를 가진 \\(y^{new}\\)의 새로운 데이터 관측치에 대한 사후 예측분포는 확률적 개념으로 다음과 같이 개략적으로 추정될 수 있다: \\[ \\Pr(y^{\\text{new}}|x^{\\text{new}}) \\approx \\frac{1}{S}\\sum^S_{s=1}\\Pr(y^{\\text{new}}|x^{\\text{new}}, \\beta^s, \\sigma^s). \\] Figure 11.15: (a) Simulated data, along with the posterior mean and predictive distribution for the 18th data point from fitted linear regressions. The solid curve shows the posterior predictive distribution for \\(y_18\\) given the line fit to all the data, and the dashed line shows the posterior predictive distribution given the line fit to all the data except the 18th observation. (b) Residuals from the fitted models. Solid circles show residuals from the model fit to all the data; open circles show leave-one-out residuals, where each observation is compared to its expected value from the model holding that data point out of the fit. LOO 교차 타당화에서는 모든 관측치를 한 번씩 제외하는 과정을 반복해야한다. 11.8.2 Fast leave-one-out cross validation 기존의 LOO 교차 타당화는 \\(n\\)이 클수록 시간이 오래 걸린다는 단점이 있다. {loo} 패키지는 베이지언 추론에 입각하여 이 시간을 단축시키기 위한 함수를 제공한다. 사후 분포를 사전분포와 가능도의 곱으로 계산하는 것이다. 만약 관측치들이 조건적으로 독립적이라면, 가능도는 모든 개별 관측치에 대한 산물일 것이다: 베이지언 개념에서 사후 분포 \\(\\Pr(\\theta|y)\\propto\\Pr(\\theta)\\prod^n_{i=1}\\Pr(y_i|\\theta)\\)를 유도할 수 있다. 이때, \\(\\theta\\)는 모델 내 존재하는 모든 파라미터 값이며, 예측변수 \\(X\\)에 조건적이다. 여기서 자세한 추정 절차에 대해서는 논의하지 않는다. Gelman, Hill, and Vehtari (2020, 174) 참고. 11.8.3 Summarizing prediction error using the log score and deviance 모델 예측의 정확성을 평가하는 것에도 여러 가지 방법이 있다. 그 중 하나가 가능도에 로그값을 취한 뒤, 어떤 변수가 포함되었을 경우와 포함되지 않았을 경우에 모델의 설명력이 얼마나 변화하는지를 살펴보는 것이다. 보다 일반적으로 로그값은 비정규적인 오차 분포를 살펴볼 때 유용하며, 특정한 점추정량이 아니라 예측분포 전체의 정확성에 관심을 가지고 있을 때 그 사용이 적절하다. Figure 11.16: Log posterior predictive densities and log LOO predictive densities from a regression model fitted to the data shown in Figure 11.20a. The solid circles represent log predictive densities relative to the model fit to all the data, and the open circles correspond to leave-one-out fits. The open circles are always lower than the solid circles, because removing an observation from the likelihood causes the model to fit less well to that data point. 11.8.4 Overfitting and AIC 교차 타당화는 과적합의 문제를 피하고자 수행하는 것이라고 했을 때, 이 과적합의 문제를 교정하는 또 다른 방법은 바로 모델에 적합된 파라미터의 수를 설명하는 로그 스코어를 조정하는 것이라고 할 수 있다. 간단히 말하면, MLE를 사용한 모델에서는 Akaike information criterion; AIC라고 하는, AIC=\\(\\text{deviance}+2k\\)로 정의되는 값을 통해서 적합된 모델이 새로운 데이터를 예측할 경우에 얼마만큼의 편차를 추정할지 살펴볼 수 있다. 편차는 로그 스코어에 -2를 곱한 값이기 때문에 AIC는 과적합을 설명하기 위한 로그 스코어로부터 \\(k\\)를 뺀 것과 같다. 더 간단히 말하면, 그냥 패널티를 주는 방법이다. 변수가 추가되어서 모델이 정말 더 많은 것을 설명하면 좋겠지만, 추가되서 설명하는 것보다 단지 추가되서 모델이 복잡해질 뿐이라면 안 넣느니만 못하다. 따라서 모델 내 파라미터의 수를 일종의 패널티로 모델의 설명력을 비교분석할 수 있는 지표가 AIC인 것이다. 11.8.5 Interpreting differences in log scores 로그 스코어를 직접적으로 해석하는 경우는 거의 없다. 우리는 대개 둘 이상의 모델의 로그 스코어 값을 구해 그 차이를 살펴본다. 이 경우, 기준이 되는 비교 모델은 대개 아무런 선형 예측변수가 포함되지 않은, 절편값만 있는 모델이 된다. 절편만으로 종속변수를 설명했을 때와 비교하여 예측변수들이 추가될 때마다 얼마나 모델의 설명력이 개선되는지, 추가되는 것에 비해 개선이 형편없는지 등을 살펴보게 되는 것이다. 11.8.6 Demonstration of adding pure noise predictors to a model 예측변수를 모델에 더할 때, 설사 그 예측변수가 순수한 잡음(pure noise)일지라도, 데이터에 대한 적합과 표본 내 예측된 측정지표는 일반적으로 개선된다. 즉, 변수를 추가하면 설명력은 자동으로 올라간다. 예측변수에 잡음이 추가되더라도 모델의 적합도는 개선되는 것을 확인할 수 있다(Gelman, Hill, and Vehtari 2020: 176). 하지만 이를 통해 개선된 적합도가 바람직하다고 할 수 없다. 오히려 표본은 설명하되 우리가 가진 표본 이외의 데이터, 모집단을 보여줄 수 있는 또 다른 표본 등은 설명하지 못하는 과적합의 문제를 생각해볼 수 있다. 11.8.7 \\(K\\)-fold cross validation LOO 교차 타당화는 이론적으로 \\(n\\)번 반복해서 모델을 재적합할 것을 요구한다. 문제는 \\(n\\)의 크기가 클수록 그 시간이 오래 걸리며, 불안정해질 수 있다는 것에 있다. 만약 LOO 교차타당화가 불안정하다면, \\(K-fold\\) 교차 타당화를 대안으로 생각해볼 수 있다. \\(K-fold\\) 교차 타당화는 데이터를 \\(K\\)개의 서브셋으로 무작위로 세분하고 각 서브셋에 대한 적합을 나머지 데이터에 대한 모델 적합도에 기초하여 평가하는 것이다. 따라서 \\(K-fold\\) 타당도는 오직 \\(K\\)개의 새로운 모델 적합도만 필요하다. 11.8.8 Demonstration of \\(K\\)-fold cross validation using simulated data 10-fold 교차 타당화를 페이크데이터를 통해 살펴보자. 무작위이지만 독립적이지는 않은 30개의 예측변수를 가진 \\(60\\times30\\)의 행렬을 시뮬레이팅하는 것에서 시작한다. mvrnorm 함수를 이용하여 0.8의 상관관계를 가진 다변량 정규분포로부터 시뮬레이션 표본을 추출해본다. library(&quot;MASS&quot;) k &lt;- 30 rho &lt;- 0.8 Sigma &lt;- rho*array(1, c(k,k)) + (1-rho)*diag(k) X &lt;- mvrnorm(n, rep(0,k), Sigma) 대충 (-1, 1, 2)로 자의적으로 설정한 세 개의 첫 번째 계수들, \\(\\beta_1, \\beta_2, \\beta_3\\)을 가진 모델 \\(X\\beta + \\text{error}\\)로부터 \\(y\\)를 시뮬레이션해보았다. 그리고 나머지 계수들은 0으로 일단 설정하고 독립적인 오차는 \\(\\sim N(0, 2)\\)라고 상정하였다: b &lt;- c(c(-1,1,2), rep(0, k-3)) y &lt;- X %*% b + 2*rnorm(n) fake &lt;- data.frame(X, y) 이제 약한 사전분포를 사용하여 선형 회귀모델을 적합해보자: fit_1 &lt;- stan_glm(y ~ ., prior=normal(0, 10), data=fake, refresh = 0) loo_1 &lt;- loo(fit_1) 이때 loo(fit_1)는 다음과 같은 경고 메시지를 보이게 된다: Warning: Found 19 observations with a pareto_k &gt; 0.7. With this many problematic observations we recommend calling 'kfold' with argument 'K=10' to perform 10-fold cross-validation rather than LOO. 따라서 메시지에 따라 다음과 같이 설정해준다. kfold_1 &lt;- kfold(fit_1, K=10) print(kfold_1) ## ## Based on 10-fold cross-validation ## ## Estimate SE ## elpd_kfold -75.9 1.0 ## p_kfold NA NA ## kfoldic 151.7 2.0 무작위로 세분화된 데이터는 약 10개의 비슷한 규모로 나뉘어지며, 우리는 모델을 10번 적합하되, 적합할 때마다 데이터의 9/10씩 적합하는 것과 같다. 이 결과는 교차 타당화를 수행해서 얻은 데이터의 추정된 로그 스코어 값이며, LOO에 따라 동일한 척도 위에 놓인 것이다. 다음으로는 좀 더 정보를 포함한 사전정보를 이용해서 대안 모델들로부터 얻은 적합도를 약한 사전정보로 추정했던 모델의 적합도와 비교하는 것이다. fit_2 &lt;- update(fit_1, prior=hs()) kfold_2 &lt;- kfold(fit_2, K=10) loo_compare(kfold_1, kfold_2) ## elpd_diff se_diff ## fit_2 0.0 0.0 ## fit_1 -33.2 2.7 로그 스코어에 대한 두 교차 타당화 추정량을 비교한 결과를 제시한다. 이 결과에 따르면 모델 2가 모델 1보다 더 퍼포먼스가 좋다. 설명을 잘 한다는 것을 의미한다. 11.8.9 Concerns about model selection 여러 개의 모델을 염두에 두고 있을 때, 교차 타당화를 이용해 예측 성과가 더 좋을 것을 비교 및 평가해서 모델을 선택할 수 있다. 하지만 모델을 이처럼 추정된 예측 성과를 최적화하는 모델로 선정하는 것이 좋은 결과를 가져오는 것은 아니다. 목표가 우리가 획득한 것/관측한 것과 같은 데이터에 대한 예측뿐이라고 한다면, 단지 하나를 고르기보다는 여러 모델들을 평균내는 것이 더 좋을 수도 있다. 만약 새로운 데이터셋에 대한 예측이 목적이라면 표본과 모집단 간의 차이를 설명할 수 있는 예측 오차들에 대한 가중치를 부여하는 것이 필요하다. 여러 모델들 가운데 하나를 선택하거나 평균을 내는 것보다 더 나은 것은 앞선 모델을 포괄할 수 있는 확장된 모델을 수립하는 것일 수 있다. 인과추론이라는 측면에서 모델에 중간결과가 포함되었을 때, 회귀계수를 해석하는 것이 더 어려워질 수 있다. 따라서 일반적으로 모델의 영향력을 높이는 변수라고 할지라도 사후처치 변수들을 모델에 포함하는 것을 추천하지 않는다(Gelman, Hill, and Vehtari 2020: 180). 만약 사후처치 예측변수들이 인과성을 보여주고자 하는 회귀모델에 포함된다면, 추정된 처치 효과를 떼어내기 위해 추가적인 노력이 요구된다. 이 경우이는 단순히 처치변수의 계수값만 보는 것으로는 충분하지 않기 때문이다. References "],["simulation-1.html", "Chapter 12 Simulation 12.1 Simulation of discrete probability models 12.2 Simulation of continuous and mixed discrete/continuous models 12.3 Summarizing a set of simulations using median and median absolute deviation 12.4 Bootstrapping to simulate a sampling distribution 12.5 Fake-data simulation as a way of life", " Chapter 12 Simulation 12.1 Simulation of discrete probability models 12.1.1 How many girls in 400 births? 12.1.2 Accounting for twins 12.2 Simulation of continuous and mixed discrete/continuous models 12.2.1 Simulation in R using custom-made functions 12.3 Summarizing a set of simulations using median and median absolute deviation 12.4 Bootstrapping to simulate a sampling distribution 12.4.1 Choices in defining the bootstrap distribution 12.4.1.1 Time series 12.4.1.2 Multilevel structure 12.4.1.3 Discrete data 12.4.2 Limitations of bootstrapping 12.5 Fake-data simulation as a way of life "],["simulation-2.html", "Chapter 13 Simulation 13.1 Simulation of discrete probability models 13.2 Simulation of continuous and mixed discrete/continuous models 13.3 Summarizing a set of simulations using median and median absolute deviation 13.4 Bootstrapping to simulate a sampling distribution 13.5 Fake-data simulation as a way of life", " Chapter 13 Simulation 13.1 Simulation of discrete probability models 13.1.1 How many girls in 400 births? 13.1.2 Accounting for twins 13.2 Simulation of continuous and mixed discrete/continuous models 13.2.1 Simulation in R using custom-made functions 13.3 Summarizing a set of simulations using median and median absolute deviation 13.4 Bootstrapping to simulate a sampling distribution 13.4.1 Choices in defining the bootstrap distribution 13.4.1.1 Time series 13.4.1.2 Multilevel structure 13.4.1.3 Discrete data 13.4.2 Limitations of bootstrapping 13.5 Fake-data simulation as a way of life "],["simulation-3.html", "Chapter 14 Simulation 14.1 Simulation of discrete probability models 14.2 Simulation of continuous and mixed discrete/continuous models 14.3 Summarizing a set of simulations using median and median absolute deviation 14.4 Bootstrapping to simulate a sampling distribution 14.5 Fake-data simulation as a way of life", " Chapter 14 Simulation 14.1 Simulation of discrete probability models 14.1.1 How many girls in 400 births? 14.1.2 Accounting for twins 14.2 Simulation of continuous and mixed discrete/continuous models 14.2.1 Simulation in R using custom-made functions 14.3 Summarizing a set of simulations using median and median absolute deviation 14.4 Bootstrapping to simulate a sampling distribution 14.4.1 Choices in defining the bootstrap distribution 14.4.1.1 Time series 14.4.1.2 Multilevel structure 14.4.1.3 Discrete data 14.4.2 Limitations of bootstrapping 14.5 Fake-data simulation as a way of life "],["simulation-4.html", "Chapter 15 Simulation 15.1 Simulation of discrete probability models 15.2 Simulation of continuous and mixed discrete/continuous models 15.3 Summarizing a set of simulations using median and median absolute deviation 15.4 Bootstrapping to simulate a sampling distribution 15.5 Fake-data simulation as a way of life", " Chapter 15 Simulation 15.1 Simulation of discrete probability models 15.1.1 How many girls in 400 births? 15.1.2 Accounting for twins 15.2 Simulation of continuous and mixed discrete/continuous models 15.2.1 Simulation in R using custom-made functions 15.3 Summarizing a set of simulations using median and median absolute deviation 15.4 Bootstrapping to simulate a sampling distribution 15.4.1 Choices in defining the bootstrap distribution 15.4.1.1 Time series 15.4.1.2 Multilevel structure 15.4.1.3 Discrete data 15.4.2 Limitations of bootstrapping 15.5 Fake-data simulation as a way of life "],["simulation-5.html", "Chapter 16 Simulation 16.1 Simulation of discrete probability models 16.2 Simulation of continuous and mixed discrete/continuous models 16.3 Summarizing a set of simulations using median and median absolute deviation 16.4 Bootstrapping to simulate a sampling distribution 16.5 Fake-data simulation as a way of life", " Chapter 16 Simulation 16.1 Simulation of discrete probability models 16.1.1 How many girls in 400 births? 16.1.2 Accounting for twins 16.2 Simulation of continuous and mixed discrete/continuous models 16.2.1 Simulation in R using custom-made functions 16.3 Summarizing a set of simulations using median and median absolute deviation 16.4 Bootstrapping to simulate a sampling distribution 16.4.1 Choices in defining the bootstrap distribution 16.4.1.1 Time series 16.4.1.2 Multilevel structure 16.4.1.3 Discrete data 16.4.2 Limitations of bootstrapping 16.5 Fake-data simulation as a way of life "],["simulation-6.html", "Chapter 17 Simulation 17.1 Simulation of discrete probability models 17.2 Simulation of continuous and mixed discrete/continuous models 17.3 Summarizing a set of simulations using median and median absolute deviation 17.4 Bootstrapping to simulate a sampling distribution 17.5 Fake-data simulation as a way of life", " Chapter 17 Simulation 17.1 Simulation of discrete probability models 17.1.1 How many girls in 400 births? 17.1.2 Accounting for twins 17.2 Simulation of continuous and mixed discrete/continuous models 17.2.1 Simulation in R using custom-made functions 17.3 Summarizing a set of simulations using median and median absolute deviation 17.4 Bootstrapping to simulate a sampling distribution 17.4.1 Choices in defining the bootstrap distribution 17.4.1.1 Time series 17.4.1.2 Multilevel structure 17.4.1.3 Discrete data 17.4.2 Limitations of bootstrapping 17.5 Fake-data simulation as a way of life "],["simulation-7.html", "Chapter 18 Simulation 18.1 Simulation of discrete probability models 18.2 Simulation of continuous and mixed discrete/continuous models 18.3 Summarizing a set of simulations using median and median absolute deviation 18.4 Bootstrapping to simulate a sampling distribution 18.5 Fake-data simulation as a way of life", " Chapter 18 Simulation 18.1 Simulation of discrete probability models 18.1.1 How many girls in 400 births? 18.1.2 Accounting for twins 18.2 Simulation of continuous and mixed discrete/continuous models 18.2.1 Simulation in R using custom-made functions 18.3 Summarizing a set of simulations using median and median absolute deviation 18.4 Bootstrapping to simulate a sampling distribution 18.4.1 Choices in defining the bootstrap distribution 18.4.1.1 Time series 18.4.1.2 Multilevel structure 18.4.1.3 Discrete data 18.4.2 Limitations of bootstrapping 18.5 Fake-data simulation as a way of life "],["simulation-8.html", "Chapter 19 Simulation 19.1 Simulation of discrete probability models 19.2 Simulation of continuous and mixed discrete/continuous models 19.3 Summarizing a set of simulations using median and median absolute deviation 19.4 Bootstrapping to simulate a sampling distribution 19.5 Fake-data simulation as a way of life", " Chapter 19 Simulation 19.1 Simulation of discrete probability models 19.1.1 How many girls in 400 births? 19.1.2 Accounting for twins 19.2 Simulation of continuous and mixed discrete/continuous models 19.2.1 Simulation in R using custom-made functions 19.3 Summarizing a set of simulations using median and median absolute deviation 19.4 Bootstrapping to simulate a sampling distribution 19.4.1 Choices in defining the bootstrap distribution 19.4.1.1 Time series 19.4.1.2 Multilevel structure 19.4.1.3 Discrete data 19.4.2 Limitations of bootstrapping 19.5 Fake-data simulation as a way of life "],["simulation-9.html", "Chapter 20 Simulation 20.1 Simulation of discrete probability models 20.2 Simulation of continuous and mixed discrete/continuous models 20.3 Summarizing a set of simulations using median and median absolute deviation 20.4 Bootstrapping to simulate a sampling distribution 20.5 Fake-data simulation as a way of life", " Chapter 20 Simulation 20.1 Simulation of discrete probability models 20.1.1 How many girls in 400 births? 20.1.2 Accounting for twins 20.2 Simulation of continuous and mixed discrete/continuous models 20.2.1 Simulation in R using custom-made functions 20.3 Summarizing a set of simulations using median and median absolute deviation 20.4 Bootstrapping to simulate a sampling distribution 20.4.1 Choices in defining the bootstrap distribution 20.4.1.1 Time series 20.4.1.2 Multilevel structure 20.4.1.3 Discrete data 20.4.2 Limitations of bootstrapping 20.5 Fake-data simulation as a way of life "],["simulation-10.html", "Chapter 21 Simulation 21.1 Simulation of discrete probability models 21.2 Simulation of continuous and mixed discrete/continuous models 21.3 Summarizing a set of simulations using median and median absolute deviation 21.4 Bootstrapping to simulate a sampling distribution 21.5 Fake-data simulation as a way of life", " Chapter 21 Simulation 21.1 Simulation of discrete probability models 21.1.1 How many girls in 400 births? 21.1.2 Accounting for twins 21.2 Simulation of continuous and mixed discrete/continuous models 21.2.1 Simulation in R using custom-made functions 21.3 Summarizing a set of simulations using median and median absolute deviation 21.4 Bootstrapping to simulate a sampling distribution 21.4.1 Choices in defining the bootstrap distribution 21.4.1.1 Time series 21.4.1.2 Multilevel structure 21.4.1.3 Discrete data 21.4.2 Limitations of bootstrapping 21.5 Fake-data simulation as a way of life "],["simulation-11.html", "Chapter 22 Simulation 22.1 Simulation of discrete probability models 22.2 Simulation of continuous and mixed discrete/continuous models 22.3 Summarizing a set of simulations using median and median absolute deviation 22.4 Bootstrapping to simulate a sampling distribution 22.5 Fake-data simulation as a way of life", " Chapter 22 Simulation 22.1 Simulation of discrete probability models 22.1.1 How many girls in 400 births? 22.1.2 Accounting for twins 22.2 Simulation of continuous and mixed discrete/continuous models 22.2.1 Simulation in R using custom-made functions 22.3 Summarizing a set of simulations using median and median absolute deviation 22.4 Bootstrapping to simulate a sampling distribution 22.4.1 Choices in defining the bootstrap distribution 22.4.1.1 Time series 22.4.1.2 Multilevel structure 22.4.1.3 Discrete data 22.4.2 Limitations of bootstrapping 22.5 Fake-data simulation as a way of life "],["exercises-of-regression-and-other-stories.html", "Chapter 23 Exercises of Regression and Other Stories 23.1 Overview 23.2 Causal inference 23.3 Statistics as generalization 23.4 Statistics as generalization 23.5 A problem with linear models 23.6 Some basic methods in mathematics and probability", " Chapter 23 Exercises of Regression and Other Stories 23.1 Overview Data for examples and assignments in this and other chapters are at www.stat.columbia.edu/~gelman/regression/. See Appendix A for an introduction to R, the software you will use for computing. 23.1.1 From design to decision Figure 1.9 displays the prototype for a paper “helicopter.” The goal of this assignment is to design a helicopter that takes as long as possible to reach the floor when dropped from a fixed height, for example 8 feet. The helicopters are restricted to have the general form shown in the sketch. No additional folds, creases, or perforations are allowed. The wing length and the wing width of the helicopter are the only two design parameters, that is, the only two aspects of the helicopter that can be changed. The body width and length must remain the same for all helicopters. A metal paper clip is attached to the bottom of the helicopter. Here are some comments from previous students who were given this assignment: Rich creased the wings too much and the helicopters dropped like a rock, turned upside down, turned sideways, etc. Helis seem to react very positively to added length. Too much width seems to make the helis unstable. They flip-flop during flight. Andy proposes to use an index card to make a template for folding the base into thirds. After practicing, we decided to switch jobs. It worked better with Yee timing and John dropping. 3 – 2 – 1 – GO. Your instructor will hand out 25 half-sheets of paper and 2 paper clips to each group of students. The body width will be one-third of the width of the sheets, so the wing width can be anywhere from \\(\\frac{1}{6}\\) to \\(\\frac{1}{2}\\) of the body width; see Figure 1.9a. The body length will be specified by the instructor. For example, if the sheets are U.S.-sized (\\(8.5\\times5.5\\) inches) and the body length is set to 3 inches, then the wing width could be anywhere from 0.91 to 2.75 inches and the wing length could be anywhere from 0 to 5.5 inches. In this assignment you can experiment using your 25 half-sheets and 10 paper clips. You can make each half-sheet into only one helicopter. But you are allowed to design sequentially, setting the wing width and body length for each helicopter given the data you have already recorded. Take a few measurements using each helicopter, each time dropping it from the required height and timing how long it takes to land. Figure 23.1: (a) Diagram for making a “helicopter” from half a sheet of paper and a paper clip. The long segments on the left and right are folded toward the middle, and the resulting long 3-ply strip is held together by a paper clip. One of the two segments at the top is folded forward and the other backward. The helicopter spins in the air when dropped. (b) Data file showing flight times, in seconds, for 5 flights each of two identical helicopters with wing width 1.8 inches and wing length 3.2 inches dropped from a height of approximately 8 feet. From Gelman and Nolan (2017). library(tidyverse) file_helicopters &lt;- here::here(&quot;data/ros-master/Helicopters/data/helicopters.txt&quot;) helicopters &lt;- file_helicopters %&gt;% read.table(header = TRUE) %&gt;% as_tibble(.name_repair = str_to_lower) 23.1.1.1 (a) Record the wing width and body length for each of your 25 helicopters along with your time measurements, all in a file in which each observation is in its own row, following the pattern of helicopters.txt in the folder Helicopters, also shown in Figure 1.9b. # The wing length and the wing width of the helicopter are the only two design variables, that is, the only two measurements on the helicopter that can be changed. The body width and length must remain the same for all helicopters. # wing width 4.6 centimeters and wing length 8.2 centimeters helicopters %&gt;% arrange(time_sec) %&gt;% mutate( wing_width = c(seq(0.91, 2.75, 0.1), 2.75), wing_length = sample(0:5.5, 20, replace=TRUE), body_length = 3) %&gt;% select(helicopter_id, time_sec, wing_width, body_length, everything())-&gt; helicopters ## Error in select(., helicopter_id, time_sec, wing_width, body_length, everything()): unused arguments (helicopter_id, time_sec, wing_width, body_length, everything()) 23.1.1.2 (b) Graph your data in a way that seems reasonable to you. helicopters %&gt;% mutate( helicopter_id = as.factor(helicopter_id)) %&gt;% ggplot(aes(y = time_sec, x = wing_width, group = helicopter_id, color = helicopter_id, fill = helicopter_id)) + geom_point() + theme_bw() + theme(legend.position = &quot;bottom&quot;) ## Error in FUN(X[[i]], ...): object &#39;wing_width&#39; not found 23.1.1.3 (c) Given your results, propose a design (wing width and length) that you think will maximize the helicopter’s expected time aloft. It is not necessary for you to fit a formal regression model here, but you should think about the general concerns of regression. The above description is adapted from Gelman and Nolan (2017, section 20.4). See Box, Hunter, and Hunter (2005) for a more advanced statistical treatment of this sort of problem. ## ## Call: ## lm(formula = time_sec ~ width_cm + length_cm + helicopter_id, ## data = helicopters) ## ## Residuals: ## Min 1Q Median 3Q Max ## -0.0560 -0.0285 -0.0005 0.0175 0.0750 ## ## Coefficients: (2 not defined because of singularities) ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 1.68400 0.02713 62.080 &lt;2e-16 *** ## width_cm NA NA NA NA ## length_cm NA NA NA NA ## helicopter_id -0.01900 0.01716 -1.107 0.283 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 0.03836 on 18 degrees of freedom ## Multiple R-squared: 0.06379, Adjusted R-squared: 0.01178 ## F-statistic: 1.227 on 1 and 18 DF, p-value: 0.2827 23.1.2 Sketching a regression model and data Figure 1.1b shows data corresponding to the fitted line y = 46.3 + 3.0x with residual standard deviation 3.9, and values of x ranging roughly from 0 to 4%. 23.1.2.1 (a) Sketch hypothetical data with the same range of x but corresponding to the line \\(y = 30 + 10x\\) with residual standard deviation 3.9. ## ## Call: ## lm(formula = vote_est1 ~ growth_est1, data = q1.2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -24.272 -11.060 -2.109 11.624 27.395 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.5825 3.6594 13.003 3.32e-09 *** ## growth_est1 0.9718 0.7282 1.335 0.203 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 14.58 on 14 degrees of freedom ## Multiple R-squared: 0.1129, Adjusted R-squared: 0.04949 ## F-statistic: 1.781 on 1 and 14 DF, p-value: 0.2033 ## Error in select(., growth_est1, growth_est2, vote_est1, vote_est2): unused arguments (growth_est1, growth_est2, vote_est1, vote_est2) 23.1.2.2 (b) Sketch hypothetical data with the same range of x but corresponding to the line \\(y = 30 + 10x\\) with residual standard deviation 10. ## ## Call: ## lm(formula = vote_est2 ~ growth_est2, data = q1.2) ## ## Residuals: ## Min 1Q Median 3Q Max ## -28.1890 -13.2468 0.9711 12.0352 28.4193 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 47.1213 4.7173 9.989 9.47e-08 *** ## growth_est2 -0.1587 0.4334 -0.366 0.72 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 18.81 on 14 degrees of freedom ## Multiple R-squared: 0.009486, Adjusted R-squared: -0.06126 ## F-statistic: 0.1341 on 1 and 14 DF, p-value: 0.7197 ## Error in select(., growth_est1, growth_est2, vote_est1, vote_est2): unused arguments (growth_est1, growth_est2, vote_est1, vote_est2) 23.1.3 Goals of regression Download some data on a topic of interest to you. Without graphing the data or performing any statistical analysis, discuss how you might use these data to do the following things: 23.1.3.1 (a) Fit a regression to estimate a relationship of interest. With V-Dem dataset, I will fit the model, \\(\\text{EDI} \\sim \\beta X\\), which \\(X\\) includes various covariates that can affect the levels of democracy, which existing studies have found. 23.1.3.2 (b) Use regression to adjust for differences between treatment and control groups. 23.1.3.3 (c) Use a regression to make predictions. 23.1.4 Problems of statistics Give examples of applied statistics problems of interest to you in which there are challenges in: 23.1.4.1 (a) Generalizing from sample to population. 23.1.4.2 (b) Generalizing from treatment to control group. 23.1.4.3 (c) Generalizing from observed measurements to the underlying constructs of interest. 23.1.5 Goals of regression Give examples of applied statistics problems of interest to you in which the goals are: 23.1.5.1 (a) Forecasting/classification. 23.1.5.2 (b) Exploring associations. 23.1.5.3 (c) Extrapolation. 23.1.5.4 (d) Causal inference. 23.2 Causal inference Find a real-world example of interest with a treatment group, control group, a pre-treatment predictor, and a post-treatment predictor. Make a graph like Figure 1.8 using the data from this example. 23.3 Statistics as generalization Find a published paper on a topic of interest where you feel there has been insufficient attention to: 23.3.0.1 (a) Generalizing from sample to population. 23.3.0.2 (b) Generalizing from treatment to control group. 23.3.0.3 (c) Generalizing from observed measurements to the underlying constructs of interest. 23.4 Statistics as generalization Find a published paper on a topic of interest where you feel the following issues have been addressed well: 23.4.0.1 (a) Generalizing from sample to population. 23.4.0.2 (b) Generalizing from treatment to control group. 23.4.0.3 (c) Generalizing from observed measurements to the underlying constructs of interest. 23.5 A problem with linear models Consider the helicopter design experiment in Exercise 1.1. Suppose you were to construct 25 helicopters, measure their falling times, fit a linear model predicting that outcome given wing width and body length: \\[ \\text{time} = \\beta_0 + \\beta_1 ∗ \\text{width} + \\beta_2 ∗ \\text{length}+ \\text{error}, \\] and then use the fitted model \\(\\text{time} = \\beta_0 + \\beta_1 ∗ \\text{width} + \\beta_2 ∗ \\text{length}\\) to estimate the values of wing width and body length that will maximize expected time aloft. 23.5.0.1 (a) Why will this approach fail? 23.5.0.2 (b) Suggest a better model to fit that would not have this problem. 23.5.1 Working through your own example Download or collect some data on a topic of interest of to you. You can use this example to work though the concepts and methods covered in the book, so the example should be worth your time and should have some complexity. This assignment continues throughout the book as the final exercise of each chapter. For this first exercise, discuss your applied goals in studying this example and how the data can address these goals. 23.6 Some basic methods in mathematics and probability 23.6.1 Weighted averages A survey is conducted in a certain city regarding support for increased property taxes to fund schools. In this survey, higher taxes are supported by 50% of respondents aged 18–29, 60% of respondents aged 30–44, 40% of respondents aged 45–64, and 30% of respondents aged 65 and up. Assume there is no nonresponse.Suppose the sample includes 200 respondents aged 18–29, 250 aged 30–44, 300 aged 45–64, and 250 aged 65+. Use the weighted average formula to compute the proportion of respondents in the sample who support higher taxes. ## # A tibble: 4 x 6 ## age support n total weight supportweighted ## &lt;chr&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 18-29 0.5 200 1000 0.2 0.1 ## 2 30-44 0.6 250 1000 0.25 0.15 ## 3 45-64 0.4 300 1000 0.3 0.12 ## 4 65 and up 0.3 250 1000 0.25 0.075 ## # A tibble: 1 x 1 ## sum ## &lt;dbl&gt; ## 1 0.445 23.6.2 Weighted averages Continuing the previous exercise, suppose you would like to estimate the proportion of all adults in the population who support higher taxes, so you take a weighted average as in Section 3.1. Give a set of weights for the four age categories so that the estimated proportion who support higher taxes for all adults in the city is 40%. ## # A tibble: 1 x 1 ## sum ## &lt;dbl&gt; ## 1 0.405 23.6.3 Probability distributions Using R, graph probability densities for the normal distribution, plotting several different curves corresponding to different choices of mean and standard deviation parameters. 23.6.4 Probability distributions Using a bar plot in R, graph the Poisson distribution with parameter 3.5. 23.6.5 Probability distributions Using a bar plot in R, graph the binomial distribution with n = 20 and p = 0.3. 23.6.6 Linear transformations A test is graded from 0 to 50, with an average score of 35 and a standard deviation of 10. For comparison to other tests, it would be convenient to rescale to a mean of 100 and standard deviation of 15. 23.6.6.1 (a) Labeling the original test scores as x and the desired rescaled test score as \\(y\\), come up with a linear transformation, that is, values of a and b so that the rescaled scores \\(y = a + bx\\) have a mean of 100 and a standard deviation of 15. 23.6.6.2 (b) What is the range of possible values of this rescaled score \\(y\\)? 23.6.6.3 (c) Plot the line showing y vs. x. 23.6.7 Linear transformations Continuing the previous exercise, there is another linear transformation that also rescales the scores to have mean 100 and standard deviation 15. What is it, and why would you not want to use it for this purpose? 23.6.8 Correlated random variables Suppose that the heights of husbands and wives have a correlation of 0.3, husbands’ heights have a distribution with mean 69.1 and standard deviation 2.9 inches, and wives’ heights have mean 63.7 and standard deviation 2.7 inches. Let x and y be the heights of a married couple chosen at random. What are the mean and standard deviation of the average height, (x + y)/2? 23.6.9 Comparison of distributions Find an example in the scientific literature of the effect of treatment on some continuous outcome, and make a graph similar to Figure 3.9 showing the estimated population shift in the potential outcomes under a constant treatment effect. 23.6.10 Working through your own example Continuing the example from Exercises 1.10 and 2.10, consider a deterministic model on the linear or logarithmic scale that would arise in this topic. Graph the model and discuss its relevance to your problem. "],["references.html", "References", " References "]]
