[["index.html", "Reading Notes for Regression and Other Stories by Andrew Gelman, Jeniffer Hill and Aki Vehtari Chapter 1 Overview 1.1 The three challenges of statistics 1.2 Why learn regression? 1.3 Some examples of regression 1.4 Challenges in building, understanding, and interpreting regressions 1.5 Classical and Bayesian inference 1.6 Computing least squares and Bayesian regression", " Reading Notes for Regression and Other Stories by Andrew Gelman, Jeniffer Hill and Aki Vehtari Sanghoon Park 2021-05-15 Chapter 1 Overview 이 책(이하 Gelman, Hill, and Vehtari (2020))은 예측모형을 만들고, 이해하고, 사용하는 데 있어서 마주할 수 있는 문제들을 다루고 있다. 우선 데이터, 측정, 그리고 통계치(statistics)에 관한 기본적인 개념들을 앞의 다섯개 챕터에서 검토하고, 하나의 예측변수와 여러개의 예측변수를 가지는 선형 회귀모델을 다룬다. 뒷 부분에서는 로지스틱 회귀모델을 포함한 일반화 선형모델들을 살펴보게 될 것이다. 저자들이 말하는 것처럼 이 책의 장점 중 하나는 단순히 기법적인 것들을 설명하는 것이 아닌, 이러한 모델들을 이용해서 어떻게 가지고 있는 데이터로부터 인과추론에 이르기까지 일반화를 할 수 있는지에 대한 회귀모델 “적용”의 문제를 다루고 있다는 것이다. GHV를 읽고 정리한 이 리딩노트는 모든 내용을 요약하지 않고 필수적이라고 생각되는 예제들을 선택적으로 포함하여 본문의 Figure 나 Table과 캡션이나 레이블이 일치하지 않을 수 있다. 이를 참고하기 바란다. 1.1 The three challenges of statistics 통계적 추론(statistical inference)에 있어서 마주할 수 있는 세 가지 문제는 다음과 같다: 표본을 가지고 모집단 수준으로 일반화를 해야하는 문제. 이 문제는 설문 표집(survey sampling)과 관련되어 있지만, 사실 모든 통계 추론을 적용할 때 제기될 수 있는 문제이다. 왜냐하면 우리가 가진 데이터는 그것이 설문 데이터이건 아니건 간에 모두 하나의 표본(sample)이기 때문이다. 처치집단의 결과를 가지고 통제집단까지 일반화를 해야하는 문제. 거의 대부분의 회귀모델을 해석하는데 있어서 야기되는 인과추론과 관련된 문제이다. 결국 회귀모델도, 통계모델도 일종의 준실험적(quasi-experimental)이라고 불리는 만큼, 어떻게 관계에 영향을 미치는 잡음(noise)과 체계적 요인(systematic factors)을 구분해 우리가 관심을 가지고 있는 관계를 드러낼 것인가에 대한 “통제”의 문제와 밀접하게 관련을 가진다. 관측된 측정지표를 가지고 우리가 관심을 가지고 있는, 그 측정지표 너머의(기저의) 구성개념으로 일반화를 해야하는 문제. 대부분의 경우, 우리가 가지고 있는 데이터가 완벽하게 혹은 정확하게 우리가 이상적으로 연구하고자 하는 대상을 기록하고 있다고 보기는 어렵다. 예를 들어, 민주주의를 측정한다고 할 때, 우리가 개념적으로 기대하는 민주주의를 실제 측정지표로 완벽하게 포착하기는 어렵다. 따라서 우리는 일종의 조작화(operationalization)라는 과정을 거치게 되는데, 이때 우리의 개념화(conceptualization)와 조작화(operationalization) 간에는 필연적으로 간극이 생길 수 밖에 없게 된다. 이 간극을 어떻게 좁힐 것인가에 대한 문제라고도 이해할 수 있다. 위의 세 문제들은 “예측의 문제”(problems of prediction)라는 한 울타리 안에 담을 수 있다. 예를 들어, 새로운 사람들을 대상으로 했을 때, 변화한 표본이 이전의 표본과 마찬가지로 모집단 수준에서 일반화를 하기에 적절한지, 처치(treatment)가 달라졌을 때 이전과 이후의 결과가 어떻게 달라질지, 그리고 앞으로도 우리가 조작화한 측정지표가 우리가 기대한 개념을 정확하게 측정할지 등에 대한 문제가 산적해있는 것이다. 이런 점들을 고려하여 GHV는 이 책을 통해 다음과 같은 핵심 역량을 기르기를 주문한다. 회귀모델을 이해하는 것. 회귀모델이란 결국 일련의 예측변수들을 이용해서 결과과 어떠할 것이라고 예측하는 수리적 모델이다. 이 책은 그 예측을 일종의 선형(linear) 관계로 바라보는 것으로부터 다양한 비선형(non-linear) 관계로 일반화할 수 있는 단계로까지 이해할 수 있는 내용을 다룬다. 회귀모델을 구성하는 것. 회귀모델에 어떤 변수를 선택해서 포함시키고, 혹은 변수를 어떻게 변형시킬지 등은 연구자에게 주어진 선택지이다. 동일한 결과를 회귀모델로 분석하고자 하더라도 연구자마다 다른 변수들을 사용하여 분석할 수 있다. 데이터에 회귀모델을 적합시키는 것. R과 Stan이라는 소프트웨어를 이용하여 데이터로부터 회귀모델을 적합, 그 분석 결과를 도출할 수 있는 스킬을 배우게 된다. 회귀보델의 결과를 보여주고 해석하는 것. 단순히 통계 분석을 수행하는 것이 아니라 그 결과가 가지는 의미를 다른 사람들이 이해할 수 있는 방식으로 보여주고 해석하는 것이 중요하다. 이를 위해서 통계 분석 이상의 프로그래밍 스킬과 수학적 이해를 요구한다. 마지막으로 이 책의 핵심 주제는 바로 추론 (inference)이다. 우리가 손에 넣은 특정한 데이터로부터 수리적 모델을 이용해 (모집단에서 통용되는) 일반화된 주장을 할 수 있는 능력을 의미한다. 1.2 Why learn regression? Figure 1.1: Predicting elections from the economy: (a) the data, (b) the linear fit, y = 46.3 + 3.0x. 회귀모델은 일련의 예측변수들로 정의된 개별 개체들에 따라서 결과의 평균적인 값, 혹은 예측이 어떻게 될 것이라는 걸 보여주는 방법이다. 예를 들어, Figure 1.1a는 미국 대선에서의 집권당의 득표율과 각 선거가 있었던 해에 경제성장률의 측정지표를 그래프로 보여주고 있다. Figure 1.1b는 그 데이터에 적합하는 선형 회귀모델의 결과를 보여준다. 회귀모델은 비록 어느정도의 불확실성은 존재하지만 변화하는 경제성장률에 따라 득표율이 어떻게 될 것이라는 예측이 가능하게 해주며, 그러한 가정 하에서 미래의 선거도 과거와 비슷하다면 어떻게 전개될 것이라고 기대할 수 있게 해준다. GHV는 Stan을 이용해 베이지안 통계 패키지를 이용해 회귀모델을 분석하고 있지만, 여기서는 일반적인 패키지를 이용해 분석한다. 회귀분석에 대한 자세한 내용은 이후의 챕터들에서 다루게 될 것이다. 회귀모델이 주요하게 사용되는 것은 다음과 같다: 예측: 가지고 있는 데이터를 모델링하거나 새로운 데이터를 예측하는 것을 의미힌다. 관계의 탐색: 얼마나 변수들이 결과를 잘 예측하는지를 보여주는 것이 필요하다. 외삽(extrapolation): 여기서는 외삽이라는 개념을 사용했는데, 그보다는 일반화(generalization)라는 표현이 좀 더 이해하기 쉬울 듯 하다. 표본과 모집단의 차이를 알아야 한다는 것에서 시작한다. 현실세계의 표본은 결코 모집단을 완벽하게 대표할 수 없기 때문에, 우리는 표본을 통해서 얻은 결과를 모집단의 수준에서 일반화하는 과정에서 일종의 조정 과정을 거치게 되는데, 이를 외삽이라고 표현한 것이다. 회귀분석은 Figure 1.1b에서 보았듯 일종의 예측을 제시하지만 어디까지나 주어진 표본 하에서 그 선은 그어진 것이고, 앞으로도 계속 그 추세가 이어질지는 알지 못한다. 그럼에도 불구하고 우리는 주어진 데이터에서 모델을 이용한 예측을 일반화화된 진술로 표현하게 된다. 인과추론: 회귀모델에서 가장 중요한 부분으로, 처치효과(treatment effects)를 추정하는 것에 관련된 것이다. 즉, 우리가 기대하는 어떠한 변수가 진짜로 결과의 차이를 가져오는 데 기여하였는가, 그렇다면 얼마나 기여하였는가를 추정하는 것이다. 인과추론은 평균적으로 얼마나 처치 이전에 처치군과 통제군이 유사하였는지, 그리고 처치 이후에 두 집단의 차이가 존재하였는지를 확실히 보여주는가에 그 성패가 달려있다고 할 수 있다. 1.3 Some examples of regression 1.3.1 A randomized experiment on the effect of an educational television program Figure 1.2: Post-treatment classroom-average test scores from an experiment measuring the effect of an educational television program, The Electric Company, on children’s reading abilities. The dark vertical line in each histogram shows the average for the corresponding group of classrooms. 1970년대 새로운 TV 교육 프로그램(The Electric Company)이 어린이들의 독해력에 미치는 효과를 측정하기 위해 수행된 연구를 살펴보자. 실험대상은 미국의 두 작은 도시에 1-4학년 사이의 아이들이었다. 각 도시와 학년에 따라서 10개부터 20개 사이의 학교가 선택되었고, 각 학교는 독해력 시험 점수가 가장 낮은 해당 학년의 두개 학급씩을 선정하였다. 각 2개 학급별로 한 학급은 무작위로 정규 독해 강의를 듣게 했고, 다른 학급은 TV 프로그램을 시청하게 하였다. 즉, 성적이 최하위인 A와 B라는 같은 학년의 두 학급을 선정 후, A에서 무작위로 뽑은 학생들은 정규 독해 강의를 듣고, B에서 무작위로 뽑은 학생들은 TV 프로그램을 보게 한 것이다. 따라서 A는 강의를 들은 학생들과 듣지 않은 학생, B는 TV 프로그램을 본 학생과 보지 않은 학생으로 구분할 수 있다. 각 학생들은 학년이 시작하기 전에 사전 테스트를 쳤고, 학년 말에 사후 테스트를 쳤다. Figure 1.2는 각 학년별 통제 학급과 처치 학급의 사후 테스트 결과를 보여준다. 각 행을 비교하면 통제 학급에 비해 처치 학급이 저학년(Grade 1, Grade 2)의 경우 TV 프로그램을 시청하였을 때 더 높은 독해력을 보여주는 것을 확인할 수 있고, 그 차이는 고학년(Grade 3, Grade 4)으로 가면 줄어드는 것을 확인할 수 있다. 물론, 더 자세한 처치 효과를 추정하기 위해서는 통계적 분석이 필요하다(제19장에서 다시 살펴본다). 1.3.2 Comparing the peacekeeping and gun-control studies GHV는 UN의 평화유지군 파병이 내전이 발생했던 국가가 다시 내전에 재돌입하는 것에 미치는 효과를 본 연구와 일련의 총기 관련 정책이 가지는 효과를 두루 살펴본 연구를 비교하면서 다음과 같은 함의를 이끌어내고 있다. 보고자 하는 것이 무엇인지(연구문제)를 명확히 하고, 그에 맞는 연구설계를 할 필요가 있다. 그 경우에 보다 믿을 수 있고 설득력 있는 결과를 제시할 수 있다. 한 번에 하나의 모델에서 너무 많은 인과관계를 보여줄 필요는 없다. 변수를 많이 추가할수록 조건이 추가되는 것이다. 즉, A가 일정할 때, B가 결과에 미치는 효과는 어떠할 것이다라는 진술과 A부터 G까지의 변수들이 일정할 때, H가 변수에 미치는 효과는 어떠할 것이다라는 진술은 현실 세계에서 우리가 그 결과를 직관적으로 이해할 수 있는가에 영향을 미칠 수 있다. 마찬가지로 비교하고자 하는 대상–분석 단위에 대한 고민도 필요하다. 분석 단위들 간에 존재할 수 있는 체계적 차이를 어떻게 고려하느냐도 우리의 결과가 가지는 신빙성에 영향을 미칠 수 있기 때문이다. 1.4 Challenges in building, understanding, and interpreting regressions 인과추론을 위한 회귀모델에 있어서 두 가지를 구분할 수 있다: 관계를 추정하는 것과 비교하고자 하는 대상들의 기저에 놓인 변수들을 조정(adjusting)하는 것이다. 1.4.1 Regression to estimate a relationship of interest 어떤 처치군과 통제군을 비교한다고 가정해보자. 일단 첫 번째 생각해야할 조건은 처치군과 통제군에 들어갈 사람들이 무작위로 배정되었는지(randomly assigned)에 대한, “무작위화”(randomization)이다. 혹은 배정이 두 집단 간의 균형을 고려한 보다 복잡한 설계를 바탕으로 이루어졌을 수도 있다. 처치군과 통제군을 대략적으로(완벽하게 동일한 개체가 될 수는 없으니까) 비교가능한 집단으로 만드는 것과 이 두 집단 간에 알려진, 혹은 모델에 포함된 차이를 조정하는 방법은 다양하게 존재한다. Figure 1.3: Regression to estimate a causal effect with (a) simple comparison of treatment and control, or (b) a range of treatment levels. Figure 1.4: (a) Hypothetical data in which the causal effect is a nonlinear function of the treatment level; (b) same data with a linear effect estimated. It is always possible to estimate a linear model, even if it does not fit the data. 만약 처치, \\(x\\)가 결과, \\(y\\)에 미치는 효과에 관심이 있고 가지고 있는 데이터가 무작위화 혹은 다른 처치군과 통제군 간의 균형을 고려한 실험설계 방법을 통해 얻어졌다면 우리는 회귀모델을 데이터에 적합하여 불확실성을 포함해 \\(x\\)로부터 \\(y\\)를 예측할 수 있다.1 만약 \\(x\\)가 이항변수(통제일 경우 \\(x=0\\), 처치가 이루어졌을 경우 \\(x=1\\))라면 회귀모델 분석의 결과는 Figure 1.3a와 같이 나타날 것이고, 만약 \\(x\\)가 연속적인 값을 같는 변수라면 Figure 1.3b와 같은 결과를 확인할 수 있을 것이다. 실험방법을 통해 두 집단 간의 비교가능성이 확보된 상황이라면 주어진 처치에 대해 결과를 예측한 회귀분석 결과는 인과효과(causal effect)를 직접적으로 추정한 것이라고 할 수 있다. 하지만 데이터를 더 잘 설명하기 위해, 혹은 더 정확하게 예측하기 위해 더 정교한 모델링을 할 수도 있다. 예를 들어, 연속형 변수의 처치효과가 결과에 비선형적인 관계를 가지는 경우를 생각해볼 수 있다. Figure 1.4a가 바로 그런 경우이다. Figure 1.4a와 Figure 1.4b 모두 같은 데이터를 예측하지만 처치 효과의 관계가 선형적이냐, 비선형적이냐에 따라 다른 기대를 가지고 있는 모델이다. 혹은 모델 내 서로 다른 예측변수들 간의 함수적 관계에 따라 처치효과가 다르게 나타나는 상호작용(interactions)을 모델에 포함할 것을 고려해볼 수 있다. Figure 1.5: Lifetime added risk of lung cancer for men, as a function of average radon exposure in picocuries per liter (pCi/L). The relation between cancer rate and radon is different for smokers and nonsmokers. Figure 1.5은 라돈 가스가 남성의 폐암 발병률에 미치는 효과를 추정한 것을 보여준다. 라돈은 폐암을 발병시키고, 그 효과는 비흡연자에 비해 흡연자들에게서 더 크게 나타난다. 이 모델은 라돈의 효과가 선형적이라고 가정하며 동시에 흡연과 상호작용할 것이라는 가정을 하고 있다. 1.4.2 Regression to adjust for differences between treatment and control groups 현실의 인과추론의 문제에서 처치와 통제가 이루어지는 피험체(experimental units) 간에는 체계적 차이(systematic difference)가 존재한다.2 Figure 1.6은 가상으로 만든 데이터와 그에 적합하는 선형회귀모델을 시각화한 것이다. Figure 1.6은 다음과 같이 요약할 수 있다. 처치를 받은 단위의 평균은 \\(\\bar{y}=31.7\\)로 통제된 단위의 평균인 \\(\\bar{y}=25.5\\)에 비해 4.8 포인트 높았다. 그러나 두 집단은 처치가 이루어지기 이전의 예측변수에 있어서 차이를 보였다: 예측변수, \\(x\\)의 평균인 \\(\\bar{x}\\)는 처치군에서는 0.4였고, 통제군에서는 1.2였다. 이러한 차이를 조정한 이후에는 처치효과가 10.0이라고 추정할 수 있었다. 따라서 주요 예측변수에 있어서 처치/통제 단위 간 불균형(imbalance)이 존재한다고 할 때에는 그 불균형을 어느 정도 조정(adjustment) 해주는 것이 필요하다. Figure 1.6: Hypothetical data with a binary treatment and a continuous pre-treatment variable. Treated units are displayed with circles on the scatterplot, and controls are shown with dots. Overlaid is a fitted regression predicting the outcome given treatment and background variable, with the estimated treatment effect being the difference between the two lines. 1.4.3 Interpreting coefficients in a predictive model 회귀모델은 일종의 예측모델이지만 만약 모델 내에 포함된 오차(errors)가 클 경우에는 무언가를 예측하는 것에는 거의 무용하다(useless). 다만 회귀모델은 추정된 기울기(estimated slope)를 통해 관측된 데이터의 변수들 간의 관계 양상을 탐색하는 것에 유용하다. 오차를 포함하더라도 그 관계가 정(positive)인지 부(negative)인지에 대한 패턴을 보여주기 때문이다. 또한 회귀모델은 표집(sampling)을 통한 추론이기 때문에, 우리는 회귀모델을 적합한 표본(sample)이 우리가 알고자 하는 모집단(population)에 대해 대표성을 가질 것이라고 기대하고 그 결과를 모집단 수준에서 직접적으로 해석할 수 있다. 혹은 표본과 모집단 간의 간극을 좁히기 위해 모델에 추가적인 예측변수들을 포함할 수도 있다. 여기서 알 수 잇는 것은 첫째, 표본이 대표성을 가지지 못한다면 표본을 통해 얻은 결과를 모집단 수준에서 해석하는 것에서 왜곡이 일어날 수 있다는 것, 둘째는 예측변수들을 추가함으로써 우리는 표본과 모집단 간의 간극을 좁힐수도 있지만 동시에 잘못된 예측변수를 추가하게 되면 그 간극이 오히려 넓어질수도 있다는 것이다. 회귀모델을 인과추론으로 해석하는 것이 일견 자연스러워 보이지만 모델 안에 포함되어야 하지만 우리가 관측하지 못해 포함하지 못한 변수들(lurking variables or confounders)이 존재할 수 있기 때문에 회귀모델은 완벽한 통제(control)가 이루어진다고 볼 수 없다. 따라서 회귀모델을 통해 인과추론을 하는 것에는 주의가 필요하다. 1.4.4 Building, interpreting, and checking regression models 통계분석은 다음과 같은 네 단계를 거쳐서 수행된다: \\(y = \\alpha + \\beta x + \\mathrm{error}\\)의 형태로 단순선형모델로 시작해 추가적인 예측변수들(\\(x_2\\cdots x_n\\)), 상호작용, 그리고 변형된 변수(transformations)들을 추가하는 것으로 확장되는 모델 구축(model building) 단계. 데이터 조작(data manipulation), 프로그래밍, 그리고 회귀계수와 불확실성을 추정하고 확률적 예측을 하기 위한 알고리즘의 사용을 포함한 모델 적합(model fitting) 단계. 그래픽과 프로그래밍, 그리고 측정지표와 모수, 그리고 연구 기저에 놓인 목적 간의 (불완전한) 관계를 적극적으로 조사하는 모델 등의 적합도(model fit)을 이해하는 단계. 모델을 발전시키기 위한 방향을 고민하고 비판하는 단계. 어떠한 연구도 완벽하지 않다(No study is perfect). 1.5 Classical and Bayesian inference GHV는 기본적으로 베이지안 추론을 사용하지만, 이 리딩노트는 기본적으로 빈도주의적 접근을 취하고자 한다. 하지만 이 장에서의 베이지안 추론의 소개는 알아둘만한 것이기에 간단히 정리한다. 통계를 하는 사람으로서 우리는 데이터에 모델을 적합하고 그 모델을 이용해 예측하는 데 많은 공을 들인다. 그리고 이러한 단계들은 방법론적, 철학적 이론틀에 바탕을 두고 있다. 전통적인(빈도주의적인) 분석틀과 베이지안 분석틀 모두가 취하고 있는 공통적인 접근법으로는: (1) 추정(estimation) 과정에 어떠한 정보(information)가 사용되는가, (2) 어떤 가정(assumptions) 하에서 이루어지는가, (3) 추정치와 예측값을 어떻게 해석(interpretation)하는가 등이 있다. 1.5.1 Information 어떤 회귀모델이던간에 결과변수(종속변수), \\(y\\)와 하나 이상의 예측변수, \\(x\\)에서 시작한다. 데이터 그 자체에 더해 우리는 데이터가 어떻게 수집되는지에 대한 정보도 필요하며, 데이터의 가용성 여부에 대한 정보도 필요하다. 마지막으로 우리는 지금 당장 가지고 있는 데이터뿐 아니라 이전의 경험, 유사한 연구 등을 바탕으로 일종의 사전적 지식(prior knowledge)을 가지게 된다. 그리고 연구에 있어서 이러한 정보들을 어떻게 반영하는가, 모델에 포함시키는가는 주위해야한다. 예를 들어, 기게재된 연구논문들은 “통계적 유의성”을 보이는 결과, 혹은 큰 효과를 보이는 결과를 선별적으로 보여주어야 출판될 수 있다는 압박에 효과를 과다추정하는 경향을 보일 수 있다. 이 경우, 데이터가 충실하지 않고, 사전적 지식이 없다면 말이 되지 않는 결론을 도출할 수 있다. 1.5.2 Assumptions 예측변수 \\(x\\)와 결과변수 \\(y\\)에 대한 회귀모델에는 약 세 가지 핵심적인 가정이 필요하다. \\(x\\)와 \\(y\\)의 관계에 대한 함수적 형태에 관한 가정이 필요하다. 데이터가 어디서 오는가에 대한 가정이 필요하다. 다른 책이나 연구논문에서는 데이터 생성과정(Data Generating Process; DGP)이라고도 한다. 기본적으로는 표본으로 우리가 확보하게 될 데이터의 (결코 관측될 수 없는) 모집단이 어떻게 생겨먹었나에 대한 가정이라고 할 수 있다. 측정된 데이터가 과연 실제 현실세계에 대한 적절성(relevance)을 가지는가에 대한 가정이 필요하다. 1.5.3 Classical inference 빈도주의적 접근(frequentist approach)이라고도 한다. 사전적 정보가 아닌, 우리가 관측하여 확보한 데이터의 정보를 요약하고 가급적 편향되지 않고 분산 정도가 적은 추정치와 예측치를 얻고자 하는 데 그 목적이 있다. 그리고 당연히 표본을 통해 추론하는 것이니 만큼, 표본을 얻는 데 필연적으로 포함되는 불확실성이 존재한다. 1.5.4 Bayesian inference 베이지안 추론은 단순히 존재하는 데이터를 요약하는 것을 넘어 사전적 정보를 포함하여 추론하는 접근법이다. 예컨데, 만약 선행연구가 어떠한 경험적 연구를 축적해 와서 핵심 예측변수가 결과변수에 미치는 평균적 효과에 대한 “사전적 정보”가 존재한다고 할 때, 그 사전적 정보를 이용하여 사후에 얻은 데이터에 반영, 사후 분포(post distribution)를 추정하는 방법인 것이다. 장점: 보다 합당한 결과를 확인할 수 있으며, 미래의 결과/미래 실험의 결과에 대해 직접적인 예측이 가능하다. 단점: 사전 분포(prior distribution)라고 하는 추가적인 정보가 필요하다. 전통적 추론은 예측값으로 한정되는 데이터의 요약을 보여줄 수 있다면, 베이지안 추론은 관측된 데이터가 빈약하더라도 추가적인 가정에 의존하여 이론으로부터 타당한 예측을 도출할 수 있다.–절대적으로 옳은 한 가지 방법이 있는 것은 아니다. 1.6 Computing least squares and Bayesian regression 베이지안 접근법과 시뮬레이션 접근법은 정규화(regularized) 선형회귀모델이나 멀티레벨 모델을 적합할 때 보다 중요하다.3 References "],["data-and-measurement.html", "Chapter 2 Data and Measurement 2.1 Examining where data come from 2.2 Validity and reliability 2.3 All graphs are comparisons 2.4 Data and adjustment: trends in mortality rates", " Chapter 2 Data and Measurement 모델을 적합하기에 앞서, 모델에 사용할 데이터와 측정지표를 탐색하고 이해할 필요가 있다. 2.1 Examining where data come from Figure 2.1: Map that appeared on the internet of the so-called ``Human Development Index,’’ ranking the 50 states and Washington, D.C., from PlatypeanArchcow (2009). Figure 2.2: Graphing the Human Development Index versus average income by state: (a) scatterplot of the data, (b) scatterplot of ranks. Figure 2.1은 Human Development Index (HDI)를 워싱턴 DC와 50개 주를 비교한 지도이다. 이 지도가 우리가 생각하는 주들 간 공중보건 수준을 현실적으로 반영하고 있을까? HDI는 세 가지 차원으로 측정된다: 기대수명(life expectancy) 성인 문해율(adult literacy rate)과 초중고등 교육 등록률(primary, secondary, and tertiary gross enrollment ratio) 구매력을 기준으로 한 일인당 국내총생산(GDP)에 자연로그를 취한 값: 생활 수준(standard of living) 즉, HDI는 위의 세 지표를 결합한 것이기 때문에 역으로 특정 지표의 값이 높지만 나머지 지표의 값이 낮은 주와 평균적으로 세 지표 모두를 중간 수준의 값으로 가지는 주 간의 차이를 구분하지 못할 수 있다는 것이다. Figure 2.2는 HDI와 주들 간 평균 소득 수준을 비교한 플롯이다. Figure 2.2a는 두 변수 간 관계가 강하지만 비선형적이라는 것을 보여주며, Figure 2.2b는 평균 소득 순위와 HDI 순위 간 관계가 매우 선명한 선형 관계를 가지고 있다는 것을 보여주고 있다. 이 예시는 다른 방법으로 그래프를 그림으로써 데이터를 더 잘 이해할 수 있다는 것을 보여준다. 2.1.1 Details of measurement can be important 미국정치는 거대 양당에 의해 주도되고 있지만 이념적 스펙트럼에 있어서는 그 강도에 따라 세분화할 수 있다. 그러나 당파성과 이념적 척도는 동일하지 않다. Figure 2.3a는 자기이념에 있어서 진보-중도-보수의 비율이 모든 소득 수준에서 비슷한 것으로 나타난다. Figure 2.3b는 당파성에 있어서 소득 수준이 적어도 2008년 기준으로는 공화당 당파성과 강한 관계가 있음을 보여준다. 회귀모델은 데이터를 요약하고, 데이터로부터 추론을 도출하는 방법이다. 따라서 회귀모델은 분석하고자 하는 데이터의 질(quality of data)과 연구문제에 대한 데이터의 적실성에 좌우된다. 측정지표와 현실 간 간극은 과학적 연구에 있어서 일반적인 문제이다. Figure 2.3: Distribution of (a) political ideology and (b) party identification, by income, from a survey conducted during the 2008 U.S. election campaign. 2.2 Validity and reliability 측정은 두 가지 이유에서 중요하다. 우리는 실제로 데이터가 무엇을 의미하는지 이해해야 한다. 이를 위해 데이터를 시각화하고, 데이터로부터 필요한 정보를 추출하는 노력이 필요하다. 정확성, 신뢰성, 그리고 타당도는 분산(variance), 상관관계(correlation), 그리고 오차 등을 이해하는 데 중요한 기초이다. 2.2.1 Validity 타당도란 “측정하고자 하는 것을 보여주는 정도”를 의미하며, 가능한 범주에서 평균적으로 정확한 답을 찾아낼 수 있도록 측정하는 과정이라고 할 수 있다. 즉, 어떤 측정지표가 측정하고자 하는 것을 제대로 측정하느냐의 문제라고 할 수 있다. 2.2.2 Reliability 신뢰도란 정확하고 안정적인 측정지표의 특성을 말한다. 우리가 무언가를 측정할 때, 그것을 여러번 측정하더라도 비슷하게 측정될 때, 신뢰도를 확보했다고 할 수 있다. 2.2.3 Sample selection 데이터 선정(selection)은 관측할 수 없는 모집단의 표본이 모집단을 잘 대표하지 못할 수도 있다는 문제를 의미한다. 물론 연구목적에 따라서 특정한 표본을 선정해야하는 경우도 있기 때문에 항상 특정한 기준으로 선택된 표본이 문제라고는 할 수 없다. 2.3 All graphs are comparisons 2.3.1 Simple scatterplots Figure 2.4는 보건지출과 기대수명 간의 관계를 보여주는데, 미국이 다른 국가에 비하여 그다지 기대수명에 눈에 보이는 진전이 나타나지 않는데도 불구하고 높은 수준의 일인당 보건지출을 하고 있다는 것을 확인할 수 있다. Figure 2.4: Health care spending and life expectancy in several countries. This scatterplot shows two things: the generally positive correlation between spending and lifespan, and the extreme position of the United States. 2.3.2 Displaying more information on a graph 이 산포도는 \\(x\\), \\(y\\), 그리고 그 두 축 위에 놓인 고나측치를 통해 측정 전 후의 처치와 통제 간의 결과를 비교하는 플롯이다. 연달아 있었던 선거의 두 해를 대상으로 지역구가 특정한 한 정당에 편향적으로 우호적인지를 보여주는 당파성 편향(partisan bias)을 추정한 결과를 보여준다. 분석단위: 미국의 주 의회 선거(state legislative election) 처치(treatment): 서로 다른 선거구 재획정 계획(redistricting plan) 통제: 선거구 제획정이 일어나지 않았던 두 선거의 관측치들(지역구들) Figure 2.5에서 상호작용은 데이터를 해석하는데 매우 중요하다. 선거구 재획정이 없으면, 당파성 편향은 체계적으로 변화하지 않는다. 선거구 재획정의 가장 큰 효과는 당파성 편향을 0에 보다 가깝게 만든다는 것이다. 이처럼 시각화한 결과는 우리가 가진 데이터의 정보를 직관적으로 이해하도록 돕는다. Figure 2.5: Effect of redistricting on partisan bias in U.S. state legislative elections. Each symbol represents a state and election year, with solid circles, open circles, and crosses representing Democratic, bipartisan, and Republican redistricting, respectively. The small dots are the control cases&lt;U+2014&gt;state-years that did not immediately follow a redistricting. Lines show fit from a regression model. Redistricting tends to make elections less biased, but small partisan biases remain based on the party controlling the redistricting. 2.3.3 Multiple plots 데이터를 기대하지 않은 방식으로 바라보는 것도 때로는 새로운 것을 발견하는 단초가 될 수 있다. 자세한 내용은 GHV의 27-28 페이지의 예제를 참고. 간단히 말하면, 데이터를 가지고 여러 플롯으로 쪼개서 다각적으로 살펴보면 새로운 것을 발견할 수도 있다는 조언이다. Figure 2.6: Distribution of last letters of boys’ names from a database of American babies born in 1906, 1956m and 2006. Redrawn from a graph by Laura Wattenberg. Figure 2.7: Trends in percentage of boys’ names ending in each letter. This graph has 26 lines, with the lines for N, D, and Y in bold to show the different trends in different-sounding names. Compare to Figures 2.6 and 2.7, which show snapshots of the last-letter distribution in 1906, 1956, and 2006. Figure 2.8: Trends in concentration of boys’ and girls’ names. In the late 1800s, and then again at different periods since 1950, there have been steep declines in the percentage of babies given the most popular names, so that now the top 10 names of each sex represent only about 10% of baby names. Thus, even as the sounds of boys’ names have become more uniform (as indicated by the pattern of last letters shown in Figure 2.6), the particular names chosen have become more varied. 2.3.4 Grids of plots 산포도는 두 개의 연속형 변수, \\(y\\)와 \\(x_1\\) 간의 관계를 보여준다. 만약 \\(x_2\\)라는 추가적인 변수가 있고, 이것이 이산형(discrete)라고 하면 산포도에서 점의 색 등을 \\(x_2\\)의 카테고리별로 다르게 출력하는 등으로 보여줄 수 있다. \\(x_2\\)가 연속형일 경우도 색의 진하기로 표현할 수 있지만, 시각적으로 뚜렷하게 구분하기가 어려워 추천하지는 않는다. 또는 \\(x_2\\), \\(x_3\\) 등을 추가적인 기준점으로 산포도 자체를 세분화해 쪼개는 방법(grid)이 있다(small multiples). Figure 2.9에서도 확인할 수 있듯, 산포도를 통해 우리는 연속형 종속변수인 \\(y\\)를 연속형 예측변수인 \\(x_1\\)과 대응되도록 그래프를 그린 후, 이산형 예측변수인 \\(x_2\\), \\(x_3\\), \\(x_4\\)를 레이어를 덧씌우듯 (마커에 색을 추가하는 등) 시각화할 수 있다. 또한, 각각의 플롯에 \\(x_2, \\cdot x_4\\)의 예측변수들의 서로 다른 고정된 값에서 \\(x_1\\)와 \\(y\\) 간의 함수적 관계에 따른 \\(y\\)의 기대값을 보여주는 예측선을 그리는 것 등도 가능하다. Figure 2.9: Swings in U.S. congressional elections in three different periods. This grid of plots demonstrates how we can display an outcome (in this case, the swing toward the Democrats or Republicans between two elections in a congressional district) as a function of four predictors: previous Democratic vote share, incumbency status (gray for incumbents running for reelection, black for open seats), region of the country, and time period. Uncontested and landslide elections have been excluded. 2.3.5 Applying graphical principles to numerical displays and communication more generally 데이터를 분석할 때는 그 결과를 읽는 독자의 입장 또한 생각해야한다. 독자의 입장에서 괜히 부담되는 불필요한 정보를 과다하게 전달할 필요는 없다. 예컨대, 숫자의 소수점도 일정 부분에서 반올림하여 읽는 사람이 직관적으로 이해할 수 있도록 도울 필요가 있다. 불확실성을 보여주는 구간 [3.276, 6.410]은 [3.3, 6.4]라고 적더라도 그 실질적 의미는 훼손되지 않으며 보는 사람 입장에서는 더 간결하다. 그리고 통계적 결과들을 그래프로 보여주는 것은 가독성을 높여준다. 단, 설명할 수 없는 그래프를 굳이 보여줄 필요는 없다. 모든 그래프에는 제목(caption)을 달아야 한다. 2.3.6 Graphics for understanding statistical models 통계분석에서 그래프는 크게 세 부분에서 유용하다. 원 데이터(raw data)를 보여주는, 이른바 “탐색적 분석”에 용이하다. 예측 모델과 추론에 있어서 그래프는 모델의 적합도를 파악하는데 도움을 준다. 예측 모델을 통해서 재생산된 데이터를 시뮬레이션해서 원 데이터와 비교하는 그래프를 그려서 보여줄 수도 있다. 최종 결과물을 그래프로 보여줄 수 있다. 그래프를 그리는 목적은 연구자 본인과 연구를 읽는 대상 간의 소통을 용이하게 하기 위해서이다. 2.3.7 Graphs as comparisons 모든 시각화된 그래프는 일종의 비교를 위한 수단이라고 볼 수 있다. 2.3.8 Graphs of fitted models 적합된 모델과 데이터를 동일한 플롯에 함께 그리는 것이 유용할 수 있다. 예를 들어, 실제 데이터와 우리가 시뮬레이션을 이용해서 예측한 값들의 관계를 함께 보여주면 우리가 가설적으로 수립한 관계가 관측된 데이터들에서도 그 양상이 나타나는지를 파악하기가 용이하다. 2.4 Data and adjustment: trends in mortality rates GHV는 사망률(mortality rates)의 예제를 통해 특정 연령집단에서의 집합적인 사망률의 증가가 45세부터 54세 연령 집단의 구성이 1990년부터 2013년 사이에 크게 변화하였기 때문인지를 분석한다. 만약 45세부터 54세 연령집단의 구성이 시간에 따라 변화하여 사망률의 차이가 나타났다면, 그 집단의 시간에 따른 사망률의 변화는 연령에 특정한 사망률의 변화는 반영하고 있지 않는다고 볼 수 있다. 즉, 연도-시간의 변화가 주요 요인이라면 45세부터 54세라는 이 중장년층이라는 연령 자체의 특정한 효과는 사망률의 변화에 큰 영향을 미치지 않앗을 것이라고 볼 수 있다는 것이다. 이를 확인하기 위해서 GHV는 이 연령 집단의 순수한 사망률의 변화도 보고, 평균 연령의 변화, 나아가 그 두 패턴을 비교해본다. Figure 2.10이 바로 그것이다. Figure 2.10은 해당 연령 집단의 사망률 변화를 이해하기 위해서는 연령에 대한 조정이 필요하다는 것을 보여준다(연령 그 자체가 사망률에 영향을 미칠 수 있음). 왜냐면 시간적 추이에 따라서 사망률이 계속 증가하는 것은 맞지만 동시에 평균 연령도 증가하고 있기 때문에 평균연령의 증가가 사망률의 증가로 이어졋을 가능성을 배제할 수 없기 때문이다. Figure 2.10: (a) Observed increase in raw mortality rate among 45-to-54-year-old non-Hispanic whites, unadjusted for age; (b) increase in average age of this group as the baby boom generation moves through; (c) raw death rate, along with trend in death rate attributable by change in age distribution alone, had age-specific mortality rates been at the 2013 level throughout. Figure 2.11a은 연령에 대해 조정한 경향성이 그다지 사망률의 증가에 민감한 영향을 미치지 않는다는 것을 보여준다. 반면에 성별로 연령대별 조정한 사망률을 분리해서 살펴보면 Figure 2.11b와 같은 결과를 얻을 수 있는데, 1999년부터 2013년까지 여성의 사망률이 증가한 반면, 남성의 사망률은 1999년부터 2005년까지 증가하지만 2005년부터 2013년까지는 반전하는 것을 확인할 수 있는 것이다. 이처럼 데이터가 가지고 있는 정보는 그것을 어떻게 집약(aggregation)하고, 또는 해체(disaggregation)하느냐에 따라서 다른 결과를 보여줄 수 있다. Figure 2.11: (a) Age-adjusted death rates among 45-to-54-year-old non-Hispanic whites, showing an increase from 1999 to 2005 and a steady pattern since 2005; (b) comparison of two different age adjustments; (c) trends in age-adjusted death rates broken down by sex. The three graphs are on different scales. 마지막으로 Figre 2.12는 셩별에 따른 미국의 지역별 연령 조정된 사망률의 추이를 보여주는데, 특기할 것은 남부 지역의 여성의 사망률이 눈에 띄는 증가세를 보인다는 점이다. 반면에 두 성별 모두 북동부에서는 사망률이 감소하는 모습을 보였고, 가장 낮은 추이를 보였다. 이같은 일련의 그래프들은 데이터 탐색(data exploration)이 얼마나 중요한지를 보여준다. Figure 2.12: Age-adjusted death rates among 45-to-54-year-old non-Hispanic white men and women, broken down by region of the country. The most notable pattern has been an increase in death rates among women in the South. In contrast, death rates for both sexes have been declining in the Northeast. The graphs are on different scales; as can be seen from the y-axes, death rates are lower for women than for men. "],["some-basic-methods-in-mathematics-and-probability.html", "Chapter 3 Some Basic Methods in Mathematics and Probability 3.1 Weighted averages 3.2 Vectors and matrices 3.3 Graphing a line 3.4 Exponential and power-law growth and decline; logarithmic and log-log relationships 3.5 Probability distributions 3.6 Probability modeling", " Chapter 3 Some Basic Methods in Mathematics and Probability 회귀모델에 있어서 기초적인 수리통계학적 기법들을 숙지하는 것은 약 세 가지 측면에 있어서 중요하다. 선형대수(linear algebra)와 간단한 확률분포는 정교한 모델의 토대가 된다. 모델들을 들여다보기에 앞서 추론에 대한 기본적인 개념들을 이해하는 것은 유용하다. 때로는 정교한 모델을 적합하기 이전에 연구문제의 일부에 대해 빠르게 비교 및 추정해보는 것은 모델 결과를 이해하는 데 유용하다. 3.1 Weighted averages 통계학에서 연구하고자 하는 모집단(target population)에 맞추기 위하여 데이터 또는 추론에 어떠한 가중치를 부여하는 것은 흔한 일이다. 간단한 예로, 2010년에 북미에 거주하는 4,560만명 중 3억 1000만명은 미국에, 1억 1200만명은 멕시코에, 3,400만명은 캐나다에 거주하는 사람이었다고 하자. 해당 연도에 각 국가에 거주하는 사람들의 평균 연령은 Table 3.1에서 확인할 수 있다. 그리고 모든 북미 거주자의 평균연령은 가중평균(weighted average)이다. \\[ \\begin{align*} \\text{average age} &amp; = \\frac{310{,}000{,}000 \\cdot 36.8 + 112{,}000{,}000 \\cdot 26.7 + 34{,}000{,}000 \\cdot 40.7}{310{,}000{,}000 + 112{,}000{,}000 + 34{,}000{,}000} \\\\ &amp; = 34.6. \\end{align*} \\] 단순평균이 아니라 가중평균이라고 하는 이유는 각 국가의 인구에 가중치(weights), 36.8, 26.7, 40.7, 를 비례하여 곱해주었기 때문이다. 북미의 전체 인구는 \\(310 + 112 + 34 = 456\\), 즉 4억 5,600만명이고, 우리는 위의 식을 다음과 같이 바꾸어 쓸 수 있다. \\[ \\begin{align*} \\text{average age} &amp; = \\frac{310{,}000{,}000}{456{,}000{,}000} \\cdot 36.8 + \\frac{112{,}000{,}000}{456{,}000{,}000} \\cdot 26.7 + \\frac{34{,}000{,}000}{456{,}000{,}000} \\cdot 40.7 \\\\ &amp; = 0.6798 \\cdot 36.8 + 0.2456 \\cdot 26.7 + 0.0746 \\cdot 40.7 \\\\ &amp; = 34.6. \\end{align*} \\] 위의 식에서 나타난 비율, 0.6798, 0.2456, 그리고 0.0746의 총합은 1이며, 이들 각각은 가중평균에서 각 국가들에 대한 가중치를 의미한다. 위와 같은 가중평균을 구하는 식은 다음과 같이 축약할 수 있다. \\[\\text{weighted average} = \\frac{\\sum_j N_j \\bar y_j}{\\sum_j N_j},\\] 이때, \\(j\\)는 국가를 나타내며 가중평균을 구하기 위해서 우리는 각 층위(strata), 여기서는 각 국가 단위에서의 연령의 합을 구해주어야 한다. Table 3.1: Populations and average ages of countries in North America. (Data from CIA World Factbook 2010.) The average age of all North Americans is a weighted average of the average ages within each country. Stratum Label Population Average age 1 United States 310 million 36.8 2 Mexico 112 million 26.7 3 Canada 34 million 40.7 3.2 Vectors and matrices 일련의 숫자들의 모임(a list of numbers)을 벡터(vector)라고 한다. 동시에 숫자를 이차원으로 배열한 것(a rectangular array of numbers)은 행렬(matrix)라고 한다. Section 1.2에서 선거 직전 해의 경제적 조건에 따른 미국 대선의 집권당 투표율 예측 예시를 떠올려보자. \\[ \\begin{align*} \\text{predicted vote percentage} &amp; = 46.3 + 3.0 \\cdot (\\text{growth rate of average personal income}) \\\\ \\hat y &amp; = 46.3 + 3.0 x \\\\ \\hat y &amp; = \\hat a + \\hat b x, \\end{align*} \\] 이때 \\(\\hat a\\)와 \\(\\hat b\\)는 데이터로부터 적합하여 추정해낸 추정값(estimates)을 의미하며, \\(\\hat y\\)는 예측값(predicted value)을 보여준다. 위의 예제에서 \\(y\\)는 실제 선거 결과를 의미한다. \\(\\hat y\\)는 모델의 예측 결과를 나타낸다. 이제 이 모델을 몇 가지 특수한 사례들에 적용해보자. \\(x = -1\\). 경제성장률이 -1%일 때, 모델에 따르면 집권당의 득표율은 \\(46.3 + 3.0 * (-1) = 43.3%\\)가 된다. \\(x = 0\\). 경제성장률이 0%, 즉 전혀 성장하지 않았을 때에는 \\(46.3 + 3.0 * 0 = 43.3%\\)가 된다. \\(x = 3\\), 약 3%의 경제성장률은 집권당 후보가 이길 수 있는 \\(46.3 + 3.0 * 3 = 55.3%\\)의 득표율로 이어질 것이다. Table 3.2: Special cases for the model a_hat b_hat x formula y_hat 46.3 3 -1 46.3 + 3 * -1 43.3 46.3 3 0 46.3 + 3 * 0 46.3 46.3 3 3 46.3 + 3 * 3 55.3 위의 적용은 벡터로도 나타낼 수 있다. \\[\\hat y = \\begin{bmatrix} 43.4 \\\\ 46.3 \\\\ 55.3 \\end{bmatrix} = \\begin{bmatrix} 46.3 + 3.0 \\cdot (-1)\\\\ 46.3 + 3.0 \\cdot 0 \\\\ 46.3 + 3.0 \\cdot 3\\end{bmatrix},\\] 마찬가지로 행렬로도 나타낼 수 있다. \\[\\hat y = \\begin{bmatrix} 43.4 \\\\ 46.3 \\\\ 55.3 \\end{bmatrix} = \\begin{bmatrix} 1 &amp; -1 \\\\ 1 &amp; 0 \\\\ 1 &amp; 3 \\end{bmatrix} \\begin{bmatrix} 46.3 \\\\ 3.0 \\end{bmatrix},\\] 혹은 더 축약하여 다음과 같이 나타낼 수 있다. \\[\\hat y = X \\hat \\beta,\\] 이때 \\(y\\)와 \\(x\\)는 길이가 3인 벡터가 된다.4 이때, \\(X\\)는 \\(3\\times 2\\)의 행렬이 되며, 1 세개는 각각의 \\(x\\) 사례에서 모델에 포함될 절편을, 그리고 다른 하나의 열은 세 \\(x\\) 값을 가지게 된다. \\(\\hat \\beta = (46.3, 3.0)\\)은 추정된 계수값의 벡터이다. 즉, \\(\\hat y = X \\hat \\beta,\\)은 일종의 회귀모델의 개념으로 \\(\\text{예측값} = \\text{주어진 관측값}\\times\\text{모델로 추정한 계수값}\\)으로 구성된다고 이해할 수 있다. 3.3 Graphing a line 선형회귀모델을 효과적으로 사용하기 위해서는 회귀모델로 인해 그리는 직선에 대한 대수학(algebra)와 기하학(geometry)적 논리를 이해하는 것이 필요하다. Figure 3.2는 \\(y = a + bx\\)에 대한 선을 보여준다. 절편(intercept), \\(a\\)는 \\(x\\)가 0일 때의 \\(y\\)의 값이다. 계수값(coefficient), \\(b\\)는 직선의 기울기(slope)를 의미한다. \\(b&gt;0\\)이면 기울기가 우상향하고 우리는 이 관계를 정의 관계(positive)라고 서술한다. \\(b&lt;0\\)이면 기울기가 우하향하고 우리는 이 관계를 부의 관계(negative)라고 서술한다. \\(b=0\\)이면 기울기는 수평해지며, 이때 우리는 \\(x\\)와 \\(y\\)의 관계가 독립적이라고 볼 수 있다. 왜냐하면 \\(x\\)가 어떤 값을 취하던 \\(y\\)는 항상 일정하기 때문(변하지 않기 때문)에 \\(x\\)가 \\(y\\)에 어떠한 영향을 미친다고 볼 수 없기 때문이다. 기울기 값의 절대값이 클수록 그 관계 양상은 심화되며, 기울기는 가팔라진다. Figure 3.1: Lines y = a + bx with positive and negative slopes. Figure 3.3a는 \\(y = 1007-0.39x\\)라는 수리적 예제에 대한 시각화 결과이다. 이 식은 \\(x\\)가 0일 때 \\(y\\)는 1007이며, \\(y\\)는 \\(x\\)의 한 단위가 증가할 때마다 0.39씩 감소한다는 것을 의미한다. 이 선은 1900년부터 2000년까지 세계 1마일 달리기 애회의 기록과 개략적으로 일치한다(Figure 3.3b). Figure 3.2: (a) The line y = 1007 &lt;U+2212&gt; 0.393x. (b) For x between 1900 and 2000, the line y = 1007 &lt;U+2212&gt; 0.393x approximates the trend of world record times in the mile run. Compare to Figure A.1. 물론 이 결과는 실제 값과는 다르다. 왜냐하면 \\(x\\)는 현실 세계에서 0일 수 없기 때문이다. 3.4 Exponential and power-law growth and decline; logarithmic and log-log relationships \\(y = a + bx\\)의 선은 로그변환(logarithmic transformations)을 통하여 보다 일반적인 관계 양상을 표현하는 데 사용될 수 있다. \\(\\log y = a+bx\\)는 기하급수적인(exponential) 성장(\\(b&gt;0\\)일 때)이나 침체(\\(b&lt;0\\))를 나타내며, \\(A = e^a\\)라고 할 때, \\(y = Ae^{bx}\\)로 나타낼 수 있다. \\(A\\)는 \\(x= 0\\)일때의 \\(y\\)의 값이다. \\(b\\)는 경제성장률 혹은 침체율의 그 비율(rate)을 결정하는 모수(parameter)이다. \\(x\\)의 한 단위 변화는 \\(\\log y\\)에 있어서의 \\(b\\)만큼의 추가적인 변화로 이어지며, 이는 곧 \\(y\\)가 \\(e^b\\)만큼 변화하는, 일종의 곱셈적 관계로 나타난다. 기하급수적(exponential)이라는 표현을 사용하는 이유는 그 관계가 선형, 직선의 형태로 서술되지 않기 때문이다. 로그 변환이 회귀모델 분석의 해석과 어떠한 관계가 있는지를 나타내기 위해 하나의 예제를 살펴보자. \\(y, x\\) 모두에 로그변환이 이루어진 상태로 다음과 같은 모델이 존재한다고 하자: \\[ \\log y = 1.4 + 0.74\\log x. \\] 우리는 양변의 로그를 모두 풀어줄 수도 있다. 이때, 위의 식을 변환하지 않은 척도의 \\(x\\)와 \\(y\\)로 나타내면 다음과 같다. \\[ \\begin{align*} e^{\\log y}&amp;=e^{1.4 + 0.74\\log x}\\\\ y&amp;=4.1x^{0.74}. \\end{align*} \\] 그리고 \\(x\\)와 \\(y\\)를 로그변환했을 때는 직선의 형태로 나타났던 관계가, 로그변환을 풀어주면 곡선의 관계로 바뀌게 된다. 당연히 해석하는 방식도 달라질텐데, 여기서 하나의 함의는 원래 비선형 관계인 \\(x\\)와 \\(y\\)를 로그변환 등을 통해 직선의 관계로 나타낼 수는 있지만 실질적 해석을 할 때에는 그 둘의 관계가 원래는 비선형이었다는 것을 염두에 두어야 한다는 것이다. 예를 들어, \\(\\log x\\)의 한 단위 증가가 \\(\\log y\\)의 \\(\\beta\\) 만큼의 증가로 이어진다라고 해석하면 누구도 쉽게 이해하지 못할 것이다. Figure 3.3: Fitted curve of metabolic rate vs. body mass of animals, on the log-log and untransformed scales. The difference from the elephant’s metabolic rate from its predictive value is relatively small on the logarithmic scale but large on the absolute scale. Figure 3.4: Fitted curve of metabolic rate vs. body mass of animals, on the log-log and untransformed scales. The difference from the elephant’s metabolic rate from its predictive value is relatively small on the logarithmic scale but large on the absolute scale. 3.5 Probability distributions 앞에서 기울기와 절편 등은 선형회귀모델의 예측에 있어서의 “결정주의적”(deterministic) 부분을 보여주는 것이었다면5, 여기서는 우리의 모델이 정확하게 데이터와 적합하지 않기에 필요한 확률분포와 확률변수라는 개념을 살펴본다. 확률분포는 현실 속 모델에 포함되지 않는 측면을 식에서 오차항(error term, \\(\\epsilon\\))으로 나타내며, 위에서 살펴본 모델은 \\(y = a + bx + \\epsilon\\)의 형태로 업데이트 될 수 있다. 그리고 이러한 불확실성은 우리가 데이터를 통해 어떠한 인과성 등을 추론하게 하는 원동력이 된다. 우리의 처치6는 일종의 개념적 정의와 수리적 공식이 결합된 것이기 때문에 확률분포에 대해 이해는 유용하다. 확률분포에 대한 적용은 다음과 같은 것들을 의미한다. \\(y_i, i = 1, \\dots, n\\)으로 나타낼 수 있는 데이터의 분포 \\(\\epsilon_i, i = 1, \\dots, n\\)으로 나타낼 수 있는 오차항의 분포 회귀모델에서 핵심적인 부분은 주어진 예측변수들의 조건 하에서 결과변수들의 값이 어떻게 분포되어 있는지를 살펴보는 것이다. 주어진 예측변수들의 조건 하에서 결과변수의 평균값을 예측한다. 예측값의 변동성(variation)을 요약(summarize)한다. 회귀모델에서 확률분포는 평균을 예측한 이후에 존재하는 분산을 특정하는데 사용된다. 즉, 확률분포란 우리의 예측이 어느 정도의 불확실성을 내포하는지를 추정하고자 하는 모수를 기준으로 보여주는 데 사용된다.7 3.5.1 Mean and standard deviation of a probability distribution 확률변수, \\(z\\)의 확률분포는 일정한 값의 범위를 가진다. 분포의 평균(mean)은 그 모든 범위 값의 평균(average)이다. 평균은 기대값(expected value)라고도 불리며, \\(E(z)\\) 또는 \\(\\mu_z\\)라고 쓸 수 있다.8 한편 확률변수 \\(z\\)의 분포에 대한 분산(variance)은 \\(E((z-\\mu_z)^2)\\)로 표현할 수 있으며, 각 관측치와 평균 간의 차이를 제곱한 것의 평균값이다. 분포의 변동성 정도에 따라서 \\(z\\)에 대한 표본추출된 값은 다를 수 있다. 변동성 정도에 따라서 \\(\\mu_z\\)를 기대하였지만 표본의 평균은 그보다 작거나 클수도 있고, 그 차이는 더 커질수도, 작아질수도 있다. 만약 변동성이 존재하지 않는다면, \\(z\\)의 분산은 0이라고 할 수 있다. Figure 3.5: (a) Heights of women, which approximately follow a normal distribution, as predicted from the Central Limit Theorem. The distribution has mean 63.7 and standard deviation 2.7, so about 68% of women have heights in the range 63.7 ± 2.7. (b) Heights of men, approximately following a normal distribution with mean 69.1 and standard deviation 2.9. (c) Heights of all adults in the United States, which have the form of a mixture of two normal distributions, one for each sex. 표준편차(standard deviation)는 분산에 제곱근을 취한 것이다. Figure 3.5a에서 여성 키의 표준편차는 2.7인치로, 이는 우리가 모집단에서 무작위로 여성들을 뽑아 표본으로 만들 경우, 그 관측된 값(확률분포), \\(z\\)에서 평균 키를 빼고 제곱을 취한 뒤 평균을 낸 것에 제곱근을 취한 결과라는 것이다. 즉, \\((z-63.7)^2\\)을 구한 뒤 평균을 내면 분산이 되고, 그 값이 7.3이라고 할 때, \\(\\sqrt{7.3} = 2.7\\)이 표준편차라고 할 수 있다. 정리하자면 표준편차는 관측치들이 평균적으로 평균으로부터 떨어져 있는 정도를 보여준다고 할 수 있다. 3.5.2 Normal distribution; mean and standard deviation Figure 3.6: Approximately 50% of the mass of the normal distribution falls within 0.67 standard deviations from the mean, 68% of the mass falls within 1 standard deviation from the mean, 95% within 2 standard deviations of the mean, and 99.7% within 3 standard deviations 확률의 중심극한정리(The Central Limit Theorem)는 소규모의 독립적인 확률 변수들의 총합이 정규분포(normal distribution)라 불리는 확률변수로 근사한다는 정리이다. 독립적인 각 요소들의 총합: \\(z = \\sum^n_{i=1}z_i\\) \\(z\\)의 평균: \\(\\mu_z =\\sum^n_{i=1}\\mu_{z_i}\\) \\(z\\)의 분산: \\(\\sigma_z = \\sqrt{\\sum^n_{i=1}\\sigma^2_{z_i}}\\) 수리적으로 정규분포는 \\(z\\sim \\mathrm{N}(\\mu_z, \\sigma^2_z)\\)라고 쓸 수 있다. 확률변수 \\(z\\)는 평균–\\(\\mu_z\\)와 분산–\\(\\sigma^2_z\\)를 가지는 분포라는 의미이다. 앞으로 평균 \\(\\mu\\)와 표준편차 \\(\\sigma\\)를 가지는 정규분포를 \\(\\mathrm{N}(\\mu, sigma^2)\\)라고 쓴다. 대략적으로 이 분포에 속한 값들의 50%는 \\(\\mu \\pm 0.67\\sigma\\)에 속하는 값의 범위에 떨어지게 된다. 약 68%에 해당하는 값들은 \\(\\mu \\pm \\sigma\\)의 범위 내에 속하게 되며, 95%의 값들은 \\(\\mu \\pm 2\\sigma\\)에, 99.7%의 값들은 \\(\\mu \\pm 3\\sigma\\)의 범위 내에 위치하게 된다(Figure 3.6 참고). 정규분포는 총합, 차이, 그리고 추정된 회귀계수 등을 평균 또는 가중평균 등의 수리적 표현으로 나타낼 수 있다는 점에서 유용하다. 3.5.3 Linear transformations 정규분포는 선형변환(linear tranformation)해도 여전히 정규성을 지닌다. 만약 \\(y\\)가 남성의 키를 인치로 나타낸 변수로 그 평균이 69.1이라고 하고 표준편차가 2.9라고 하자. 그러면 2.54 \\(y\\)는 센티미터로의 키를 의미하며, 평균은 \\(2.54*69 = 175\\)가 되며 표준편차는 \\(2.54*2.9 = 7.4\\)가 된다. 3.5.4 Mean and standard deviation of the sum of correlated random variables 평균이 \\(\\mu_u,\\mu_v\\)이고 표준편차가 \\(\\sigma_a, \\sigma_b\\)인 두 확률변수 \\(u\\)와 \\(v\\)가 있다고 하자. 이때, 이 두 변수의 상관관계(correlation)은 \\(\\rho_{uv} = \\mathrm{E}((u-\\mu_u)(v-\\mu_v))/(\\sigma_a\\sigma_b)\\)로 나타낼 수 있다. 그리고 상관관계는 \\([-1, 1]\\)의 범위 내에 존재하게 된다. 상관관계는 \\(u\\)와 \\(v\\)의 선형결합에 관한 정보를 제시한다. 두 변수의 합(\\(u+v\\))의 평균은 \\(\\mu_u + \\mu_v\\)로, 표준편차는 \\(\\sqrt{\\sigma^2_{u} + \\sigma^2_{v} + 2\\rho\\sigma_u\\sigma_v}\\)로 나타낼 수 있다. 일반적으로 가중치가 부여된 합(\\(au + bv\\))는 \\(a\\mu_u + b\\mu_v\\)를 평균으로, \\(\\sqrt{a^2\\sigma^2_{u} + b^2\\sigma^2_{v} + 2ab\\rho\\sigma_u\\sigma_v}\\)를 표준편차로 가진다. 마찬가지로 두 변수의 차이인 \\(u-v\\)의 평균은 \\(\\mu_u-\\mu_v\\)로, 표준편차는 \\(\\sqrt{\\sigma^2_{u} + \\sigma^2_{v} - 2\\rho\\sigma_u\\sigma_v}\\)이다. 3.5.5 Lognormal distribution 로그변환은 0이나 음수값을 취하는 것을 허용하지 않기 때문에 로그 척도로 확률변수를 변환할 경우 모두 양수값을 가지게 된다. Figure 3.7은 미국 내 남성들의 로그를 취한 몸무게와 몸무게의 원변수의 분포를 각기 보여준다. Figure 3.7: Weights of men (which approximately follow a lognormal distribution, as predicted from the Central Limit Theorem from combining many small multiplicative factors), plotted on the logarithmic and original scales. 3.5.6 Binomial distribution 농구에서 20발의 슛을 쐈다고 하고, 성공률이 0.3이며 각각의 슈팅은 서로 독립적이라고 가정하자. 그러면 우리는 \\(n=20\\)에 \\(p=0.3\\)인 이항분포(binomial distribution)이며, \\(y\\sim \\mathrm{binomial(n, p)}\\)로 나타낼 수 있다. \\(n\\), \\(p\\)의 모수를 갖는 이항분포는 \\(np\\)를 평균으로, \\(\\sqrt{np(1-p)}\\)를 표준편차로 갖는다. 3.5.7 Poisson distribution 포아송 분포는 암발병 환자의 수나 웹사이트 방문자 수와 같은 횟수와 관련된 카운트 데이터에 사용되는 분포이다. 정치학 분야에서는 전쟁 횟수 등과 같은 종속변수를 분석하기 위해 사용될 수 있다. 3.5.8 Unclassified probability distribution 실제 데이터가 항상 특정한 확률 분포와 대응되는 것은 아니다. 하지만 확률분포의 종류는 실제 데이터를 이해 및 분석하는 데 있어서 일종의 가이드라인을 제시한다. 3.5.9 Probability distributions for error 회귀모델은 실제 데이터의 변동성으로 수립할 수 있는 \"결정적 모델(deterministic model)\"과 오차(error), 또는 설명되지 않는 변동성을 포착하기 위해 포함되는 확률분포로 이루어진다. 3.5.10 Comparing distributions 평균과 같은 요약치들을 이용해 분포들을 비교하기도 하지만 분위(quantiles)의 변화 등도 살펴볼 필요가 있다. 평균은 집단의 중심경향성(central tendancy)을 보여주는 값이기는 하지만, 분포가 치우쳐 있을 경우(skewed), 평균이 대표값으로 유용하지 않을 수도 있고, 평균 그 자체는 불확실성 정도를 보여주지 못하기 때문이다. Figure 3.8: Distributions of potential outcomes for patients given placebo or heart stents, using a normal approximation and assuming a treatment effect in which stents improve exercise time by 20 seconds, a shift which corresponds to taking a patient from the 50th to the 54th percentile of the distribution under the placebo. 3.6 Probability modeling 두 명의 후보와 \\(n\\)명의 유권자가 참여하는 선거가 있다고 가정하자. 만약 모든 유권자가 정확히 반반으로 갈라지거나 (\\(n\\)이 짝수일 때), 후보가 득표한 수가 서로 동수일 때 (\\(n\\)이 홀수 일 때), 한 표 한 표가 더해질 때마다, 그 표들은 잠재적으로 결과를 “결정지을 수 있는” 표가 된다(승부를 결정하는 표). 이 경우, 확률을 추정하기 위해 두 가지 방법을 생각해볼 수 있다: 첫째는 경험적으로 예측하는(forecasting) 접근법이고, 둘째는 이항확률모델을 사용하는 것인데, 이 경우는 심각한 문제를 가지고 있다. 3.6.1 Using an empirical forecast \\(y\\)가 후보 중 한 명이 받을 표의 비율이라고 하고, \\(y\\)의 불확실성은 평균 0.49, 표준편차 0.04의 정규분포로 나타낼 수 있다고 하자. 즉, 후보자가 질 거라고 예측되지만(평균이 \\(0.49 &lt; 0.5\\)), 불확실성을 감안하면 실제 결과는 이길수도, 질수도 있다는 것이 된다(\\(0.49-0.04 &lt; 0.05 &lt; 0.53\\)). \\(n\\)명의 표가 \\(n\\)이 짝수일 때 정확하게 갈라질 확률 또는 \\(n\\)이 홀수일 때 딱 한 표 차이로 나뉘게 될 확률은 \\(1/n\\)에 0.5의 예측 득표율 밀도의 곱으로 나타낼 수 있다. 예를 들어, 200,000명의 유권자가 있는 선거에서 이 확률은 아래와 같이 계산할 수 있다. dnorm(0.5, 0.49, 0.04)/2e5 ## [1] 4.833351e-05 결과는 약 4.8e-5로 약 \\(1/21000\\)에 근사하는 값이다. 이 값은 개별 유권자에게 있어서는 매우 낮은 확률이지만 캠페인에 있어서는 그다지 낮다고 보기는 힘들다. 유권자 수가 늘어날수록 이 확률은 점차 증가할 것이기 때문이다. 3.6.2 Using an reasonable-seeming but inappropriate probability model \\(n\\)명의 유권자가 있고, 특정 후보에게 투표할 확률이 \\(p\\)라고 하자. 둘이 정확하게 동점이 되거나 혹은 동점에서 딱 한 표가 모자랄 확률은 이항분포를 통해서 계산할 수 있다. 예를 들어, \\(n=200,000\\)이고 \\(p=0.5\\)라고 할 때, 선거 동수의 확률은 다음과 같이 계산할 수 있다. dbinom(1e5, 2e5, 0.5) ## [1] 0.001784122 그런데 이항분포 모델을 사용했을 때의 문제가 무엇일까? 가장 직접적으로 이항분포 모델을 사용할 수 없는 이유는 그 분포가 \\(n\\)번의 독립시행에서의 \\(p\\)의 확률에 따른 성공의 횟수를 나타낸다는 것에 있다. 하지만 유권자들은 독립적으로 의사결정을 내리지 않는다. 그들의 결정은 홍보, 후보자들의 연설, 뉴스 등과 같은 여러 공통적 요인들에 의해 영향을 받는다. 게다가 유권자들은 확률 \\(p\\)를 공유하지도 않는다. 유권자들의 당파성은 서로 독립적이지도, 동일하지도 않다. 어기서의 선거 예제에서 핵심적인 문제점은 이항 모델이 불확실성을 잡아내는 데 썩 훌륭하지 않다는 것이다. \\(n\\)명의 유권자가 독립적인 의사결정을 한다고 하고, 비현실적이지만 각각이 특정 후보에게 투표할 확률 \\(p\\)를 동일하게 갖는다고 가정하자. 만약 \\(p\\)가 유권자 전체의 평균 확률로 해석될 수 있다면, 이 \\(p\\) 자체는 어디서 오는 걸까? 실제 선거에서 우리는 이 확률을 결코 알 수 없다. 즉, 어디까지나 가정해야하기 때문에 불확실성을 포착할 수 없는 것이다. 3.6.3 General lessons for probability modeling 결과적으로 우리는 확률모델을 경험적 함의(emplical implications)로 확인할 필요가 있다. 만약 확률모델이 상식적으로 말이 안되는 예측을 내놓는다면, 모델에 무언가 문제가 있는지를 확인할 기회를 가지게 되고, 어떠한 가정이 위배되는지를 검토할 수 있게 된다. 확률모델에 문제가 있을 경우에, 우리는 그 (예측)실패를 우리의 이해를 제고하기 위한 방법으로 사용할 수 있기 때문에, 예측모델은 강력한 분석도구라고 할 수 있다. 위에서 \\(x\\)에 해당하는 경제성장률도 세 개의 값을 줬기 때문에 그에 따라서 예측되는 \\(\\hat y\\)도 세개가 되므로, 각각은 길이가 3인 벡터가 된다. 여기서 결정주의적이라는 의미는, 확실한 혹은 무작위가 아니(비체계적이지 않은)라는 의미로 이해할 수 있다. GHV는 처치라는 표현을 많이 쓰는데, 풀어서 이해하자면 우리가 종속변수, 혹은 결과변수인 \\(y\\)에 주요한 영향을 미칠 것으로 기대하는 예측변수, 설명변수라고 이해할 수 있다. 예컨대, 통계에서 \\(x_1\\)이 우리가 기대하는 주요 예측변수고 \\(x_2\\cdots x_n\\)이 선행연구 등을 통해 종속변수에 영향을 미칠 수 있는 여타의 변수로서 모델에 포함된 통제변수라고 할 때, 우리는 \\(x_1\\)의 값이 변화할 때(처치가 가해질 때)의 $ y$의 변화를 통해서 \\(x_1\\)과 \\(y\\)의 관계를 추론하고자 하는 것이다. \\(\\alpha\\)라고 하는 모집단의 모수(parameter)를 추정하기 위해 표본을 통해 \\(a\\)라는 통계치(statistics)를 얻었다고 하자. 우리는 모집단과 표본 간에 존재하는 필연적 불확실성–표본이 아무리 모집단을 대표한다고 해도 표집방법 등과 같은 이유로 나타날 수 밖에 없는 오차로 인해여 통계치가 완벽하게 모수와 동일하다고 확신할 수 없다. 즉, 통계치는 일정한 불확실성을 수반하게 되는데, 확률분포는 이 불확실성을 보여주기 위해 사용된다. 하지만 이 부분은 조금 더 부연설명이 필요한데, 모집단을 대표하는 값을 기대값이라고 할 때, 현실적으로 우리가 가진 데이터(표본)을 대표할 수 있는 값 중 하나가 평균이다. 그래서 평균을 표본 수준에서 일종의 기대값에 대응하는 개념으로 사용하는 것이지 엄밀하게 말하면 평균 = 기대값이라고 보기에는 무리가 있다. "],["statistical-inference.html", "Chapter 4 Statistical Inference 4.1 Sampling distributions and generative models 4.2 Estimates, standard errors, and confidence intervals 4.3 Bias and unmodeled uncertainty 4.4 Statistical significance, hypothesis testing, and statistical errors 4.5 Problems with the concept of statistical significance 4.6 Example of hypothesis testing: 55,000 residents need your help! 4.7 Moving beyond hypothesis testing", " Chapter 4 Statistical Inference 통계적 추론은 데이터에 기초하여 모집단의 모수에 관한 예측을 추정과 불확실성을 포함한 진술의 형태로 구성하는 것이다. 즉, 데이터가 현실 속에서 우리가 연구하고자 하는 모집단에 대한 하나의 표본이라고 할 때, 그 표본을 통해 모집단에서 존재하는 관계양상 등(모수)에 관해 예측하고, 그 예측에는 표본-모집단의 관계로 인한 불확실성이 존재하기에 그것 또한 반영하여 진술(statement)의 형태로 가공해내는 것이다. 이 챕터에서는 확률모델, 추정(estimation), 편향(bias), 분산, 그리고 통계적 추론의 해석과 통계적 오차에 관한 기본적인 내용들을 다룬다. 나아가 통계적 추론에서 불확실성의 개념이 어떻게 연계되는지를 살펴보고 잡음이 있는 데이터(불확실성을 포함한 데이터)로부터 확실성을 이끌어내기 위해 가설 검정과 통계적 유의성을 사용하는 것의 문제 또한 짚어본다. 4.1 Sampling distributions and generative models 4.1.1 Sampling, measurement error, and model error 4.1.2 The sampling distribution 4.2 Estimates, standard errors, and confidence intervals 4.2.1 Parameters, estimands, and estimates 4.2.2 Standard errors, inferential uncertainty, and confidence intervals 4.2.3 Standard errors and confidence intervals for average and proportions 4.2.4 Standard error and confidence interval for a proportion when \\(y = 0\\) or \\(y = n\\) 4.2.5 Standard error for a comparison 4.2.6 Sampling distribution of the sample mean and standard deviation; normal and \\(\\chi^2\\) distributions 4.2.7 Degrees of freedom 4.2.8 Confidence intervals from the \\(t\\) distribution 4.2.9 Inference for discrete data 4.2.10 Linear transformations 4.2.11 Comparisons, visual and numerical 4.2.12 Weighted averages 4.3 Bias and unmodeled uncertainty 4.3.1 Bias in estimation 4.3.2 Adjusting inferences to account for bias and unmodeled uncertainty 4.4 Statistical significance, hypothesis testing, and statistical errors 4.4.1 Statistical significance 4.4.2 Hypothesis testing for simple comparisons 4.4.2.1 Estimate, standard error, and degrees of freedom 4.4.2.2 Null and alternative hypotheses 4.4.3 Hypothesis testing: general formulation 4.4.4 Comparisons of parameters to fixed values and each other: interpreting confidence intervals as hypothesis tests 4.4.5 Type 1 and type 2 errors and why we don’t like talking about them 4.4.6 Type M (magnitude) and type S (sign) errors 4.4.7 Hypothesis testing and statistical practice 4.5 Problems with the concept of statistical significance 4.5.1 Statistical significance is not the same as practical importance 4.5.2 Non-significance is not the same as zero 4.5.3 The difference between “significant” and “not significant” is not itself statistically significant 4.5.4 Researcher degrees of freedom, \\(p\\)-hacking, and forking paths 4.5.5 The statistical significance filter 4.5.6 Example: A flawed study of ovulation and political attitudes 4.6 Example of hypothesis testing: 55,000 residents need your help! 4.7 Moving beyond hypothesis testing "],["simulation.html", "Chapter 5 Simulation 5.1 Simulation of discrete probability models 5.2 Simulation of continuous and mixed discrete/continuous models 5.3 Summarizing a set of simulations using median and median absolute deviation 5.4 Bootstrapping to simulate a sampling distribution 5.5 Fake-data simulation as a way of life", " Chapter 5 Simulation 5.1 Simulation of discrete probability models 5.1.1 How many girls in 400 births? 5.1.2 Accounting for twins 5.2 Simulation of continuous and mixed discrete/continuous models 5.2.1 Simulation in R using custom-made functions 5.3 Summarizing a set of simulations using median and median absolute deviation 5.4 Bootstrapping to simulate a sampling distribution 5.4.1 Choices in defining the bootstrap distribution 5.4.1.1 Time series 5.4.1.2 Multilevel structure 5.4.1.3 Discrete data 5.4.2 Limitations of bootstrapping 5.5 Fake-data simulation as a way of life "],["simulation-1.html", "Chapter 6 Simulation 6.1 Simulation of discrete probability models 6.2 Simulation of continuous and mixed discrete/continuous models 6.3 Summarizing a set of simulations using median and median absolute deviation 6.4 Bootstrapping to simulate a sampling distribution 6.5 Fake-data simulation as a way of life", " Chapter 6 Simulation 6.1 Simulation of discrete probability models 6.1.1 How many girls in 400 births? 6.1.2 Accounting for twins 6.2 Simulation of continuous and mixed discrete/continuous models 6.2.1 Simulation in R using custom-made functions 6.3 Summarizing a set of simulations using median and median absolute deviation 6.4 Bootstrapping to simulate a sampling distribution 6.4.1 Choices in defining the bootstrap distribution 6.4.1.1 Time series 6.4.1.2 Multilevel structure 6.4.1.3 Discrete data 6.4.2 Limitations of bootstrapping 6.5 Fake-data simulation as a way of life "],["simulation-2.html", "Chapter 7 Simulation 7.1 Simulation of discrete probability models 7.2 Simulation of continuous and mixed discrete/continuous models 7.3 Summarizing a set of simulations using median and median absolute deviation 7.4 Bootstrapping to simulate a sampling distribution 7.5 Fake-data simulation as a way of life", " Chapter 7 Simulation 7.1 Simulation of discrete probability models 7.1.1 How many girls in 400 births? 7.1.2 Accounting for twins 7.2 Simulation of continuous and mixed discrete/continuous models 7.2.1 Simulation in R using custom-made functions 7.3 Summarizing a set of simulations using median and median absolute deviation 7.4 Bootstrapping to simulate a sampling distribution 7.4.1 Choices in defining the bootstrap distribution 7.4.1.1 Time series 7.4.1.2 Multilevel structure 7.4.1.3 Discrete data 7.4.2 Limitations of bootstrapping 7.5 Fake-data simulation as a way of life "],["simulation-3.html", "Chapter 8 Simulation 8.1 Simulation of discrete probability models 8.2 Simulation of continuous and mixed discrete/continuous models 8.3 Summarizing a set of simulations using median and median absolute deviation 8.4 Bootstrapping to simulate a sampling distribution 8.5 Fake-data simulation as a way of life", " Chapter 8 Simulation 8.1 Simulation of discrete probability models 8.1.1 How many girls in 400 births? 8.1.2 Accounting for twins 8.2 Simulation of continuous and mixed discrete/continuous models 8.2.1 Simulation in R using custom-made functions 8.3 Summarizing a set of simulations using median and median absolute deviation 8.4 Bootstrapping to simulate a sampling distribution 8.4.1 Choices in defining the bootstrap distribution 8.4.1.1 Time series 8.4.1.2 Multilevel structure 8.4.1.3 Discrete data 8.4.2 Limitations of bootstrapping 8.5 Fake-data simulation as a way of life "],["simulation-4.html", "Chapter 9 Simulation 9.1 Simulation of discrete probability models 9.2 Simulation of continuous and mixed discrete/continuous models 9.3 Summarizing a set of simulations using median and median absolute deviation 9.4 Bootstrapping to simulate a sampling distribution 9.5 Fake-data simulation as a way of life", " Chapter 9 Simulation 9.1 Simulation of discrete probability models 9.1.1 How many girls in 400 births? 9.1.2 Accounting for twins 9.2 Simulation of continuous and mixed discrete/continuous models 9.2.1 Simulation in R using custom-made functions 9.3 Summarizing a set of simulations using median and median absolute deviation 9.4 Bootstrapping to simulate a sampling distribution 9.4.1 Choices in defining the bootstrap distribution 9.4.1.1 Time series 9.4.1.2 Multilevel structure 9.4.1.3 Discrete data 9.4.2 Limitations of bootstrapping 9.5 Fake-data simulation as a way of life "],["simulation-5.html", "Chapter 10 Simulation 10.1 Simulation of discrete probability models 10.2 Simulation of continuous and mixed discrete/continuous models 10.3 Summarizing a set of simulations using median and median absolute deviation 10.4 Bootstrapping to simulate a sampling distribution 10.5 Fake-data simulation as a way of life", " Chapter 10 Simulation 10.1 Simulation of discrete probability models 10.1.1 How many girls in 400 births? 10.1.2 Accounting for twins 10.2 Simulation of continuous and mixed discrete/continuous models 10.2.1 Simulation in R using custom-made functions 10.3 Summarizing a set of simulations using median and median absolute deviation 10.4 Bootstrapping to simulate a sampling distribution 10.4.1 Choices in defining the bootstrap distribution 10.4.1.1 Time series 10.4.1.2 Multilevel structure 10.4.1.3 Discrete data 10.4.2 Limitations of bootstrapping 10.5 Fake-data simulation as a way of life "],["simulation-6.html", "Chapter 11 Simulation 11.1 Simulation of discrete probability models 11.2 Simulation of continuous and mixed discrete/continuous models 11.3 Summarizing a set of simulations using median and median absolute deviation 11.4 Bootstrapping to simulate a sampling distribution 11.5 Fake-data simulation as a way of life", " Chapter 11 Simulation 11.1 Simulation of discrete probability models 11.1.1 How many girls in 400 births? 11.1.2 Accounting for twins 11.2 Simulation of continuous and mixed discrete/continuous models 11.2.1 Simulation in R using custom-made functions 11.3 Summarizing a set of simulations using median and median absolute deviation 11.4 Bootstrapping to simulate a sampling distribution 11.4.1 Choices in defining the bootstrap distribution 11.4.1.1 Time series 11.4.1.2 Multilevel structure 11.4.1.3 Discrete data 11.4.2 Limitations of bootstrapping 11.5 Fake-data simulation as a way of life "],["simulation-7.html", "Chapter 12 Simulation 12.1 Simulation of discrete probability models 12.2 Simulation of continuous and mixed discrete/continuous models 12.3 Summarizing a set of simulations using median and median absolute deviation 12.4 Bootstrapping to simulate a sampling distribution 12.5 Fake-data simulation as a way of life", " Chapter 12 Simulation 12.1 Simulation of discrete probability models 12.1.1 How many girls in 400 births? 12.1.2 Accounting for twins 12.2 Simulation of continuous and mixed discrete/continuous models 12.2.1 Simulation in R using custom-made functions 12.3 Summarizing a set of simulations using median and median absolute deviation 12.4 Bootstrapping to simulate a sampling distribution 12.4.1 Choices in defining the bootstrap distribution 12.4.1.1 Time series 12.4.1.2 Multilevel structure 12.4.1.3 Discrete data 12.4.2 Limitations of bootstrapping 12.5 Fake-data simulation as a way of life "],["simulation-8.html", "Chapter 13 Simulation 13.1 Simulation of discrete probability models 13.2 Simulation of continuous and mixed discrete/continuous models 13.3 Summarizing a set of simulations using median and median absolute deviation 13.4 Bootstrapping to simulate a sampling distribution 13.5 Fake-data simulation as a way of life", " Chapter 13 Simulation 13.1 Simulation of discrete probability models 13.1.1 How many girls in 400 births? 13.1.2 Accounting for twins 13.2 Simulation of continuous and mixed discrete/continuous models 13.2.1 Simulation in R using custom-made functions 13.3 Summarizing a set of simulations using median and median absolute deviation 13.4 Bootstrapping to simulate a sampling distribution 13.4.1 Choices in defining the bootstrap distribution 13.4.1.1 Time series 13.4.1.2 Multilevel structure 13.4.1.3 Discrete data 13.4.2 Limitations of bootstrapping 13.5 Fake-data simulation as a way of life "],["simulation-9.html", "Chapter 14 Simulation 14.1 Simulation of discrete probability models 14.2 Simulation of continuous and mixed discrete/continuous models 14.3 Summarizing a set of simulations using median and median absolute deviation 14.4 Bootstrapping to simulate a sampling distribution 14.5 Fake-data simulation as a way of life", " Chapter 14 Simulation 14.1 Simulation of discrete probability models 14.1.1 How many girls in 400 births? 14.1.2 Accounting for twins 14.2 Simulation of continuous and mixed discrete/continuous models 14.2.1 Simulation in R using custom-made functions 14.3 Summarizing a set of simulations using median and median absolute deviation 14.4 Bootstrapping to simulate a sampling distribution 14.4.1 Choices in defining the bootstrap distribution 14.4.1.1 Time series 14.4.1.2 Multilevel structure 14.4.1.3 Discrete data 14.4.2 Limitations of bootstrapping 14.5 Fake-data simulation as a way of life "],["simulation-10.html", "Chapter 15 Simulation 15.1 Simulation of discrete probability models 15.2 Simulation of continuous and mixed discrete/continuous models 15.3 Summarizing a set of simulations using median and median absolute deviation 15.4 Bootstrapping to simulate a sampling distribution 15.5 Fake-data simulation as a way of life", " Chapter 15 Simulation 15.1 Simulation of discrete probability models 15.1.1 How many girls in 400 births? 15.1.2 Accounting for twins 15.2 Simulation of continuous and mixed discrete/continuous models 15.2.1 Simulation in R using custom-made functions 15.3 Summarizing a set of simulations using median and median absolute deviation 15.4 Bootstrapping to simulate a sampling distribution 15.4.1 Choices in defining the bootstrap distribution 15.4.1.1 Time series 15.4.1.2 Multilevel structure 15.4.1.3 Discrete data 15.4.2 Limitations of bootstrapping 15.5 Fake-data simulation as a way of life "],["simulation-11.html", "Chapter 16 Simulation 16.1 Simulation of discrete probability models 16.2 Simulation of continuous and mixed discrete/continuous models 16.3 Summarizing a set of simulations using median and median absolute deviation 16.4 Bootstrapping to simulate a sampling distribution 16.5 Fake-data simulation as a way of life", " Chapter 16 Simulation 16.1 Simulation of discrete probability models 16.1.1 How many girls in 400 births? 16.1.2 Accounting for twins 16.2 Simulation of continuous and mixed discrete/continuous models 16.2.1 Simulation in R using custom-made functions 16.3 Summarizing a set of simulations using median and median absolute deviation 16.4 Bootstrapping to simulate a sampling distribution 16.4.1 Choices in defining the bootstrap distribution 16.4.1.1 Time series 16.4.1.2 Multilevel structure 16.4.1.3 Discrete data 16.4.2 Limitations of bootstrapping 16.5 Fake-data simulation as a way of life "],["simulation-12.html", "Chapter 17 Simulation 17.1 Simulation of discrete probability models 17.2 Simulation of continuous and mixed discrete/continuous models 17.3 Summarizing a set of simulations using median and median absolute deviation 17.4 Bootstrapping to simulate a sampling distribution 17.5 Fake-data simulation as a way of life", " Chapter 17 Simulation 17.1 Simulation of discrete probability models 17.1.1 How many girls in 400 births? 17.1.2 Accounting for twins 17.2 Simulation of continuous and mixed discrete/continuous models 17.2.1 Simulation in R using custom-made functions 17.3 Summarizing a set of simulations using median and median absolute deviation 17.4 Bootstrapping to simulate a sampling distribution 17.4.1 Choices in defining the bootstrap distribution 17.4.1.1 Time series 17.4.1.2 Multilevel structure 17.4.1.3 Discrete data 17.4.2 Limitations of bootstrapping 17.5 Fake-data simulation as a way of life "],["simulation-13.html", "Chapter 18 Simulation 18.1 Simulation of discrete probability models 18.2 Simulation of continuous and mixed discrete/continuous models 18.3 Summarizing a set of simulations using median and median absolute deviation 18.4 Bootstrapping to simulate a sampling distribution 18.5 Fake-data simulation as a way of life", " Chapter 18 Simulation 18.1 Simulation of discrete probability models 18.1.1 How many girls in 400 births? 18.1.2 Accounting for twins 18.2 Simulation of continuous and mixed discrete/continuous models 18.2.1 Simulation in R using custom-made functions 18.3 Summarizing a set of simulations using median and median absolute deviation 18.4 Bootstrapping to simulate a sampling distribution 18.4.1 Choices in defining the bootstrap distribution 18.4.1.1 Time series 18.4.1.2 Multilevel structure 18.4.1.3 Discrete data 18.4.2 Limitations of bootstrapping 18.5 Fake-data simulation as a way of life "],["simulation-14.html", "Chapter 19 Simulation 19.1 Simulation of discrete probability models 19.2 Simulation of continuous and mixed discrete/continuous models 19.3 Summarizing a set of simulations using median and median absolute deviation 19.4 Bootstrapping to simulate a sampling distribution 19.5 Fake-data simulation as a way of life", " Chapter 19 Simulation 19.1 Simulation of discrete probability models 19.1.1 How many girls in 400 births? 19.1.2 Accounting for twins 19.2 Simulation of continuous and mixed discrete/continuous models 19.2.1 Simulation in R using custom-made functions 19.3 Summarizing a set of simulations using median and median absolute deviation 19.4 Bootstrapping to simulate a sampling distribution 19.4.1 Choices in defining the bootstrap distribution 19.4.1.1 Time series 19.4.1.2 Multilevel structure 19.4.1.3 Discrete data 19.4.2 Limitations of bootstrapping 19.5 Fake-data simulation as a way of life "],["references.html", "References", " References "]]
